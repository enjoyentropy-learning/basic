{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P7bkMrMRMHL3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vijayamritagrawal/fromLaptop/Personal/Personal2/trm/basic/.venv/lib/python3.13/site-packages/torch/_subclasses/functional_tensor.py:283: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "\n",
        "torch.set_default_dtype(torch.float) # Default to float32 initially, can be changed per experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5Noqc-qnMIIT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RawAttention(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.Wq = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.Wk = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.Wv = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, d_model)\n",
        "\n",
        "        Q = self.Wq(x)\n",
        "        K = self.Wk(x)\n",
        "        V = self.Wv(x)\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(1, 2)) / (self.d_model ** 0.5)\n",
        "\n",
        "        out = torch.matmul(scores, V)\n",
        "        # (batch, seq_len, d_model)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class RawAttentionWithTopNeuron(nn.Module):\n",
        "    def __init__(self, d_model,seq_len):\n",
        "        super().__init__()\n",
        "        self.raw_attention = RawAttention(d_model)\n",
        "        self.readout = nn.Linear(d_model*seq_len, 1, bias=True)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, d_model)\n",
        "\n",
        "        attended = self.raw_attention(x)\n",
        "\n",
        "        # Residual\n",
        "        combined = attended + x\n",
        "\n",
        "\n",
        "\n",
        "        # Pool over tokens\n",
        "        #pooled = combined.sum(dim=1)\n",
        "        # (batch, d_model)\n",
        "\n",
        "        out = self.readout(combined.reshape(combined.shape[0], -1))\n",
        "        # (batch, 1)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szfXl9M9Qvfa"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# -----------------------------\n",
        "# Example data\n",
        "# -----------------------------\n",
        "# Shape: (batch, 9)\n",
        "X_digits = torch.tensor([\n",
        "    [1, 2, 3, 4, 5, 6, 7, 8, 9],  # valid\n",
        "    [1, 2, 8, 4, 5, 6, 3, 8, 7],  # duplicate 8, missing 9\n",
        "    [9, 8, 7, 6, 5, 4, 3, 2, 1],  # valid\n",
        "    [1, 7, 2, 3, 4, 5, 6, 1, 8],  # duplicate 1, missing 9\n",
        "], dtype=torch.long)\n",
        "\n",
        "y = torch.tensor([\n",
        "    [1.],\n",
        "    [0.],\n",
        "    [1.],\n",
        "    [0.]\n",
        "])\n",
        "\n",
        "# One-hot encode digits 1..9 â†’ indices 0..8\n",
        "X_onehot = torch.nn.functional.one_hot(X_digits - 1, num_classes=9)\n",
        "X_onehot = X_onehot.float()\n",
        "# Shape: (batch, 9, 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VQ8hhs0jhA9j"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Model, loss, optimizer\n",
        "# -----------------------------\n",
        "\n",
        "d_model = 9\n",
        "seq_len = 9\n",
        "model = RawAttentionWithTopNeuron(d_model, seq_len)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_history = []\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.03)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Umse1fqmFty"
      },
      "outputs": [],
      "source": [
        "\n",
        "#optimizer = optim.AdamW(model.parameters(), lr=0.03)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDUhD0GfnKRE"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    for p in model.parameters():\n",
        "        p.add_(0.1 * torch.randn_like(p))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haCs4Ix2ih1m"
      },
      "outputs": [],
      "source": [
        "#optimizer = optim.SGD(model.parameters(), lr=0.1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNKlP_siROGi",
        "outputId": "311887e4-d3cb-4314-cb03-b50c2f286391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch total:  2177.0\n",
            "Epoch   0 | Loss: 0.49218571 | Acc: 0.50849793 | \n",
            "epoch total:  2177.0\n",
            "Epoch   1 | Loss: 0.29097226 | Acc: 0.50252641 | \n",
            "epoch total:  2177.0\n",
            "Epoch   2 | Loss: 0.30210626 | Acc: 0.51676619 | \n",
            "epoch total:  2177.0\n",
            "Epoch   3 | Loss: 0.33487320 | Acc: 0.50574185 | \n",
            "epoch total:  2177.0\n",
            "Epoch   4 | Loss: 0.30737463 | Acc: 0.50390446 | \n",
            "epoch total:  2177.0\n",
            "Epoch   5 | Loss: 0.27182412 | Acc: 0.51998163 | \n",
            "epoch total:  2177.0\n",
            "Epoch   6 | Loss: 0.25099355 | Acc: 0.53651814 | \n",
            "epoch total:  2177.0\n",
            "Epoch   7 | Loss: 0.24600714 | Acc: 0.55718879 | \n",
            "epoch total:  2177.0\n",
            "Epoch   8 | Loss: 0.24958897 | Acc: 0.54294901 | \n",
            "epoch total:  2177.0\n",
            "Epoch   9 | Loss: 0.25225666 | Acc: 0.53973358 | \n",
            "epoch total:  2177.0\n",
            "Epoch  10 | Loss: 0.24806185 | Acc: 0.55029858 | \n",
            "epoch total:  2177.0\n",
            "Epoch  11 | Loss: 0.23771526 | Acc: 0.57923748 | \n",
            "epoch total:  2177.0\n",
            "Epoch  12 | Loss: 0.22806172 | Acc: 0.62149747 | \n",
            "epoch total:  2177.0\n",
            "Epoch  13 | Loss: 0.22637831 | Acc: 0.63114378 | \n",
            "epoch total:  2177.0\n",
            "Epoch  14 | Loss: 0.22724184 | Acc: 0.62195682 | \n",
            "epoch total:  2177.0\n",
            "Epoch  15 | Loss: 0.21859565 | Acc: 0.64859899 | \n",
            "epoch total:  2177.0\n",
            "Epoch  16 | Loss: 0.20567903 | Acc: 0.69039963 | \n",
            "epoch total:  2177.0\n",
            "Epoch  17 | Loss: 0.19760838 | Acc: 0.71107028 | \n",
            "epoch total:  2177.0\n",
            "Epoch  18 | Loss: 0.19241329 | Acc: 0.70969224 | \n",
            "epoch total:  2177.0\n",
            "Epoch  19 | Loss: 0.18364130 | Acc: 0.73311897 | \n",
            "epoch total:  2177.0\n",
            "Epoch  20 | Loss: 0.16952050 | Acc: 0.79329352 | \n",
            "epoch total:  2177.0\n",
            "Epoch  21 | Loss: 0.15471382 | Acc: 0.82590721 | \n",
            "epoch total:  2177.0\n",
            "Epoch  22 | Loss: 0.14538057 | Acc: 0.82452917 | \n",
            "epoch total:  2177.0\n",
            "Epoch  23 | Loss: 0.14037612 | Acc: 0.82544786 | \n",
            "epoch total:  2177.0\n",
            "Epoch  24 | Loss: 0.13585392 | Acc: 0.85943960 | \n",
            "epoch total:  2177.0\n",
            "Epoch  25 | Loss: 0.13479312 | Acc: 0.89802480 | \n",
            "epoch total:  2177.0\n",
            "Epoch  26 | Loss: 0.13501741 | Acc: 0.91869545 | \n",
            "epoch total:  2177.0\n",
            "Epoch  27 | Loss: 0.13053347 | Acc: 0.92007350 | \n",
            "epoch total:  2177.0\n",
            "Epoch  28 | Loss: 0.12245326 | Acc: 0.91502067 | \n",
            "epoch total:  2177.0\n",
            "Epoch  29 | Loss: 0.11673830 | Acc: 0.89526872 | \n",
            "epoch total:  2177.0\n",
            "Epoch  30 | Loss: 0.11452425 | Acc: 0.88056959 | \n",
            "epoch total:  2177.0\n",
            "Epoch  31 | Loss: 0.11178433 | Acc: 0.88608176 | \n",
            "epoch total:  2177.0\n",
            "Epoch  32 | Loss: 0.10924388 | Acc: 0.90078089 | \n",
            "epoch total:  2177.0\n",
            "Epoch  33 | Loss: 0.10778158 | Acc: 0.91869545 | \n",
            "epoch total:  2177.0\n",
            "Epoch  34 | Loss: 0.10505283 | Acc: 0.92420763 | \n",
            "epoch total:  2177.0\n",
            "Epoch  35 | Loss: 0.10103500 | Acc: 0.91915480 | \n",
            "epoch total:  2177.0\n",
            "Epoch  36 | Loss: 0.09796182 | Acc: 0.90583372 | \n",
            "epoch total:  2177.0\n",
            "Epoch  37 | Loss: 0.09591929 | Acc: 0.90215893 | \n",
            "epoch total:  2177.0\n",
            "Epoch  38 | Loss: 0.09349836 | Acc: 0.91364263 | \n",
            "epoch total:  2177.0\n",
            "Epoch  39 | Loss: 0.09144124 | Acc: 0.92926045 | \n",
            "epoch total:  2177.0\n",
            "Epoch  40 | Loss: 0.09021866 | Acc: 0.93569132 | \n",
            "epoch total:  2177.0\n",
            "Epoch  41 | Loss: 0.08909161 | Acc: 0.93661001 | \n",
            "epoch total:  2177.0\n",
            "Epoch  42 | Loss: 0.08789922 | Acc: 0.93247588 | \n",
            "epoch total:  2177.0\n",
            "Epoch  43 | Loss: 0.08696201 | Acc: 0.92696371 | \n",
            "epoch total:  2177.0\n",
            "Epoch  44 | Loss: 0.08594337 | Acc: 0.92420763 | \n",
            "epoch total:  2177.0\n",
            "Epoch  45 | Loss: 0.08459164 | Acc: 0.92650436 | \n",
            "epoch total:  2177.0\n",
            "Epoch  46 | Loss: 0.08356324 | Acc: 0.93247588 | \n",
            "epoch total:  2177.0\n",
            "Epoch  47 | Loss: 0.08303472 | Acc: 0.93982545 | \n",
            "epoch total:  2177.0\n",
            "Epoch  48 | Loss: 0.08248277 | Acc: 0.93844740 | \n",
            "epoch total:  2177.0\n",
            "Epoch  49 | Loss: 0.08190673 | Acc: 0.93339458 | \n",
            "epoch total:  2177.0\n",
            "Epoch  50 | Loss: 0.08157975 | Acc: 0.92788241 | \n",
            "epoch total:  2177.0\n",
            "Epoch  51 | Loss: 0.08107978 | Acc: 0.92971980 | \n",
            "epoch total:  2177.0\n",
            "Epoch  52 | Loss: 0.08015873 | Acc: 0.93477262 | \n",
            "epoch total:  2177.0\n",
            "Epoch  53 | Loss: 0.07928597 | Acc: 0.94258153 | \n",
            "epoch total:  2177.0\n",
            "Epoch  54 | Loss: 0.07861178 | Acc: 0.94487827 | \n",
            "epoch total:  2177.0\n",
            "Epoch  55 | Loss: 0.07805120 | Acc: 0.94533762 | \n",
            "epoch total:  2177.0\n",
            "Epoch  56 | Loss: 0.07768979 | Acc: 0.94166284 | \n",
            "epoch total:  2177.0\n",
            "Epoch  57 | Loss: 0.07734773 | Acc: 0.94304088 | \n",
            "epoch total:  2177.0\n",
            "Epoch  58 | Loss: 0.07671499 | Acc: 0.94441893 | \n",
            "epoch total:  2177.0\n",
            "Epoch  59 | Loss: 0.07600548 | Acc: 0.94901240 | \n",
            "epoch total:  2177.0\n",
            "Epoch  60 | Loss: 0.07551949 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch  61 | Loss: 0.07520529 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch  62 | Loss: 0.07499471 | Acc: 0.94855305 | \n",
            "epoch total:  2177.0\n",
            "Epoch  63 | Loss: 0.07478803 | Acc: 0.94671566 | \n",
            "epoch total:  2177.0\n",
            "Epoch  64 | Loss: 0.07439733 | Acc: 0.94671566 | \n",
            "epoch total:  2177.0\n",
            "Epoch  65 | Loss: 0.07392917 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch  66 | Loss: 0.07356735 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch  67 | Loss: 0.07325387 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch  68 | Loss: 0.07295215 | Acc: 0.94901240 | \n",
            "epoch total:  2177.0\n",
            "Epoch  69 | Loss: 0.07262787 | Acc: 0.94763436 | \n",
            "epoch total:  2177.0\n",
            "Epoch  70 | Loss: 0.07217345 | Acc: 0.94947175 | \n",
            "epoch total:  2177.0\n",
            "Epoch  71 | Loss: 0.07169155 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch  72 | Loss: 0.07129700 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch  73 | Loss: 0.07093257 | Acc: 0.95039045 | \n",
            "epoch total:  2177.0\n",
            "Epoch  74 | Loss: 0.07059193 | Acc: 0.94901240 | \n",
            "epoch total:  2177.0\n",
            "Epoch  75 | Loss: 0.07025148 | Acc: 0.94855305 | \n",
            "epoch total:  2177.0\n",
            "Epoch  76 | Loss: 0.06987923 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch  77 | Loss: 0.06956629 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch  78 | Loss: 0.06933112 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch  79 | Loss: 0.06914054 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch  80 | Loss: 0.06900033 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch  81 | Loss: 0.06886062 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch  82 | Loss: 0.06873348 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch  83 | Loss: 0.06865310 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch  84 | Loss: 0.06859151 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch  85 | Loss: 0.06855208 | Acc: 0.95039045 | \n",
            "epoch total:  2177.0\n",
            "Epoch  86 | Loss: 0.06850468 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch  87 | Loss: 0.06843415 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch  88 | Loss: 0.06836749 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch  89 | Loss: 0.06830136 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch  90 | Loss: 0.06825057 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch  91 | Loss: 0.06820577 | Acc: 0.95039045 | \n",
            "epoch total:  2177.0\n",
            "Epoch  92 | Loss: 0.06814957 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch  93 | Loss: 0.06809267 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch  94 | Loss: 0.06803244 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch  95 | Loss: 0.06798187 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch  96 | Loss: 0.06793933 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch  97 | Loss: 0.06789473 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch  98 | Loss: 0.06784979 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch  99 | Loss: 0.06779893 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 100 | Loss: 0.06775087 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 101 | Loss: 0.06770569 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 102 | Loss: 0.06766099 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 103 | Loss: 0.06761707 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 104 | Loss: 0.06757001 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 105 | Loss: 0.06752539 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 106 | Loss: 0.06748222 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 107 | Loss: 0.06744140 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 108 | Loss: 0.06740168 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 109 | Loss: 0.06736144 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 110 | Loss: 0.06732316 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 111 | Loss: 0.06728546 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 112 | Loss: 0.06724975 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 113 | Loss: 0.06721360 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 114 | Loss: 0.06717677 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 115 | Loss: 0.06713918 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 116 | Loss: 0.06710084 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 117 | Loss: 0.06706280 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 118 | Loss: 0.06702404 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 119 | Loss: 0.06698532 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 120 | Loss: 0.06694585 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 121 | Loss: 0.06690661 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 122 | Loss: 0.06686743 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 123 | Loss: 0.06682849 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 124 | Loss: 0.06678958 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 125 | Loss: 0.06675047 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 126 | Loss: 0.06671145 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 127 | Loss: 0.06667218 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 128 | Loss: 0.06663278 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 129 | Loss: 0.06659274 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 130 | Loss: 0.06655239 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 131 | Loss: 0.06651162 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 132 | Loss: 0.06647072 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 133 | Loss: 0.06642939 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 134 | Loss: 0.06638774 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 135 | Loss: 0.06634571 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 136 | Loss: 0.06630341 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 137 | Loss: 0.06626082 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 138 | Loss: 0.06621785 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 139 | Loss: 0.06617450 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 140 | Loss: 0.06613081 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 141 | Loss: 0.06608684 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 142 | Loss: 0.06604256 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 143 | Loss: 0.06599798 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 144 | Loss: 0.06595313 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 145 | Loss: 0.06590809 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 146 | Loss: 0.06586285 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 147 | Loss: 0.06581744 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 148 | Loss: 0.06577189 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 149 | Loss: 0.06572627 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 150 | Loss: 0.06568064 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 151 | Loss: 0.06563506 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 152 | Loss: 0.06558955 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 153 | Loss: 0.06554423 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 154 | Loss: 0.06549910 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 155 | Loss: 0.06545426 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 156 | Loss: 0.06540971 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 157 | Loss: 0.06536552 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 158 | Loss: 0.06532171 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 159 | Loss: 0.06527834 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 160 | Loss: 0.06523550 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 161 | Loss: 0.06519316 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 162 | Loss: 0.06515142 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 163 | Loss: 0.06511026 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 164 | Loss: 0.06506971 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 165 | Loss: 0.06502982 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 166 | Loss: 0.06499054 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 167 | Loss: 0.06495193 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 168 | Loss: 0.06491394 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 169 | Loss: 0.06487662 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 170 | Loss: 0.06483996 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 171 | Loss: 0.06480393 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 172 | Loss: 0.06476855 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 173 | Loss: 0.06473380 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 174 | Loss: 0.06469969 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 175 | Loss: 0.06466621 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 176 | Loss: 0.06463333 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 177 | Loss: 0.06460109 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 178 | Loss: 0.06456947 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 179 | Loss: 0.06453849 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 180 | Loss: 0.06450813 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 181 | Loss: 0.06447841 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 182 | Loss: 0.06444935 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 183 | Loss: 0.06442092 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 184 | Loss: 0.06439315 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 185 | Loss: 0.06436602 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 186 | Loss: 0.06433958 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 187 | Loss: 0.06431381 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 188 | Loss: 0.06428870 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 189 | Loss: 0.06426428 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 190 | Loss: 0.06424052 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 191 | Loss: 0.06421744 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 192 | Loss: 0.06419504 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 193 | Loss: 0.06417330 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 194 | Loss: 0.06415219 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 195 | Loss: 0.06413174 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 196 | Loss: 0.06411193 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 197 | Loss: 0.06409272 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 198 | Loss: 0.06407411 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 199 | Loss: 0.06405609 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 200 | Loss: 0.06403860 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 201 | Loss: 0.06402168 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 202 | Loss: 0.06400525 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 203 | Loss: 0.06398932 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 204 | Loss: 0.06397384 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 205 | Loss: 0.06395882 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 206 | Loss: 0.06394421 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 207 | Loss: 0.06392998 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 208 | Loss: 0.06391613 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 209 | Loss: 0.06390263 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 210 | Loss: 0.06388946 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 211 | Loss: 0.06387661 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 212 | Loss: 0.06386404 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 213 | Loss: 0.06385177 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 214 | Loss: 0.06383976 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 215 | Loss: 0.06382800 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 216 | Loss: 0.06381647 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 217 | Loss: 0.06380520 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 218 | Loss: 0.06379414 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 219 | Loss: 0.06378330 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 220 | Loss: 0.06377266 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 221 | Loss: 0.06376223 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 222 | Loss: 0.06375197 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 223 | Loss: 0.06374190 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 224 | Loss: 0.06373202 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 225 | Loss: 0.06372230 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 226 | Loss: 0.06371276 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 227 | Loss: 0.06370337 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 228 | Loss: 0.06369412 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 229 | Loss: 0.06368504 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 230 | Loss: 0.06367607 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 231 | Loss: 0.06366725 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 232 | Loss: 0.06365856 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 233 | Loss: 0.06365000 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 234 | Loss: 0.06364159 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 235 | Loss: 0.06363341 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 236 | Loss: 0.06362575 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 237 | Loss: 0.06361955 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 238 | Loss: 0.06361850 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 239 | Loss: 0.06363589 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 240 | Loss: 0.06372402 | Acc: 0.96003675 | \n",
            "epoch total:  2177.0\n",
            "Epoch 241 | Loss: 0.06406084 | Acc: 0.94533762 | \n",
            "epoch total:  2177.0\n",
            "Epoch 242 | Loss: 0.06520966 | Acc: 0.96876435 | \n",
            "epoch total:  2177.0\n",
            "Epoch 243 | Loss: 0.06717734 | Acc: 0.92926045 | \n",
            "epoch total:  2177.0\n",
            "Epoch 244 | Loss: 0.06798059 | Acc: 0.97473588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 245 | Loss: 0.06411856 | Acc: 0.94671566 | \n",
            "epoch total:  2177.0\n",
            "Epoch 246 | Loss: 0.06500091 | Acc: 0.94166284 | \n",
            "epoch total:  2177.0\n",
            "Epoch 247 | Loss: 0.06651515 | Acc: 0.97243914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 248 | Loss: 0.06364883 | Acc: 0.95039045 | \n",
            "epoch total:  2177.0\n",
            "Epoch 249 | Loss: 0.06550771 | Acc: 0.93569132 | \n",
            "epoch total:  2177.0\n",
            "Epoch 250 | Loss: 0.06504359 | Acc: 0.96830501 | \n",
            "epoch total:  2177.0\n",
            "Epoch 251 | Loss: 0.06393757 | Acc: 0.96187414 | \n",
            "epoch total:  2177.0\n",
            "Epoch 252 | Loss: 0.06546097 | Acc: 0.93706936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 253 | Loss: 0.06361168 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 254 | Loss: 0.06481230 | Acc: 0.96784566 | \n",
            "epoch total:  2177.0\n",
            "Epoch 255 | Loss: 0.06382546 | Acc: 0.94579697 | \n",
            "epoch total:  2177.0\n",
            "Epoch 256 | Loss: 0.06422540 | Acc: 0.94395958 | \n",
            "epoch total:  2177.0\n",
            "Epoch 257 | Loss: 0.06408485 | Acc: 0.96463023 | \n",
            "epoch total:  2177.0\n",
            "Epoch 258 | Loss: 0.06386584 | Acc: 0.96325218 | \n",
            "epoch total:  2177.0\n",
            "Epoch 259 | Loss: 0.06413030 | Acc: 0.94487827 | \n",
            "epoch total:  2177.0\n",
            "Epoch 260 | Loss: 0.06363501 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 261 | Loss: 0.06407728 | Acc: 0.96279283 | \n",
            "epoch total:  2177.0\n",
            "Epoch 262 | Loss: 0.06355637 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 263 | Loss: 0.06400778 | Acc: 0.94579697 | \n",
            "epoch total:  2177.0\n",
            "Epoch 264 | Loss: 0.06351516 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 265 | Loss: 0.06389691 | Acc: 0.96187414 | \n",
            "epoch total:  2177.0\n",
            "Epoch 266 | Loss: 0.06350227 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 267 | Loss: 0.06381650 | Acc: 0.94671566 | \n",
            "epoch total:  2177.0\n",
            "Epoch 268 | Loss: 0.06350143 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 269 | Loss: 0.06372833 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 270 | Loss: 0.06349429 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 271 | Loss: 0.06366602 | Acc: 0.94809371 | \n",
            "epoch total:  2177.0\n",
            "Epoch 272 | Loss: 0.06349400 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 273 | Loss: 0.06360534 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 274 | Loss: 0.06348526 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 275 | Loss: 0.06355886 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 276 | Loss: 0.06348065 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 277 | Loss: 0.06351662 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 278 | Loss: 0.06347130 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 279 | Loss: 0.06348079 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 280 | Loss: 0.06346190 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 281 | Loss: 0.06345099 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 282 | Loss: 0.06345053 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 283 | Loss: 0.06342445 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 284 | Loss: 0.06343817 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 285 | Loss: 0.06340329 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 286 | Loss: 0.06342402 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 287 | Loss: 0.06338416 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 288 | Loss: 0.06340863 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 289 | Loss: 0.06336911 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 290 | Loss: 0.06339201 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 291 | Loss: 0.06335651 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 292 | Loss: 0.06337372 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 293 | Loss: 0.06334583 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 294 | Loss: 0.06335530 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 295 | Loss: 0.06333657 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 296 | Loss: 0.06333677 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 297 | Loss: 0.06332734 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 298 | Loss: 0.06331933 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 299 | Loss: 0.06331716 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 300 | Loss: 0.06330372 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 301 | Loss: 0.06330558 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 302 | Loss: 0.06329019 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 303 | Loss: 0.06329212 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 304 | Loss: 0.06327871 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 305 | Loss: 0.06327742 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 306 | Loss: 0.06326820 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 307 | Loss: 0.06326251 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 308 | Loss: 0.06325755 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 309 | Loss: 0.06324842 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 310 | Loss: 0.06324581 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 311 | Loss: 0.06323580 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 312 | Loss: 0.06323268 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 313 | Loss: 0.06322436 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 314 | Loss: 0.06321887 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 315 | Loss: 0.06321309 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 316 | Loss: 0.06320541 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 317 | Loss: 0.06320105 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 318 | Loss: 0.06319295 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 319 | Loss: 0.06318799 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 320 | Loss: 0.06318115 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 321 | Loss: 0.06317461 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 322 | Loss: 0.06316914 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 323 | Loss: 0.06316173 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 324 | Loss: 0.06315634 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 325 | Loss: 0.06314946 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 326 | Loss: 0.06314307 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 327 | Loss: 0.06313713 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 328 | Loss: 0.06313007 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 329 | Loss: 0.06312419 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 330 | Loss: 0.06311747 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 331 | Loss: 0.06311088 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 332 | Loss: 0.06310472 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 333 | Loss: 0.06309777 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 334 | Loss: 0.06309147 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 335 | Loss: 0.06308486 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 336 | Loss: 0.06307802 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 337 | Loss: 0.06307163 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 338 | Loss: 0.06306476 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 339 | Loss: 0.06305805 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 340 | Loss: 0.06305143 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 341 | Loss: 0.06304445 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 342 | Loss: 0.06303772 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 343 | Loss: 0.06303090 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 344 | Loss: 0.06302387 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 345 | Loss: 0.06301706 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 346 | Loss: 0.06301005 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 347 | Loss: 0.06300298 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 348 | Loss: 0.06299603 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 349 | Loss: 0.06298891 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 350 | Loss: 0.06298175 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 351 | Loss: 0.06297467 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 352 | Loss: 0.06296745 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 353 | Loss: 0.06296021 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 354 | Loss: 0.06295301 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 355 | Loss: 0.06294571 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 356 | Loss: 0.06293838 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 357 | Loss: 0.06293109 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 358 | Loss: 0.06292371 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 359 | Loss: 0.06291632 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 360 | Loss: 0.06290895 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 361 | Loss: 0.06290153 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 362 | Loss: 0.06289409 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 363 | Loss: 0.06288669 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 364 | Loss: 0.06287926 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 365 | Loss: 0.06287182 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 366 | Loss: 0.06286440 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 367 | Loss: 0.06285701 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 368 | Loss: 0.06284960 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 369 | Loss: 0.06284223 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 370 | Loss: 0.06283490 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 371 | Loss: 0.06282759 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 372 | Loss: 0.06282033 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 373 | Loss: 0.06281311 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 374 | Loss: 0.06280594 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 375 | Loss: 0.06279883 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 376 | Loss: 0.06279178 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 377 | Loss: 0.06278481 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 378 | Loss: 0.06277790 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 379 | Loss: 0.06277107 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 380 | Loss: 0.06276431 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 381 | Loss: 0.06275766 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 382 | Loss: 0.06275108 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 383 | Loss: 0.06274457 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 384 | Loss: 0.06273818 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 385 | Loss: 0.06273188 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 386 | Loss: 0.06272567 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 387 | Loss: 0.06271955 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 388 | Loss: 0.06271351 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 389 | Loss: 0.06270758 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 390 | Loss: 0.06270173 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 391 | Loss: 0.06269596 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 392 | Loss: 0.06269028 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 393 | Loss: 0.06268468 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 394 | Loss: 0.06267915 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 395 | Loss: 0.06267370 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 396 | Loss: 0.06266832 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 397 | Loss: 0.06266300 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 398 | Loss: 0.06265774 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 399 | Loss: 0.06265254 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 400 | Loss: 0.06264740 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 401 | Loss: 0.06264231 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 402 | Loss: 0.06263727 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 403 | Loss: 0.06263228 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 404 | Loss: 0.06262733 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 405 | Loss: 0.06262242 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 406 | Loss: 0.06261756 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 407 | Loss: 0.06261273 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 408 | Loss: 0.06260795 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 409 | Loss: 0.06260321 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 410 | Loss: 0.06259847 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 411 | Loss: 0.06259379 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 412 | Loss: 0.06258913 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 413 | Loss: 0.06258453 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 414 | Loss: 0.06257993 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 415 | Loss: 0.06257537 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 416 | Loss: 0.06257083 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 417 | Loss: 0.06256634 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 418 | Loss: 0.06256187 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 419 | Loss: 0.06255742 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 420 | Loss: 0.06255301 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 421 | Loss: 0.06254862 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 422 | Loss: 0.06254426 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 423 | Loss: 0.06253992 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 424 | Loss: 0.06253561 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 425 | Loss: 0.06253133 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 426 | Loss: 0.06252708 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 427 | Loss: 0.06252287 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 428 | Loss: 0.06251869 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 429 | Loss: 0.06251459 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 430 | Loss: 0.06251062 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 431 | Loss: 0.06250701 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 432 | Loss: 0.06250424 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 433 | Loss: 0.06250378 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 434 | Loss: 0.06250978 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 435 | Loss: 0.06253471 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 436 | Loss: 0.06261460 | Acc: 0.94993110 | \n",
            "epoch total:  2177.0\n",
            "Epoch 437 | Loss: 0.06286412 | Acc: 0.96095544 | \n",
            "epoch total:  2177.0\n",
            "Epoch 438 | Loss: 0.06357049 | Acc: 0.94120349 | \n",
            "epoch total:  2177.0\n",
            "Epoch 439 | Loss: 0.06549775 | Acc: 0.97060175 | \n",
            "epoch total:  2177.0\n",
            "Epoch 440 | Loss: 0.06828053 | Acc: 0.91731741 | \n",
            "epoch total:  2177.0\n",
            "Epoch 441 | Loss: 0.06958643 | Acc: 0.97749196 | \n",
            "epoch total:  2177.0\n",
            "Epoch 442 | Loss: 0.06373821 | Acc: 0.94304088 | \n",
            "epoch total:  2177.0\n",
            "Epoch 443 | Loss: 0.06426915 | Acc: 0.93706936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 444 | Loss: 0.06673112 | Acc: 0.97335783 | \n",
            "epoch total:  2177.0\n",
            "Epoch 445 | Loss: 0.06269711 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 446 | Loss: 0.06515466 | Acc: 0.93339458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 447 | Loss: 0.06433967 | Acc: 0.96692696 | \n",
            "epoch total:  2177.0\n",
            "Epoch 448 | Loss: 0.06324854 | Acc: 0.96279283 | \n",
            "epoch total:  2177.0\n",
            "Epoch 449 | Loss: 0.06484257 | Acc: 0.93339458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 450 | Loss: 0.06258094 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 451 | Loss: 0.06423965 | Acc: 0.96876435 | \n",
            "epoch total:  2177.0\n",
            "Epoch 452 | Loss: 0.06258827 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 453 | Loss: 0.06390259 | Acc: 0.94074414 | \n",
            "epoch total:  2177.0\n",
            "Epoch 454 | Loss: 0.06263749 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 455 | Loss: 0.06352834 | Acc: 0.96417088 | \n",
            "epoch total:  2177.0\n",
            "Epoch 456 | Loss: 0.06258412 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 457 | Loss: 0.06336761 | Acc: 0.94166284 | \n",
            "epoch total:  2177.0\n",
            "Epoch 458 | Loss: 0.06258312 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 459 | Loss: 0.06317572 | Acc: 0.96325218 | \n",
            "epoch total:  2177.0\n",
            "Epoch 460 | Loss: 0.06254558 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 461 | Loss: 0.06306060 | Acc: 0.94395958 | \n",
            "epoch total:  2177.0\n",
            "Epoch 462 | Loss: 0.06254558 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 463 | Loss: 0.06292822 | Acc: 0.96187414 | \n",
            "epoch total:  2177.0\n",
            "Epoch 464 | Loss: 0.06255573 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 465 | Loss: 0.06282498 | Acc: 0.94625632 | \n",
            "epoch total:  2177.0\n",
            "Epoch 466 | Loss: 0.06256630 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 467 | Loss: 0.06271844 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 468 | Loss: 0.06260009 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 469 | Loss: 0.06262423 | Acc: 0.94993110 | \n",
            "epoch total:  2177.0\n",
            "Epoch 470 | Loss: 0.06261593 | Acc: 0.94993110 | \n",
            "epoch total:  2177.0\n",
            "Epoch 471 | Loss: 0.06255985 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 472 | Loss: 0.06262043 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 473 | Loss: 0.06251263 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 474 | Loss: 0.06260809 | Acc: 0.94993110 | \n",
            "epoch total:  2177.0\n",
            "Epoch 475 | Loss: 0.06249159 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 476 | Loss: 0.06258250 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 477 | Loss: 0.06248236 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 478 | Loss: 0.06255388 | Acc: 0.95039045 | \n",
            "epoch total:  2177.0\n",
            "Epoch 479 | Loss: 0.06247859 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 480 | Loss: 0.06252403 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 481 | Loss: 0.06247929 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 482 | Loss: 0.06249560 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 483 | Loss: 0.06247825 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 484 | Loss: 0.06247254 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 485 | Loss: 0.06247452 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 486 | Loss: 0.06245403 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 487 | Loss: 0.06246719 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 488 | Loss: 0.06244073 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 489 | Loss: 0.06245775 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 490 | Loss: 0.06243058 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 491 | Loss: 0.06244674 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 492 | Loss: 0.06242184 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 493 | Loss: 0.06243568 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 494 | Loss: 0.06241426 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 495 | Loss: 0.06242474 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 496 | Loss: 0.06240707 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 497 | Loss: 0.06241398 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 498 | Loss: 0.06240001 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 499 | Loss: 0.06240412 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 500 | Loss: 0.06239289 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 501 | Loss: 0.06239474 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 502 | Loss: 0.06238556 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 503 | Loss: 0.06238613 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 504 | Loss: 0.06237817 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 505 | Loss: 0.06237782 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 506 | Loss: 0.06237077 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 507 | Loss: 0.06236983 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 508 | Loss: 0.06236345 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 509 | Loss: 0.06236209 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 510 | Loss: 0.06235617 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 511 | Loss: 0.06235456 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 512 | Loss: 0.06234892 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 513 | Loss: 0.06234717 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 514 | Loss: 0.06234175 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 515 | Loss: 0.06233989 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 516 | Loss: 0.06233463 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 517 | Loss: 0.06233267 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 518 | Loss: 0.06232765 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 519 | Loss: 0.06232547 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 520 | Loss: 0.06232074 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 521 | Loss: 0.06231833 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 522 | Loss: 0.06231392 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 523 | Loss: 0.06231123 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 524 | Loss: 0.06230717 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 525 | Loss: 0.06230417 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 526 | Loss: 0.06230047 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 527 | Loss: 0.06229718 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 528 | Loss: 0.06229379 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 529 | Loss: 0.06229027 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 530 | Loss: 0.06228711 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 531 | Loss: 0.06228345 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 532 | Loss: 0.06228041 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 533 | Loss: 0.06227672 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 534 | Loss: 0.06227370 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 535 | Loss: 0.06227012 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 536 | Loss: 0.06226697 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 537 | Loss: 0.06226355 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 538 | Loss: 0.06226026 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 539 | Loss: 0.06225701 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 540 | Loss: 0.06225362 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 541 | Loss: 0.06225047 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 542 | Loss: 0.06224706 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 543 | Loss: 0.06224391 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 544 | Loss: 0.06224057 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 545 | Loss: 0.06223736 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 546 | Loss: 0.06223412 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 547 | Loss: 0.06223084 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 548 | Loss: 0.06222767 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 549 | Loss: 0.06222439 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 550 | Loss: 0.06222123 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 551 | Loss: 0.06221799 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 552 | Loss: 0.06221480 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 553 | Loss: 0.06221163 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 554 | Loss: 0.06220841 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 555 | Loss: 0.06220527 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 556 | Loss: 0.06220207 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 557 | Loss: 0.06219893 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 558 | Loss: 0.06219579 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 559 | Loss: 0.06219262 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 560 | Loss: 0.06218950 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 561 | Loss: 0.06218636 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 562 | Loss: 0.06218323 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 563 | Loss: 0.06218012 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 564 | Loss: 0.06217699 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 565 | Loss: 0.06217390 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 566 | Loss: 0.06217080 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 567 | Loss: 0.06216771 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 568 | Loss: 0.06216463 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 569 | Loss: 0.06216155 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 570 | Loss: 0.06215849 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 571 | Loss: 0.06215542 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 572 | Loss: 0.06215236 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 573 | Loss: 0.06214932 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 574 | Loss: 0.06214628 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 575 | Loss: 0.06214324 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 576 | Loss: 0.06214022 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 577 | Loss: 0.06213719 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 578 | Loss: 0.06213417 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 579 | Loss: 0.06213117 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 580 | Loss: 0.06212817 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 581 | Loss: 0.06212516 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 582 | Loss: 0.06212217 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 583 | Loss: 0.06211920 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 584 | Loss: 0.06211622 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 585 | Loss: 0.06211324 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 586 | Loss: 0.06211028 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 587 | Loss: 0.06210732 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 588 | Loss: 0.06210437 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 589 | Loss: 0.06210142 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 590 | Loss: 0.06209848 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 591 | Loss: 0.06209554 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 592 | Loss: 0.06209261 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 593 | Loss: 0.06208969 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 594 | Loss: 0.06208677 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 595 | Loss: 0.06208386 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 596 | Loss: 0.06208095 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 597 | Loss: 0.06207805 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 598 | Loss: 0.06207515 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 599 | Loss: 0.06207226 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 600 | Loss: 0.06206936 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 601 | Loss: 0.06206650 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 602 | Loss: 0.06206362 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 603 | Loss: 0.06206074 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 604 | Loss: 0.06205788 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 605 | Loss: 0.06205501 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 606 | Loss: 0.06205215 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 607 | Loss: 0.06204931 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 608 | Loss: 0.06204646 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 609 | Loss: 0.06204361 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 610 | Loss: 0.06204077 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 611 | Loss: 0.06203795 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 612 | Loss: 0.06203511 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 613 | Loss: 0.06203228 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 614 | Loss: 0.06202947 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 615 | Loss: 0.06202665 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 616 | Loss: 0.06202383 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 617 | Loss: 0.06202103 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 618 | Loss: 0.06201822 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 619 | Loss: 0.06201541 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 620 | Loss: 0.06201262 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 621 | Loss: 0.06200983 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 622 | Loss: 0.06200704 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 623 | Loss: 0.06200425 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 624 | Loss: 0.06200146 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 625 | Loss: 0.06199868 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 626 | Loss: 0.06199590 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 627 | Loss: 0.06199313 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 628 | Loss: 0.06199036 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 629 | Loss: 0.06198759 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 630 | Loss: 0.06198483 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 631 | Loss: 0.06198207 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 632 | Loss: 0.06197931 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 633 | Loss: 0.06197655 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 634 | Loss: 0.06197380 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 635 | Loss: 0.06197105 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 636 | Loss: 0.06196831 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 637 | Loss: 0.06196556 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 638 | Loss: 0.06196282 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 639 | Loss: 0.06196009 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 640 | Loss: 0.06195734 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 641 | Loss: 0.06195462 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 642 | Loss: 0.06195188 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 643 | Loss: 0.06194916 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 644 | Loss: 0.06194642 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 645 | Loss: 0.06194370 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 646 | Loss: 0.06194098 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 647 | Loss: 0.06193826 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 648 | Loss: 0.06193554 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 649 | Loss: 0.06193282 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 650 | Loss: 0.06193011 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 651 | Loss: 0.06192740 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 652 | Loss: 0.06192469 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 653 | Loss: 0.06192199 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 654 | Loss: 0.06191928 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 655 | Loss: 0.06191658 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 656 | Loss: 0.06191388 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 657 | Loss: 0.06191118 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 658 | Loss: 0.06190849 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 659 | Loss: 0.06190581 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 660 | Loss: 0.06190315 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 661 | Loss: 0.06190056 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 662 | Loss: 0.06189814 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 663 | Loss: 0.06189625 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 664 | Loss: 0.06189590 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 665 | Loss: 0.06190039 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 666 | Loss: 0.06192028 | Acc: 0.95039045 | \n",
            "epoch total:  2177.0\n",
            "Epoch 667 | Loss: 0.06199120 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 668 | Loss: 0.06222793 | Acc: 0.94533762 | \n",
            "epoch total:  2177.0\n",
            "Epoch 669 | Loss: 0.06302822 | Acc: 0.96371153 | \n",
            "epoch total:  2177.0\n",
            "Epoch 670 | Loss: 0.06531477 | Acc: 0.93109784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 671 | Loss: 0.07065956 | Acc: 0.97795131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 672 | Loss: 0.07139023 | Acc: 0.90767111 | \n",
            "epoch total:  2177.0\n",
            "Epoch 673 | Loss: 0.06476927 | Acc: 0.97060175 | \n",
            "epoch total:  2177.0\n",
            "Epoch 674 | Loss: 0.06408709 | Acc: 0.96784566 | \n",
            "epoch total:  2177.0\n",
            "Epoch 675 | Loss: 0.06705377 | Acc: 0.92282958 | \n",
            "epoch total:  2177.0\n",
            "Epoch 676 | Loss: 0.06247216 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 677 | Loss: 0.06491907 | Acc: 0.96876435 | \n",
            "epoch total:  2177.0\n",
            "Epoch 678 | Loss: 0.06288997 | Acc: 0.94395958 | \n",
            "epoch total:  2177.0\n",
            "Epoch 679 | Loss: 0.06367155 | Acc: 0.93523197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 680 | Loss: 0.06318879 | Acc: 0.96141479 | \n",
            "epoch total:  2177.0\n",
            "Epoch 681 | Loss: 0.06315806 | Acc: 0.96187414 | \n",
            "epoch total:  2177.0\n",
            "Epoch 682 | Loss: 0.06304439 | Acc: 0.94487827 | \n",
            "epoch total:  2177.0\n",
            "Epoch 683 | Loss: 0.06285974 | Acc: 0.94487827 | \n",
            "epoch total:  2177.0\n",
            "Epoch 684 | Loss: 0.06280904 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 685 | Loss: 0.06267573 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 686 | Loss: 0.06275333 | Acc: 0.94993110 | \n",
            "epoch total:  2177.0\n",
            "Epoch 687 | Loss: 0.06244195 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 688 | Loss: 0.06267714 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 689 | Loss: 0.06230376 | Acc: 0.94993110 | \n",
            "epoch total:  2177.0\n",
            "Epoch 690 | Loss: 0.06257067 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 691 | Loss: 0.06225044 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 692 | Loss: 0.06239829 | Acc: 0.94993110 | \n",
            "epoch total:  2177.0\n",
            "Epoch 693 | Loss: 0.06231964 | Acc: 0.94533762 | \n",
            "epoch total:  2177.0\n",
            "Epoch 694 | Loss: 0.06218666 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 695 | Loss: 0.06234038 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 696 | Loss: 0.06210016 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 697 | Loss: 0.06228653 | Acc: 0.94579697 | \n",
            "epoch total:  2177.0\n",
            "Epoch 698 | Loss: 0.06209609 | Acc: 0.94947175 | \n",
            "epoch total:  2177.0\n",
            "Epoch 699 | Loss: 0.06218259 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 700 | Loss: 0.06211995 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 701 | Loss: 0.06209135 | Acc: 0.94855305 | \n",
            "epoch total:  2177.0\n",
            "Epoch 702 | Loss: 0.06211877 | Acc: 0.94855305 | \n",
            "epoch total:  2177.0\n",
            "Epoch 703 | Loss: 0.06205237 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 704 | Loss: 0.06208998 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 705 | Loss: 0.06204149 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 706 | Loss: 0.06204068 | Acc: 0.94901240 | \n",
            "epoch total:  2177.0\n",
            "Epoch 707 | Loss: 0.06204250 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 708 | Loss: 0.06200544 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 709 | Loss: 0.06203059 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 710 | Loss: 0.06199026 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 711 | Loss: 0.06200568 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 712 | Loss: 0.06198396 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 713 | Loss: 0.06197827 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 714 | Loss: 0.06198352 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 715 | Loss: 0.06195429 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 716 | Loss: 0.06197786 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 717 | Loss: 0.06194056 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 718 | Loss: 0.06196351 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 719 | Loss: 0.06193518 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 720 | Loss: 0.06194551 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 721 | Loss: 0.06193206 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 722 | Loss: 0.06193007 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 723 | Loss: 0.06192746 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 724 | Loss: 0.06191806 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 725 | Loss: 0.06191942 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 726 | Loss: 0.06190934 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 727 | Loss: 0.06191023 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 728 | Loss: 0.06190289 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 729 | Loss: 0.06190071 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 730 | Loss: 0.06189615 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 731 | Loss: 0.06189228 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 732 | Loss: 0.06188907 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 733 | Loss: 0.06188483 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 734 | Loss: 0.06188188 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 735 | Loss: 0.06187768 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 736 | Loss: 0.06187508 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 737 | Loss: 0.06187056 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 738 | Loss: 0.06186850 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 739 | Loss: 0.06186371 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 740 | Loss: 0.06186196 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 741 | Loss: 0.06185741 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 742 | Loss: 0.06185532 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 743 | Loss: 0.06185120 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 744 | Loss: 0.06184862 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 745 | Loss: 0.06184535 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 746 | Loss: 0.06184210 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 747 | Loss: 0.06183955 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 748 | Loss: 0.06183575 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 749 | Loss: 0.06183353 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 750 | Loss: 0.06182978 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 751 | Loss: 0.06182756 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 752 | Loss: 0.06182402 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 753 | Loss: 0.06182157 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 754 | Loss: 0.06181831 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 755 | Loss: 0.06181568 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 756 | Loss: 0.06181270 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 757 | Loss: 0.06180993 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 758 | Loss: 0.06180712 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 759 | Loss: 0.06180428 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 760 | Loss: 0.06180156 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 761 | Loss: 0.06179877 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 762 | Loss: 0.06179604 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 763 | Loss: 0.06179332 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 764 | Loss: 0.06179056 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 765 | Loss: 0.06178794 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 766 | Loss: 0.06178516 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 767 | Loss: 0.06178261 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 768 | Loss: 0.06177983 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 769 | Loss: 0.06177731 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 770 | Loss: 0.06177459 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 771 | Loss: 0.06177205 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 772 | Loss: 0.06176943 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 773 | Loss: 0.06176684 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 774 | Loss: 0.06176430 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 775 | Loss: 0.06176173 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 776 | Loss: 0.06175920 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 777 | Loss: 0.06175667 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 778 | Loss: 0.06175414 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 779 | Loss: 0.06175168 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 780 | Loss: 0.06174915 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 781 | Loss: 0.06174671 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 782 | Loss: 0.06174424 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 783 | Loss: 0.06174176 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 784 | Loss: 0.06173937 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 785 | Loss: 0.06173691 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 786 | Loss: 0.06173451 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 787 | Loss: 0.06173211 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 788 | Loss: 0.06172972 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 789 | Loss: 0.06172734 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 790 | Loss: 0.06172498 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 791 | Loss: 0.06172262 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 792 | Loss: 0.06172029 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 793 | Loss: 0.06171795 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 794 | Loss: 0.06171564 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 795 | Loss: 0.06171333 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 796 | Loss: 0.06171103 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 797 | Loss: 0.06170875 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 798 | Loss: 0.06170648 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 799 | Loss: 0.06170421 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 800 | Loss: 0.06170196 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 801 | Loss: 0.06169971 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 802 | Loss: 0.06169749 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 803 | Loss: 0.06169527 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 804 | Loss: 0.06169306 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 805 | Loss: 0.06169086 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 806 | Loss: 0.06168867 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 807 | Loss: 0.06168650 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 808 | Loss: 0.06168434 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 809 | Loss: 0.06168217 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 810 | Loss: 0.06168003 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 811 | Loss: 0.06167788 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 812 | Loss: 0.06167576 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 813 | Loss: 0.06167365 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 814 | Loss: 0.06167154 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 815 | Loss: 0.06166944 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 816 | Loss: 0.06166736 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 817 | Loss: 0.06166527 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 818 | Loss: 0.06166321 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 819 | Loss: 0.06166115 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 820 | Loss: 0.06165911 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 821 | Loss: 0.06165707 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 822 | Loss: 0.06165503 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 823 | Loss: 0.06165301 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 824 | Loss: 0.06165100 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 825 | Loss: 0.06164898 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 826 | Loss: 0.06164699 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 827 | Loss: 0.06164501 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 828 | Loss: 0.06164303 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 829 | Loss: 0.06164106 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 830 | Loss: 0.06163910 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 831 | Loss: 0.06163715 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 832 | Loss: 0.06163521 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 833 | Loss: 0.06163329 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 834 | Loss: 0.06163135 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 835 | Loss: 0.06162943 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 836 | Loss: 0.06162751 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 837 | Loss: 0.06162562 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 838 | Loss: 0.06162372 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 839 | Loss: 0.06162184 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 840 | Loss: 0.06161997 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 841 | Loss: 0.06161809 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 842 | Loss: 0.06161624 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 843 | Loss: 0.06161437 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 844 | Loss: 0.06161252 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 845 | Loss: 0.06161069 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 846 | Loss: 0.06160886 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 847 | Loss: 0.06160703 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 848 | Loss: 0.06160520 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 849 | Loss: 0.06160340 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 850 | Loss: 0.06160159 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 851 | Loss: 0.06159979 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 852 | Loss: 0.06159800 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 853 | Loss: 0.06159622 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 854 | Loss: 0.06159444 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 855 | Loss: 0.06159267 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 856 | Loss: 0.06159091 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 857 | Loss: 0.06158915 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 858 | Loss: 0.06158740 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 859 | Loss: 0.06158566 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 860 | Loss: 0.06158392 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 861 | Loss: 0.06158219 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 862 | Loss: 0.06158046 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 863 | Loss: 0.06157874 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 864 | Loss: 0.06157702 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 865 | Loss: 0.06157532 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 866 | Loss: 0.06157362 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 867 | Loss: 0.06157193 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 868 | Loss: 0.06157023 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 869 | Loss: 0.06156855 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 870 | Loss: 0.06156687 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 871 | Loss: 0.06156520 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 872 | Loss: 0.06156353 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 873 | Loss: 0.06156187 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 874 | Loss: 0.06156022 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 875 | Loss: 0.06155858 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 876 | Loss: 0.06155696 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 877 | Loss: 0.06155540 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 878 | Loss: 0.06155398 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 879 | Loss: 0.06155298 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 880 | Loss: 0.06155325 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 881 | Loss: 0.06155745 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 882 | Loss: 0.06157421 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 883 | Loss: 0.06163183 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 884 | Loss: 0.06182804 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 885 | Loss: 0.06246834 | Acc: 0.94212219 | \n",
            "epoch total:  2177.0\n",
            "Epoch 886 | Loss: 0.06455868 | Acc: 0.97152044 | \n",
            "epoch total:  2177.0\n",
            "Epoch 887 | Loss: 0.06932922 | Acc: 0.92099219 | \n",
            "epoch total:  2177.0\n",
            "Epoch 888 | Loss: 0.07559235 | Acc: 0.98024805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 889 | Loss: 0.06640310 | Acc: 0.92834175 | \n",
            "epoch total:  2177.0\n",
            "Epoch 890 | Loss: 0.06362146 | Acc: 0.93982545 | \n",
            "epoch total:  2177.0\n",
            "Epoch 891 | Loss: 0.06747214 | Acc: 0.97289848 | \n",
            "epoch total:  2177.0\n",
            "Epoch 892 | Loss: 0.06207410 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 893 | Loss: 0.06613651 | Acc: 0.92834175 | \n",
            "epoch total:  2177.0\n",
            "Epoch 894 | Loss: 0.06270608 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 895 | Loss: 0.06436273 | Acc: 0.96646762 | \n",
            "epoch total:  2177.0\n",
            "Epoch 896 | Loss: 0.06306915 | Acc: 0.94487827 | \n",
            "epoch total:  2177.0\n",
            "Epoch 897 | Loss: 0.06329600 | Acc: 0.94395958 | \n",
            "epoch total:  2177.0\n",
            "Epoch 898 | Loss: 0.06319639 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 899 | Loss: 0.06279346 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 900 | Loss: 0.06304146 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 901 | Loss: 0.06274595 | Acc: 0.96003675 | \n",
            "epoch total:  2177.0\n",
            "Epoch 902 | Loss: 0.06247467 | Acc: 0.94855305 | \n",
            "epoch total:  2177.0\n",
            "Epoch 903 | Loss: 0.06286862 | Acc: 0.94671566 | \n",
            "epoch total:  2177.0\n",
            "Epoch 904 | Loss: 0.06217029 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 905 | Loss: 0.06271024 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 906 | Loss: 0.06220471 | Acc: 0.95039045 | \n",
            "epoch total:  2177.0\n",
            "Epoch 907 | Loss: 0.06231252 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 908 | Loss: 0.06230250 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 909 | Loss: 0.06211721 | Acc: 0.94763436 | \n",
            "epoch total:  2177.0\n",
            "Epoch 910 | Loss: 0.06215193 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 911 | Loss: 0.06215738 | Acc: 0.96003675 | \n",
            "epoch total:  2177.0\n",
            "Epoch 912 | Loss: 0.06195733 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 913 | Loss: 0.06214959 | Acc: 0.94625632 | \n",
            "epoch total:  2177.0\n",
            "Epoch 914 | Loss: 0.06195443 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 915 | Loss: 0.06195845 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 916 | Loss: 0.06203659 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 917 | Loss: 0.06181817 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 918 | Loss: 0.06202640 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 919 | Loss: 0.06182493 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 920 | Loss: 0.06190734 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 921 | Loss: 0.06187726 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 922 | Loss: 0.06182682 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 923 | Loss: 0.06186048 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 924 | Loss: 0.06182118 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 925 | Loss: 0.06181501 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 926 | Loss: 0.06180182 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 927 | Loss: 0.06180813 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 928 | Loss: 0.06176023 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 929 | Loss: 0.06180524 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 930 | Loss: 0.06173482 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 931 | Loss: 0.06177547 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 932 | Loss: 0.06174467 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 933 | Loss: 0.06173313 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 934 | Loss: 0.06174579 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 935 | Loss: 0.06171435 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 936 | Loss: 0.06172810 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 937 | Loss: 0.06171088 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 938 | Loss: 0.06170895 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 939 | Loss: 0.06170239 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 940 | Loss: 0.06169794 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 941 | Loss: 0.06168949 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 942 | Loss: 0.06169114 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 943 | Loss: 0.06167741 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 944 | Loss: 0.06168179 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 945 | Loss: 0.06166977 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 946 | Loss: 0.06167068 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 947 | Loss: 0.06166439 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 948 | Loss: 0.06165969 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 949 | Loss: 0.06165837 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 950 | Loss: 0.06165048 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 951 | Loss: 0.06165076 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 952 | Loss: 0.06164418 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 953 | Loss: 0.06164200 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 954 | Loss: 0.06163830 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 955 | Loss: 0.06163397 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 956 | Loss: 0.06163152 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 957 | Loss: 0.06162770 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 958 | Loss: 0.06162414 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 959 | Loss: 0.06162191 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 960 | Loss: 0.06161721 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 961 | Loss: 0.06161554 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 962 | Loss: 0.06161132 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 963 | Loss: 0.06160898 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 964 | Loss: 0.06160564 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 965 | Loss: 0.06160278 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 966 | Loss: 0.06159985 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 967 | Loss: 0.06159693 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 968 | Loss: 0.06159413 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 969 | Loss: 0.06159139 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 970 | Loss: 0.06158843 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 971 | Loss: 0.06158592 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 972 | Loss: 0.06158289 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 973 | Loss: 0.06158067 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 974 | Loss: 0.06157747 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 975 | Loss: 0.06157536 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 976 | Loss: 0.06157228 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 977 | Loss: 0.06157005 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 978 | Loss: 0.06156731 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 979 | Loss: 0.06156479 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 980 | Loss: 0.06156239 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 981 | Loss: 0.06155971 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 982 | Loss: 0.06155746 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 983 | Loss: 0.06155484 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 984 | Loss: 0.06155254 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 985 | Loss: 0.06155006 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 986 | Loss: 0.06154772 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 987 | Loss: 0.06154535 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 988 | Loss: 0.06154299 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 989 | Loss: 0.06154067 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 990 | Loss: 0.06153837 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 991 | Loss: 0.06153610 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 992 | Loss: 0.06153382 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 993 | Loss: 0.06153154 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 994 | Loss: 0.06152931 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 995 | Loss: 0.06152708 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 996 | Loss: 0.06152489 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 997 | Loss: 0.06152270 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 998 | Loss: 0.06152052 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 999 | Loss: 0.06151837 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1000 | Loss: 0.06151622 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1001 | Loss: 0.06151410 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1002 | Loss: 0.06151196 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1003 | Loss: 0.06150987 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1004 | Loss: 0.06150778 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1005 | Loss: 0.06150572 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1006 | Loss: 0.06150365 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1007 | Loss: 0.06150160 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1008 | Loss: 0.06149957 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1009 | Loss: 0.06149755 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1010 | Loss: 0.06149555 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1011 | Loss: 0.06149355 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1012 | Loss: 0.06149157 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1013 | Loss: 0.06148960 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1014 | Loss: 0.06148763 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1015 | Loss: 0.06148569 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1016 | Loss: 0.06148376 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1017 | Loss: 0.06148183 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1018 | Loss: 0.06147993 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1019 | Loss: 0.06147803 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1020 | Loss: 0.06147614 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1021 | Loss: 0.06147426 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1022 | Loss: 0.06147240 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1023 | Loss: 0.06147054 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1024 | Loss: 0.06146870 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1025 | Loss: 0.06146686 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1026 | Loss: 0.06146504 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1027 | Loss: 0.06146322 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1028 | Loss: 0.06146142 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1029 | Loss: 0.06145962 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1030 | Loss: 0.06145785 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1031 | Loss: 0.06145607 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1032 | Loss: 0.06145431 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1033 | Loss: 0.06145255 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1034 | Loss: 0.06145081 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1035 | Loss: 0.06144907 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1036 | Loss: 0.06144735 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1037 | Loss: 0.06144562 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1038 | Loss: 0.06144392 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1039 | Loss: 0.06144222 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1040 | Loss: 0.06144053 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1041 | Loss: 0.06143885 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1042 | Loss: 0.06143718 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1043 | Loss: 0.06143552 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1044 | Loss: 0.06143386 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1045 | Loss: 0.06143221 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1046 | Loss: 0.06143058 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1047 | Loss: 0.06142894 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1048 | Loss: 0.06142731 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1049 | Loss: 0.06142570 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1050 | Loss: 0.06142410 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1051 | Loss: 0.06142249 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1052 | Loss: 0.06142090 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1053 | Loss: 0.06141932 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1054 | Loss: 0.06141775 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1055 | Loss: 0.06141617 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1056 | Loss: 0.06141461 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1057 | Loss: 0.06141306 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1058 | Loss: 0.06141151 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1059 | Loss: 0.06140997 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1060 | Loss: 0.06140843 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1061 | Loss: 0.06140690 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1062 | Loss: 0.06140539 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1063 | Loss: 0.06140388 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1064 | Loss: 0.06140237 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1065 | Loss: 0.06140087 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1066 | Loss: 0.06139938 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1067 | Loss: 0.06139789 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1068 | Loss: 0.06139641 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1069 | Loss: 0.06139494 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1070 | Loss: 0.06139347 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1071 | Loss: 0.06139201 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1072 | Loss: 0.06139056 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1073 | Loss: 0.06138911 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1074 | Loss: 0.06138767 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1075 | Loss: 0.06138624 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1076 | Loss: 0.06138480 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1077 | Loss: 0.06138337 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1078 | Loss: 0.06138195 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1079 | Loss: 0.06138055 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1080 | Loss: 0.06137914 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1081 | Loss: 0.06137773 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1082 | Loss: 0.06137634 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1083 | Loss: 0.06137495 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1084 | Loss: 0.06137356 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1085 | Loss: 0.06137218 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1086 | Loss: 0.06137081 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1087 | Loss: 0.06136944 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1088 | Loss: 0.06136808 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1089 | Loss: 0.06136671 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1090 | Loss: 0.06136537 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1091 | Loss: 0.06136402 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1092 | Loss: 0.06136267 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1093 | Loss: 0.06136133 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1094 | Loss: 0.06136000 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1095 | Loss: 0.06135868 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1096 | Loss: 0.06135735 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1097 | Loss: 0.06135603 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1098 | Loss: 0.06135472 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1099 | Loss: 0.06135341 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1100 | Loss: 0.06135210 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1101 | Loss: 0.06135080 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1102 | Loss: 0.06134951 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1103 | Loss: 0.06134821 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1104 | Loss: 0.06134693 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1105 | Loss: 0.06134564 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1106 | Loss: 0.06134436 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1107 | Loss: 0.06134309 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1108 | Loss: 0.06134183 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1109 | Loss: 0.06134056 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1110 | Loss: 0.06133930 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1111 | Loss: 0.06133805 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1112 | Loss: 0.06133679 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1113 | Loss: 0.06133554 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1114 | Loss: 0.06133430 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1115 | Loss: 0.06133306 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1116 | Loss: 0.06133182 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1117 | Loss: 0.06133058 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1118 | Loss: 0.06132936 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1119 | Loss: 0.06132813 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1120 | Loss: 0.06132691 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1121 | Loss: 0.06132569 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1122 | Loss: 0.06132448 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1123 | Loss: 0.06132327 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1124 | Loss: 0.06132207 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1125 | Loss: 0.06132086 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1126 | Loss: 0.06131967 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1127 | Loss: 0.06131848 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1128 | Loss: 0.06131731 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1129 | Loss: 0.06131617 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1130 | Loss: 0.06131512 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1131 | Loss: 0.06131429 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1132 | Loss: 0.06131415 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1133 | Loss: 0.06131593 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1134 | Loss: 0.06132358 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1135 | Loss: 0.06134881 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1136 | Loss: 0.06143083 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1137 | Loss: 0.06168337 | Acc: 0.94809371 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1138 | Loss: 0.06251953 | Acc: 0.96830501 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1139 | Loss: 0.06479432 | Acc: 0.93155719 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1140 | Loss: 0.07138872 | Acc: 0.98116674 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1141 | Loss: 0.07501251 | Acc: 0.90307763 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1142 | Loss: 0.07245721 | Acc: 0.98162609 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1143 | Loss: 0.06238539 | Acc: 0.96325218 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1144 | Loss: 0.07257171 | Acc: 0.91272393 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1145 | Loss: 0.06623243 | Acc: 0.97335783 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1146 | Loss: 0.06709317 | Acc: 0.97381718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1147 | Loss: 0.06530809 | Acc: 0.92926045 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1148 | Loss: 0.06585318 | Acc: 0.93385393 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1149 | Loss: 0.06312432 | Acc: 0.96600827 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1150 | Loss: 0.06555766 | Acc: 0.96508957 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1151 | Loss: 0.06262232 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1152 | Loss: 0.06464426 | Acc: 0.94350023 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1153 | Loss: 0.06309418 | Acc: 0.94487827 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1154 | Loss: 0.06323172 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1155 | Loss: 0.06318288 | Acc: 0.96646762 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1156 | Loss: 0.06305815 | Acc: 0.96095544 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1157 | Loss: 0.06254216 | Acc: 0.94947175 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1158 | Loss: 0.06312218 | Acc: 0.94809371 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1159 | Loss: 0.06227069 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1160 | Loss: 0.06266230 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1161 | Loss: 0.06246248 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1162 | Loss: 0.06220305 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1163 | Loss: 0.06242073 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1164 | Loss: 0.06208569 | Acc: 0.94855305 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1165 | Loss: 0.06220809 | Acc: 0.95222784 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1166 | Loss: 0.06203298 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1167 | Loss: 0.06210556 | Acc: 0.96095544 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1168 | Loss: 0.06190069 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1169 | Loss: 0.06201527 | Acc: 0.95084979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1170 | Loss: 0.06189920 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1171 | Loss: 0.06185005 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1172 | Loss: 0.06190900 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1173 | Loss: 0.06177756 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1174 | Loss: 0.06183609 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1175 | Loss: 0.06175378 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1176 | Loss: 0.06179905 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1177 | Loss: 0.06170782 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1178 | Loss: 0.06175292 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1179 | Loss: 0.06169864 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1180 | Loss: 0.06169180 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1181 | Loss: 0.06169866 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1182 | Loss: 0.06165216 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1183 | Loss: 0.06166264 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1184 | Loss: 0.06165144 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1185 | Loss: 0.06161411 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1186 | Loss: 0.06163934 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1187 | Loss: 0.06160143 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1188 | Loss: 0.06160556 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1189 | Loss: 0.06159037 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1190 | Loss: 0.06158644 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1191 | Loss: 0.06157861 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1192 | Loss: 0.06156528 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1193 | Loss: 0.06156863 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1194 | Loss: 0.06155103 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1195 | Loss: 0.06155011 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1196 | Loss: 0.06154668 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1197 | Loss: 0.06153176 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1198 | Loss: 0.06153610 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1199 | Loss: 0.06152441 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1200 | Loss: 0.06151992 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1201 | Loss: 0.06151787 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1202 | Loss: 0.06150939 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1203 | Loss: 0.06150758 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1204 | Loss: 0.06150080 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1205 | Loss: 0.06149751 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1206 | Loss: 0.06149355 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1207 | Loss: 0.06148818 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1208 | Loss: 0.06148515 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1209 | Loss: 0.06148083 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1210 | Loss: 0.06147669 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1211 | Loss: 0.06147369 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1212 | Loss: 0.06146948 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1213 | Loss: 0.06146634 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1214 | Loss: 0.06146243 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1215 | Loss: 0.06145973 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1216 | Loss: 0.06145567 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1217 | Loss: 0.06145291 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1218 | Loss: 0.06144971 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1219 | Loss: 0.06144622 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1220 | Loss: 0.06144390 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1221 | Loss: 0.06144034 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1222 | Loss: 0.06143750 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1223 | Loss: 0.06143501 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1224 | Loss: 0.06143144 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1225 | Loss: 0.06142953 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1226 | Loss: 0.06142626 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1227 | Loss: 0.06142356 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1228 | Loss: 0.06142131 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1229 | Loss: 0.06141819 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1230 | Loss: 0.06141602 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1231 | Loss: 0.06141339 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1232 | Loss: 0.06141073 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1233 | Loss: 0.06140848 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1234 | Loss: 0.06140595 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1235 | Loss: 0.06140357 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1236 | Loss: 0.06140126 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1237 | Loss: 0.06139881 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1238 | Loss: 0.06139660 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1239 | Loss: 0.06139425 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1240 | Loss: 0.06139207 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1241 | Loss: 0.06138981 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1242 | Loss: 0.06138759 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1243 | Loss: 0.06138542 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1244 | Loss: 0.06138328 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1245 | Loss: 0.06138112 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1246 | Loss: 0.06137906 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1247 | Loss: 0.06137692 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1248 | Loss: 0.06137490 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1249 | Loss: 0.06137285 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1250 | Loss: 0.06137082 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1251 | Loss: 0.06136884 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1252 | Loss: 0.06136683 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1253 | Loss: 0.06136488 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1254 | Loss: 0.06136296 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1255 | Loss: 0.06136100 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1256 | Loss: 0.06135911 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1257 | Loss: 0.06135721 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1258 | Loss: 0.06135534 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1259 | Loss: 0.06135349 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1260 | Loss: 0.06135164 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1261 | Loss: 0.06134984 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1262 | Loss: 0.06134801 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1263 | Loss: 0.06134623 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1264 | Loss: 0.06134445 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1265 | Loss: 0.06134269 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1266 | Loss: 0.06134095 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1267 | Loss: 0.06133921 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1268 | Loss: 0.06133749 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1269 | Loss: 0.06133579 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1270 | Loss: 0.06133409 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1271 | Loss: 0.06133243 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1272 | Loss: 0.06133076 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1273 | Loss: 0.06132912 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1274 | Loss: 0.06132748 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1275 | Loss: 0.06132585 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1276 | Loss: 0.06132424 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1277 | Loss: 0.06132263 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1278 | Loss: 0.06132105 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1279 | Loss: 0.06131947 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1280 | Loss: 0.06131790 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1281 | Loss: 0.06131635 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1282 | Loss: 0.06131481 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1283 | Loss: 0.06131328 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1284 | Loss: 0.06131175 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1285 | Loss: 0.06131025 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1286 | Loss: 0.06130875 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1287 | Loss: 0.06130726 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1288 | Loss: 0.06130578 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1289 | Loss: 0.06130430 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1290 | Loss: 0.06130285 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1291 | Loss: 0.06130140 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1292 | Loss: 0.06129996 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1293 | Loss: 0.06129854 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1294 | Loss: 0.06129711 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1295 | Loss: 0.06129570 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1296 | Loss: 0.06129429 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1297 | Loss: 0.06129291 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1298 | Loss: 0.06129152 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1299 | Loss: 0.06129015 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1300 | Loss: 0.06128878 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1301 | Loss: 0.06128743 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1302 | Loss: 0.06128607 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1303 | Loss: 0.06128472 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1304 | Loss: 0.06128339 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1305 | Loss: 0.06128207 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1306 | Loss: 0.06128075 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1307 | Loss: 0.06127944 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1308 | Loss: 0.06127813 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1309 | Loss: 0.06127684 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1310 | Loss: 0.06127555 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1311 | Loss: 0.06127428 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1312 | Loss: 0.06127300 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1313 | Loss: 0.06127173 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1314 | Loss: 0.06127048 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1315 | Loss: 0.06126922 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1316 | Loss: 0.06126798 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1317 | Loss: 0.06126674 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1318 | Loss: 0.06126551 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1319 | Loss: 0.06126428 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1320 | Loss: 0.06126307 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1321 | Loss: 0.06126185 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1322 | Loss: 0.06126065 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1323 | Loss: 0.06125946 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1324 | Loss: 0.06125826 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1325 | Loss: 0.06125708 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1326 | Loss: 0.06125589 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1327 | Loss: 0.06125473 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1328 | Loss: 0.06125356 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1329 | Loss: 0.06125239 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1330 | Loss: 0.06125123 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1331 | Loss: 0.06125008 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1332 | Loss: 0.06124893 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1333 | Loss: 0.06124780 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1334 | Loss: 0.06124666 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1335 | Loss: 0.06124553 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1336 | Loss: 0.06124441 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1337 | Loss: 0.06124330 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1338 | Loss: 0.06124219 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1339 | Loss: 0.06124107 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1340 | Loss: 0.06123998 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1341 | Loss: 0.06123887 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1342 | Loss: 0.06123779 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1343 | Loss: 0.06123669 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1344 | Loss: 0.06123562 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1345 | Loss: 0.06123454 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1346 | Loss: 0.06123346 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1347 | Loss: 0.06123240 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1348 | Loss: 0.06123133 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1349 | Loss: 0.06123028 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1350 | Loss: 0.06122923 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1351 | Loss: 0.06122817 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1352 | Loss: 0.06122713 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1353 | Loss: 0.06122610 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1354 | Loss: 0.06122506 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1355 | Loss: 0.06122402 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1356 | Loss: 0.06122300 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1357 | Loss: 0.06122198 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1358 | Loss: 0.06122095 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1359 | Loss: 0.06121995 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1360 | Loss: 0.06121894 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1361 | Loss: 0.06121793 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1362 | Loss: 0.06121693 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1363 | Loss: 0.06121593 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1364 | Loss: 0.06121494 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1365 | Loss: 0.06121394 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1366 | Loss: 0.06121296 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1367 | Loss: 0.06121198 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1368 | Loss: 0.06121100 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1369 | Loss: 0.06121003 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1370 | Loss: 0.06120906 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1371 | Loss: 0.06120810 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1372 | Loss: 0.06120713 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1373 | Loss: 0.06120617 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1374 | Loss: 0.06120522 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1375 | Loss: 0.06120427 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1376 | Loss: 0.06120332 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1377 | Loss: 0.06120237 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1378 | Loss: 0.06120143 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1379 | Loss: 0.06120050 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1380 | Loss: 0.06119956 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1381 | Loss: 0.06119862 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1382 | Loss: 0.06119771 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1383 | Loss: 0.06119677 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1384 | Loss: 0.06119586 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1385 | Loss: 0.06119493 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1386 | Loss: 0.06119402 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1387 | Loss: 0.06119311 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1388 | Loss: 0.06119220 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1389 | Loss: 0.06119131 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1390 | Loss: 0.06119040 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1391 | Loss: 0.06118950 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1392 | Loss: 0.06118860 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1393 | Loss: 0.06118771 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1394 | Loss: 0.06118682 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1395 | Loss: 0.06118594 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1396 | Loss: 0.06118505 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1397 | Loss: 0.06118418 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1398 | Loss: 0.06118330 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1399 | Loss: 0.06118241 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1400 | Loss: 0.06118155 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1401 | Loss: 0.06118068 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1402 | Loss: 0.06117982 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1403 | Loss: 0.06117896 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1404 | Loss: 0.06117809 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1405 | Loss: 0.06117723 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1406 | Loss: 0.06117638 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1407 | Loss: 0.06117553 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1408 | Loss: 0.06117468 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1409 | Loss: 0.06117383 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1410 | Loss: 0.06117298 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1411 | Loss: 0.06117215 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1412 | Loss: 0.06117131 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1413 | Loss: 0.06117047 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1414 | Loss: 0.06116963 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1415 | Loss: 0.06116881 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1416 | Loss: 0.06116798 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1417 | Loss: 0.06116714 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1418 | Loss: 0.06116633 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1419 | Loss: 0.06116550 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1420 | Loss: 0.06116470 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1421 | Loss: 0.06116388 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1422 | Loss: 0.06116307 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1423 | Loss: 0.06116231 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1424 | Loss: 0.06116160 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1425 | Loss: 0.06116110 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1426 | Loss: 0.06116113 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1427 | Loss: 0.06116290 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1428 | Loss: 0.06116998 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1429 | Loss: 0.06119416 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1430 | Loss: 0.06127324 | Acc: 0.95130914 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1431 | Loss: 0.06153762 | Acc: 0.96554892 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1432 | Loss: 0.06237839 | Acc: 0.94258153 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1433 | Loss: 0.06504997 | Acc: 0.97519522 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1434 | Loss: 0.07044350 | Acc: 0.91226458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1435 | Loss: 0.07655939 | Acc: 0.98300413 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1436 | Loss: 0.06438334 | Acc: 0.93706936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1437 | Loss: 0.06520458 | Acc: 0.93615067 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1438 | Loss: 0.06718820 | Acc: 0.97611392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1439 | Loss: 0.06278143 | Acc: 0.96646762 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1440 | Loss: 0.06620414 | Acc: 0.92926045 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1441 | Loss: 0.06209850 | Acc: 0.94993110 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1442 | Loss: 0.06445260 | Acc: 0.97197979 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1443 | Loss: 0.06252082 | Acc: 0.96049610 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1444 | Loss: 0.06339177 | Acc: 0.94028480 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1445 | Loss: 0.06277846 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1446 | Loss: 0.06279603 | Acc: 0.96187414 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1447 | Loss: 0.06265211 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1448 | Loss: 0.06252928 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1449 | Loss: 0.06248387 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1450 | Loss: 0.06237749 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1451 | Loss: 0.06220249 | Acc: 0.95039045 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1452 | Loss: 0.06225771 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1453 | Loss: 0.06197067 | Acc: 0.96233349 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1454 | Loss: 0.06215368 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1455 | Loss: 0.06182856 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1456 | Loss: 0.06197840 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1457 | Loss: 0.06178708 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1458 | Loss: 0.06181251 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1459 | Loss: 0.06173287 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1460 | Loss: 0.06173143 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1461 | Loss: 0.06164279 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1462 | Loss: 0.06167980 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1463 | Loss: 0.06158339 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1464 | Loss: 0.06159157 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1465 | Loss: 0.06158472 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1466 | Loss: 0.06151372 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1467 | Loss: 0.06154411 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1468 | Loss: 0.06149935 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1469 | Loss: 0.06148220 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1470 | Loss: 0.06149174 | Acc: 0.96095544 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1471 | Loss: 0.06144156 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1472 | Loss: 0.06146224 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1473 | Loss: 0.06142851 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1474 | Loss: 0.06142700 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1475 | Loss: 0.06141851 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1476 | Loss: 0.06139901 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1477 | Loss: 0.06140186 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1478 | Loss: 0.06138258 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1479 | Loss: 0.06138105 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1480 | Loss: 0.06137230 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1481 | Loss: 0.06136278 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1482 | Loss: 0.06136277 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1483 | Loss: 0.06134700 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1484 | Loss: 0.06134996 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1485 | Loss: 0.06133830 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1486 | Loss: 0.06133479 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1487 | Loss: 0.06133325 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1488 | Loss: 0.06131978 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1489 | Loss: 0.06132725 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1490 | Loss: 0.06131080 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1491 | Loss: 0.06131595 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1492 | Loss: 0.06130675 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1493 | Loss: 0.06130529 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1494 | Loss: 0.06130173 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1495 | Loss: 0.06129757 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1496 | Loss: 0.06129420 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1497 | Loss: 0.06129253 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1498 | Loss: 0.06128727 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1499 | Loss: 0.06128632 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1500 | Loss: 0.06128263 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1501 | Loss: 0.06127919 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1502 | Loss: 0.06127854 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1503 | Loss: 0.06127330 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1504 | Loss: 0.06127330 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1505 | Loss: 0.06126874 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1506 | Loss: 0.06126782 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1507 | Loss: 0.06126427 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1508 | Loss: 0.06126297 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1509 | Loss: 0.06125987 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1510 | Loss: 0.06125828 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1511 | Loss: 0.06125561 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1512 | Loss: 0.06125367 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1513 | Loss: 0.06125181 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1514 | Loss: 0.06124938 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1515 | Loss: 0.06124760 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1516 | Loss: 0.06124551 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1517 | Loss: 0.06124355 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1518 | Loss: 0.06124189 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1519 | Loss: 0.06123964 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1520 | Loss: 0.06123812 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1521 | Loss: 0.06123609 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1522 | Loss: 0.06123440 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1523 | Loss: 0.06123270 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1524 | Loss: 0.06123074 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1525 | Loss: 0.06122934 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1526 | Loss: 0.06122734 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1527 | Loss: 0.06122592 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1528 | Loss: 0.06122409 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1529 | Loss: 0.06122254 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1530 | Loss: 0.06122093 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1531 | Loss: 0.06121931 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1532 | Loss: 0.06121779 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1533 | Loss: 0.06121619 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1534 | Loss: 0.06121465 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1535 | Loss: 0.06121316 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1536 | Loss: 0.06121166 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1537 | Loss: 0.06121016 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1538 | Loss: 0.06120869 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1539 | Loss: 0.06120721 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1540 | Loss: 0.06120581 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1541 | Loss: 0.06120434 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1542 | Loss: 0.06120295 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1543 | Loss: 0.06120155 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1544 | Loss: 0.06120015 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1545 | Loss: 0.06119881 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1546 | Loss: 0.06119740 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1547 | Loss: 0.06119608 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1548 | Loss: 0.06119473 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1549 | Loss: 0.06119341 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1550 | Loss: 0.06119210 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1551 | Loss: 0.06119079 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1552 | Loss: 0.06118951 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1553 | Loss: 0.06118822 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1554 | Loss: 0.06118696 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1555 | Loss: 0.06118571 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1556 | Loss: 0.06118445 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1557 | Loss: 0.06118323 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1558 | Loss: 0.06118200 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1559 | Loss: 0.06118078 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1560 | Loss: 0.06117958 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1561 | Loss: 0.06117837 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1562 | Loss: 0.06117719 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1563 | Loss: 0.06117601 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1564 | Loss: 0.06117483 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1565 | Loss: 0.06117367 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1566 | Loss: 0.06117252 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1567 | Loss: 0.06117137 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1568 | Loss: 0.06117024 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1569 | Loss: 0.06116910 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1570 | Loss: 0.06116799 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1571 | Loss: 0.06116688 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1572 | Loss: 0.06116578 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1573 | Loss: 0.06116468 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1574 | Loss: 0.06116359 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1575 | Loss: 0.06116251 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1576 | Loss: 0.06116143 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1577 | Loss: 0.06116037 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1578 | Loss: 0.06115931 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1579 | Loss: 0.06115826 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1580 | Loss: 0.06115721 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1581 | Loss: 0.06115618 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1582 | Loss: 0.06115514 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1583 | Loss: 0.06115412 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1584 | Loss: 0.06115311 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1585 | Loss: 0.06115209 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1586 | Loss: 0.06115109 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1587 | Loss: 0.06115009 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1588 | Loss: 0.06114909 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1589 | Loss: 0.06114811 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1590 | Loss: 0.06114713 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1591 | Loss: 0.06114616 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1592 | Loss: 0.06114519 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1593 | Loss: 0.06114423 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1594 | Loss: 0.06114326 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1595 | Loss: 0.06114232 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1596 | Loss: 0.06114137 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1597 | Loss: 0.06114043 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1598 | Loss: 0.06113950 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1599 | Loss: 0.06113857 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1600 | Loss: 0.06113764 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1601 | Loss: 0.06113673 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1602 | Loss: 0.06113581 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1603 | Loss: 0.06113491 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1604 | Loss: 0.06113400 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1605 | Loss: 0.06113311 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1606 | Loss: 0.06113221 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1607 | Loss: 0.06113133 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1608 | Loss: 0.06113045 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1609 | Loss: 0.06112956 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1610 | Loss: 0.06112870 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1611 | Loss: 0.06112782 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1612 | Loss: 0.06112696 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1613 | Loss: 0.06112609 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1614 | Loss: 0.06112524 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1615 | Loss: 0.06112440 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1616 | Loss: 0.06112354 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1617 | Loss: 0.06112271 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1618 | Loss: 0.06112187 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1619 | Loss: 0.06112103 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1620 | Loss: 0.06112021 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1621 | Loss: 0.06111938 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1622 | Loss: 0.06111856 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1623 | Loss: 0.06111775 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1624 | Loss: 0.06111693 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1625 | Loss: 0.06111612 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1626 | Loss: 0.06111531 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1627 | Loss: 0.06111451 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1628 | Loss: 0.06111372 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1629 | Loss: 0.06111292 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1630 | Loss: 0.06111213 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1631 | Loss: 0.06111135 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1632 | Loss: 0.06111057 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1633 | Loss: 0.06110979 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1634 | Loss: 0.06110901 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1635 | Loss: 0.06110823 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1636 | Loss: 0.06110748 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1637 | Loss: 0.06110671 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1638 | Loss: 0.06110595 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1639 | Loss: 0.06110519 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1640 | Loss: 0.06110444 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1641 | Loss: 0.06110368 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1642 | Loss: 0.06110294 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1643 | Loss: 0.06110219 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1644 | Loss: 0.06110146 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1645 | Loss: 0.06110073 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1646 | Loss: 0.06109999 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1647 | Loss: 0.06109925 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1648 | Loss: 0.06109853 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1649 | Loss: 0.06109781 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1650 | Loss: 0.06109710 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1651 | Loss: 0.06109640 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1652 | Loss: 0.06109574 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1653 | Loss: 0.06109522 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1654 | Loss: 0.06109506 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1655 | Loss: 0.06109610 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1656 | Loss: 0.06110099 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1657 | Loss: 0.06111892 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1658 | Loss: 0.06118173 | Acc: 0.96049610 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1659 | Loss: 0.06140040 | Acc: 0.94855305 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1660 | Loss: 0.06217286 | Acc: 0.96830501 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1661 | Loss: 0.06463958 | Acc: 0.93155719 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1662 | Loss: 0.07132228 | Acc: 0.98162609 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1663 | Loss: 0.07523546 | Acc: 0.89343133 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1664 | Loss: 0.06865305 | Acc: 0.97841066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1665 | Loss: 0.06363968 | Acc: 0.96922370 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1666 | Loss: 0.06895198 | Acc: 0.92374828 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1667 | Loss: 0.06177065 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1668 | Loss: 0.06614771 | Acc: 0.97289848 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1669 | Loss: 0.06213122 | Acc: 0.96141479 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1670 | Loss: 0.06486942 | Acc: 0.93752871 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1671 | Loss: 0.06202262 | Acc: 0.94855305 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1672 | Loss: 0.06357486 | Acc: 0.96692696 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1673 | Loss: 0.06252550 | Acc: 0.96554892 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1674 | Loss: 0.06277829 | Acc: 0.94993110 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1675 | Loss: 0.06244603 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1676 | Loss: 0.06242198 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1677 | Loss: 0.06238028 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1678 | Loss: 0.06219114 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1679 | Loss: 0.06220211 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1680 | Loss: 0.06201260 | Acc: 0.96049610 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1681 | Loss: 0.06203144 | Acc: 0.96095544 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1682 | Loss: 0.06192634 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1683 | Loss: 0.06186387 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1684 | Loss: 0.06182953 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1685 | Loss: 0.06173886 | Acc: 0.96095544 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1686 | Loss: 0.06170827 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1687 | Loss: 0.06173952 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1688 | Loss: 0.06155830 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1689 | Loss: 0.06170708 | Acc: 0.96003675 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1690 | Loss: 0.06148188 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1691 | Loss: 0.06163656 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1692 | Loss: 0.06147205 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1693 | Loss: 0.06153334 | Acc: 0.96003675 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1694 | Loss: 0.06147950 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1695 | Loss: 0.06143766 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1696 | Loss: 0.06148454 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1697 | Loss: 0.06139287 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1698 | Loss: 0.06144388 | Acc: 0.96003675 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1699 | Loss: 0.06138931 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1700 | Loss: 0.06139268 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1701 | Loss: 0.06138445 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1702 | Loss: 0.06137190 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1703 | Loss: 0.06135580 | Acc: 0.95865870 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1704 | Loss: 0.06136562 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1705 | Loss: 0.06133160 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1706 | Loss: 0.06134451 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1707 | Loss: 0.06132989 | Acc: 0.96003675 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1708 | Loss: 0.06131393 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1709 | Loss: 0.06132746 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1710 | Loss: 0.06129853 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1711 | Loss: 0.06131175 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1712 | Loss: 0.06129324 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1713 | Loss: 0.06129427 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1714 | Loss: 0.06128849 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1715 | Loss: 0.06128031 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1716 | Loss: 0.06128241 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1717 | Loss: 0.06126980 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1718 | Loss: 0.06127308 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1719 | Loss: 0.06126503 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1720 | Loss: 0.06126243 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1721 | Loss: 0.06126037 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1722 | Loss: 0.06125497 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1723 | Loss: 0.06125289 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1724 | Loss: 0.06125034 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1725 | Loss: 0.06124616 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1726 | Loss: 0.06124472 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1727 | Loss: 0.06124162 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1728 | Loss: 0.06123780 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1729 | Loss: 0.06123808 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1730 | Loss: 0.06123203 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1731 | Loss: 0.06123314 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1732 | Loss: 0.06122850 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1733 | Loss: 0.06122706 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1734 | Loss: 0.06122544 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1735 | Loss: 0.06122195 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1736 | Loss: 0.06122150 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1737 | Loss: 0.06121801 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1738 | Loss: 0.06121696 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1739 | Loss: 0.06121446 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1740 | Loss: 0.06121290 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1741 | Loss: 0.06121075 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1742 | Loss: 0.06120924 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1743 | Loss: 0.06120696 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1744 | Loss: 0.06120571 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1745 | Loss: 0.06120351 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1746 | Loss: 0.06120222 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1747 | Loss: 0.06120025 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1748 | Loss: 0.06119873 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1749 | Loss: 0.06119709 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1750 | Loss: 0.06119544 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1751 | Loss: 0.06119394 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1752 | Loss: 0.06119236 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1753 | Loss: 0.06119083 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1754 | Loss: 0.06118938 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1755 | Loss: 0.06118781 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1756 | Loss: 0.06118646 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1757 | Loss: 0.06118498 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1758 | Loss: 0.06118354 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1759 | Loss: 0.06118222 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1760 | Loss: 0.06118073 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1761 | Loss: 0.06117944 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1762 | Loss: 0.06117807 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1763 | Loss: 0.06117672 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1764 | Loss: 0.06117544 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1765 | Loss: 0.06117411 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1766 | Loss: 0.06117286 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1767 | Loss: 0.06117155 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1768 | Loss: 0.06117031 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1769 | Loss: 0.06116907 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1770 | Loss: 0.06116782 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1771 | Loss: 0.06116663 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1772 | Loss: 0.06116541 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1773 | Loss: 0.06116420 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1774 | Loss: 0.06116305 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1775 | Loss: 0.06116185 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1776 | Loss: 0.06116074 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1777 | Loss: 0.06115955 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1778 | Loss: 0.06115844 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1779 | Loss: 0.06115730 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1780 | Loss: 0.06115620 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1781 | Loss: 0.06115510 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1782 | Loss: 0.06115400 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1783 | Loss: 0.06115292 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1784 | Loss: 0.06115184 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1785 | Loss: 0.06115079 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1786 | Loss: 0.06114974 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1787 | Loss: 0.06114869 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1788 | Loss: 0.06114765 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1789 | Loss: 0.06114664 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1790 | Loss: 0.06114561 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1791 | Loss: 0.06114460 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1792 | Loss: 0.06114360 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1793 | Loss: 0.06114262 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1794 | Loss: 0.06114163 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1795 | Loss: 0.06114065 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1796 | Loss: 0.06113969 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1797 | Loss: 0.06113872 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1798 | Loss: 0.06113777 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1799 | Loss: 0.06113682 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1800 | Loss: 0.06113589 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1801 | Loss: 0.06113496 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1802 | Loss: 0.06113403 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1803 | Loss: 0.06113312 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1804 | Loss: 0.06113221 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1805 | Loss: 0.06113131 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1806 | Loss: 0.06113041 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1807 | Loss: 0.06112953 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1808 | Loss: 0.06112864 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1809 | Loss: 0.06112777 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1810 | Loss: 0.06112690 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1811 | Loss: 0.06112603 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1812 | Loss: 0.06112517 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1813 | Loss: 0.06112432 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1814 | Loss: 0.06112349 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1815 | Loss: 0.06112264 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1816 | Loss: 0.06112180 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1817 | Loss: 0.06112098 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1818 | Loss: 0.06112015 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1819 | Loss: 0.06111934 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1820 | Loss: 0.06111852 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1821 | Loss: 0.06111772 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1822 | Loss: 0.06111691 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1823 | Loss: 0.06111612 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1824 | Loss: 0.06111532 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1825 | Loss: 0.06111454 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1826 | Loss: 0.06111376 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1827 | Loss: 0.06111298 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1828 | Loss: 0.06111221 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1829 | Loss: 0.06111144 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1830 | Loss: 0.06111068 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1831 | Loss: 0.06110992 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1832 | Loss: 0.06110917 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1833 | Loss: 0.06110842 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1834 | Loss: 0.06110768 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1835 | Loss: 0.06110693 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1836 | Loss: 0.06110621 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1837 | Loss: 0.06110547 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1838 | Loss: 0.06110474 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1839 | Loss: 0.06110403 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1840 | Loss: 0.06110331 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1841 | Loss: 0.06110259 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1842 | Loss: 0.06110188 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1843 | Loss: 0.06110118 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1844 | Loss: 0.06110048 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1845 | Loss: 0.06109977 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1846 | Loss: 0.06109908 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1847 | Loss: 0.06109839 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1848 | Loss: 0.06109770 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1849 | Loss: 0.06109702 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1850 | Loss: 0.06109633 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1851 | Loss: 0.06109566 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1852 | Loss: 0.06109498 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1853 | Loss: 0.06109431 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1854 | Loss: 0.06109365 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1855 | Loss: 0.06109300 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1856 | Loss: 0.06109232 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1857 | Loss: 0.06109168 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1858 | Loss: 0.06109102 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1859 | Loss: 0.06109037 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1860 | Loss: 0.06108972 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1861 | Loss: 0.06108908 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1862 | Loss: 0.06108844 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1863 | Loss: 0.06108780 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1864 | Loss: 0.06108718 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1865 | Loss: 0.06108655 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1866 | Loss: 0.06108592 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1867 | Loss: 0.06108528 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1868 | Loss: 0.06108467 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1869 | Loss: 0.06108405 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1870 | Loss: 0.06108344 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1871 | Loss: 0.06108282 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1872 | Loss: 0.06108221 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1873 | Loss: 0.06108160 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1874 | Loss: 0.06108100 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1875 | Loss: 0.06108039 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1876 | Loss: 0.06107979 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1877 | Loss: 0.06107919 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1878 | Loss: 0.06107861 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1879 | Loss: 0.06107801 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1880 | Loss: 0.06107742 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1881 | Loss: 0.06107684 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1882 | Loss: 0.06107625 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1883 | Loss: 0.06107568 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1884 | Loss: 0.06107510 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1885 | Loss: 0.06107452 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1886 | Loss: 0.06107394 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1887 | Loss: 0.06107338 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1888 | Loss: 0.06107280 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1889 | Loss: 0.06107223 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1890 | Loss: 0.06107168 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1891 | Loss: 0.06107111 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1892 | Loss: 0.06107055 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1893 | Loss: 0.06106999 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1894 | Loss: 0.06106944 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1895 | Loss: 0.06106889 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1896 | Loss: 0.06106833 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1897 | Loss: 0.06106778 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1898 | Loss: 0.06106723 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1899 | Loss: 0.06106669 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1900 | Loss: 0.06106615 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1901 | Loss: 0.06106561 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1902 | Loss: 0.06106507 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1903 | Loss: 0.06106454 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1904 | Loss: 0.06106399 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1905 | Loss: 0.06106347 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1906 | Loss: 0.06106294 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1907 | Loss: 0.06106241 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1908 | Loss: 0.06106189 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1909 | Loss: 0.06106136 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1910 | Loss: 0.06106085 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1911 | Loss: 0.06106032 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1912 | Loss: 0.06105980 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1913 | Loss: 0.06105928 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1914 | Loss: 0.06105876 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1915 | Loss: 0.06105825 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1916 | Loss: 0.06105775 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1917 | Loss: 0.06105724 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1918 | Loss: 0.06105673 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1919 | Loss: 0.06105623 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1920 | Loss: 0.06105572 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1921 | Loss: 0.06105522 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1922 | Loss: 0.06105472 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1923 | Loss: 0.06105422 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1924 | Loss: 0.06105372 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1925 | Loss: 0.06105322 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1926 | Loss: 0.06105274 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1927 | Loss: 0.06105224 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1928 | Loss: 0.06105177 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1929 | Loss: 0.06105128 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1930 | Loss: 0.06105084 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1931 | Loss: 0.06105044 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1932 | Loss: 0.06105020 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1933 | Loss: 0.06105041 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1934 | Loss: 0.06105183 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1935 | Loss: 0.06105687 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1936 | Loss: 0.06107253 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1937 | Loss: 0.06112031 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1938 | Loss: 0.06126755 | Acc: 0.96325218 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1939 | Loss: 0.06171155 | Acc: 0.94441893 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1940 | Loss: 0.06305916 | Acc: 0.97060175 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1941 | Loss: 0.06632949 | Acc: 0.92604502 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1942 | Loss: 0.07215778 | Acc: 0.98208544 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1943 | Loss: 0.06937394 | Acc: 0.91915480 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1944 | Loss: 0.06206814 | Acc: 0.96463023 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1945 | Loss: 0.06482562 | Acc: 0.97335783 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1946 | Loss: 0.06328242 | Acc: 0.94074414 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1947 | Loss: 0.06222009 | Acc: 0.94441893 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1948 | Loss: 0.06341439 | Acc: 0.96922370 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1949 | Loss: 0.06189868 | Acc: 0.96600827 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1950 | Loss: 0.06304891 | Acc: 0.94350023 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1951 | Loss: 0.06166381 | Acc: 0.95314653 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1952 | Loss: 0.06257690 | Acc: 0.96463023 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1953 | Loss: 0.06172264 | Acc: 0.96187414 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1954 | Loss: 0.06229470 | Acc: 0.94993110 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1955 | Loss: 0.06172070 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1956 | Loss: 0.06200304 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1957 | Loss: 0.06173028 | Acc: 0.95728066 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1958 | Loss: 0.06180439 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1959 | Loss: 0.06169702 | Acc: 0.95406523 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1960 | Loss: 0.06162585 | Acc: 0.96049610 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1961 | Loss: 0.06164356 | Acc: 0.95911805 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1962 | Loss: 0.06154241 | Acc: 0.95452458 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1963 | Loss: 0.06154515 | Acc: 0.95176849 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1964 | Loss: 0.06150376 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1965 | Loss: 0.06147597 | Acc: 0.96095544 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1966 | Loss: 0.06142452 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1967 | Loss: 0.06145109 | Acc: 0.95268718 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1968 | Loss: 0.06135060 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1969 | Loss: 0.06142835 | Acc: 0.96095544 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1970 | Loss: 0.06129710 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1971 | Loss: 0.06139171 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1972 | Loss: 0.06127387 | Acc: 0.95498392 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1973 | Loss: 0.06133394 | Acc: 0.96003675 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1974 | Loss: 0.06127987 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1975 | Loss: 0.06128351 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1976 | Loss: 0.06128298 | Acc: 0.95360588 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1977 | Loss: 0.06123890 | Acc: 0.95774001 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1978 | Loss: 0.06128024 | Acc: 0.95957740 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1979 | Loss: 0.06121979 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1980 | Loss: 0.06126110 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1981 | Loss: 0.06121675 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1982 | Loss: 0.06122882 | Acc: 0.95819936 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1983 | Loss: 0.06122329 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1984 | Loss: 0.06120307 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1985 | Loss: 0.06122303 | Acc: 0.95544327 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1986 | Loss: 0.06118821 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1987 | Loss: 0.06120781 | Acc: 0.95682131 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1988 | Loss: 0.06118913 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1989 | Loss: 0.06118849 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1990 | Loss: 0.06119015 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1991 | Loss: 0.06117234 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1992 | Loss: 0.06118535 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1993 | Loss: 0.06116710 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1994 | Loss: 0.06117376 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1995 | Loss: 0.06116662 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1996 | Loss: 0.06116153 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1997 | Loss: 0.06116500 | Acc: 0.95636197 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1998 | Loss: 0.06115449 | Acc: 0.95590262 | \n",
            "epoch total:  2177.0\n",
            "Epoch 1999 | Loss: 0.06115936 | Acc: 0.95590262 | \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Training loop\n",
        "# -----------------------------\n",
        "model.train()\n",
        "epochs = 2000\n",
        "\n",
        "N = X_train_oh.size(0)\n",
        "batch_size = N #32\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0.0\n",
        "  epoch_correct = 0.0\n",
        "  epoch_total = 0.0\n",
        "  epoch_loss_mean = 0.0\n",
        "\n",
        "  perm = torch.randperm(N)\n",
        "\n",
        "  for i in range(0, N, batch_size):\n",
        "      idx = perm[i:i + batch_size]\n",
        "      X_use = X_train_oh#[idx]\n",
        "      y_use = y_train#[idx]\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      preds = model(X_use)   # (batch, 1)\n",
        "      loss = loss_fn(preds, y_use)\n",
        "\n",
        "\n",
        "\n",
        "      loss.backward()\n",
        "      #for name, param in model.named_parameters():\n",
        "        #print(name, param.grad.norm().item())\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      with torch.no_grad():\n",
        "        preds_bin = (preds > 0.5).float()\n",
        "        epoch_loss += loss.item()*y_use.size(0)\n",
        "        epoch_correct += (preds_bin == y_use).sum().item()\n",
        "        epoch_total += y_use.size(0)\n",
        "\n",
        "  epoch_loss_mean = epoch_loss / epoch_total\n",
        "  epoch_acc = epoch_correct / epoch_total\n",
        "  print(\"epoch total: \", epoch_total)\n",
        "  loss_history.append(epoch_loss_mean) # Store loss\n",
        "  if epoch % 1 == 0:\n",
        "        print(\n",
        "            f\"Epoch {epoch:3d} | \"\n",
        "            f\"Loss: {epoch_loss_mean:.8f} | \"\n",
        "            f\"Acc: {epoch_acc:.8f} | \"\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5jmpEiTTsF_",
        "outputId": "3d2d09f4-8532-4c44-a7a6-729e4fa83ebb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step  0 | Loss: 0.06070841 | Acc: 0.95406520\n",
            "Step  1 | Loss: 0.06070729 | Acc: 0.95406520\n",
            "Step  2 | Loss: 0.06070570 | Acc: 0.95360589\n",
            "Step  3 | Loss: 0.06070365 | Acc: 0.95314652\n",
            "Step  4 | Loss: 0.06070105 | Acc: 0.95268720\n",
            "Step  5 | Loss: 0.06069775 | Acc: 0.95314652\n",
            "Step  6 | Loss: 0.06069623 | Acc: 0.95222783\n",
            "Step  7 | Loss: 0.06069460 | Acc: 0.95176852\n",
            "Step  8 | Loss: 0.06069266 | Acc: 0.95268720\n",
            "Step  9 | Loss: 0.06068936 | Acc: 0.95314652\n",
            "Step 10 | Loss: 0.06068397 | Acc: 0.95268720\n",
            "Step 11 | Loss: 0.06067901 | Acc: 0.95222783\n",
            "Step 12 | Loss: 0.06067568 | Acc: 0.95360589\n",
            "Step 13 | Loss: 0.06067249 | Acc: 0.95406520\n",
            "Step 14 | Loss: 0.06066980 | Acc: 0.95406520\n",
            "Step 15 | Loss: 0.06066763 | Acc: 0.95360589\n",
            "Step 16 | Loss: 0.06066542 | Acc: 0.95406520\n",
            "Step 17 | Loss: 0.06066350 | Acc: 0.95406520\n",
            "Step 18 | Loss: 0.06066067 | Acc: 0.95452458\n",
            "Step 19 | Loss: 0.06065695 | Acc: 0.95452458\n",
            "Step 20 | Loss: 0.06065372 | Acc: 0.95452458\n",
            "Step 21 | Loss: 0.06065097 | Acc: 0.95498395\n",
            "Step 22 | Loss: 0.06064821 | Acc: 0.95452458\n",
            "Step 23 | Loss: 0.06064606 | Acc: 0.95544326\n",
            "Step 24 | Loss: 0.06064316 | Acc: 0.95498395\n",
            "Step 25 | Loss: 0.06063930 | Acc: 0.95498395\n",
            "Step 26 | Loss: 0.06063616 | Acc: 0.95452458\n",
            "Step 27 | Loss: 0.06063221 | Acc: 0.95452458\n",
            "Step 28 | Loss: 0.06062814 | Acc: 0.95498395\n",
            "Step 29 | Loss: 0.06062508 | Acc: 0.95406520\n",
            "Step 30 | Loss: 0.06062156 | Acc: 0.95406520\n",
            "Step 31 | Loss: 0.06061696 | Acc: 0.95406520\n",
            "Step 32 | Loss: 0.06061364 | Acc: 0.95498395\n",
            "Step 33 | Loss: 0.06061070 | Acc: 0.95452458\n",
            "Step 34 | Loss: 0.06060708 | Acc: 0.95452458\n",
            "Step 35 | Loss: 0.06060365 | Acc: 0.95406520\n",
            "Step 36 | Loss: 0.06060001 | Acc: 0.95406520\n",
            "Step 37 | Loss: 0.06059783 | Acc: 0.95452458\n",
            "Step 38 | Loss: 0.06059583 | Acc: 0.95452458\n",
            "Step 39 | Loss: 0.06059380 | Acc: 0.95406520\n",
            "Step 40 | Loss: 0.06059168 | Acc: 0.95452458\n",
            "Step 41 | Loss: 0.06058906 | Acc: 0.95498395\n",
            "Step 42 | Loss: 0.06058582 | Acc: 0.95452458\n",
            "Step 43 | Loss: 0.06058357 | Acc: 0.95406520\n",
            "Step 44 | Loss: 0.06058150 | Acc: 0.95452458\n",
            "Step 45 | Loss: 0.06057892 | Acc: 0.95360589\n",
            "Step 46 | Loss: 0.06057680 | Acc: 0.95360589\n",
            "Step 47 | Loss: 0.06057471 | Acc: 0.95314652\n",
            "Step 48 | Loss: 0.06057280 | Acc: 0.95314652\n",
            "Step 49 | Loss: 0.06057071 | Acc: 0.95268720\n",
            "Step 50 | Loss: 0.06056828 | Acc: 0.95268720\n",
            "Step 51 | Loss: 0.06056504 | Acc: 0.95268720\n",
            "Step 52 | Loss: 0.06056319 | Acc: 0.95268720\n",
            "Step 53 | Loss: 0.06056117 | Acc: 0.95360589\n",
            "Step 54 | Loss: 0.06055922 | Acc: 0.95314652\n",
            "Step 55 | Loss: 0.06055778 | Acc: 0.95406520\n",
            "Step 56 | Loss: 0.06055576 | Acc: 0.95360589\n",
            "Step 57 | Loss: 0.06055287 | Acc: 0.95406520\n",
            "Step 58 | Loss: 0.06055146 | Acc: 0.95406520\n",
            "Step 59 | Loss: 0.06055002 | Acc: 0.95406520\n",
            "Step 60 | Loss: 0.06054863 | Acc: 0.95406520\n",
            "Step 61 | Loss: 0.06054655 | Acc: 0.95360589\n",
            "Step 62 | Loss: 0.06054439 | Acc: 0.95406520\n",
            "Step 63 | Loss: 0.06054228 | Acc: 0.95544326\n",
            "Step 64 | Loss: 0.06054041 | Acc: 0.95498395\n",
            "Step 65 | Loss: 0.06053883 | Acc: 0.95406520\n",
            "Step 66 | Loss: 0.06053771 | Acc: 0.95406520\n",
            "Step 67 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 68 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 69 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 70 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 71 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 72 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 73 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 74 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 75 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 76 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 77 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 78 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 79 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 80 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 81 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 82 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 83 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 84 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 85 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 86 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 87 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 88 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 89 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 90 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 91 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 92 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 93 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 94 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 95 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 96 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 97 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 98 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 99 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 100 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 101 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 102 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 103 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 104 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 105 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 106 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 107 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 108 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 109 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 110 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 111 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 112 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 113 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 114 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 115 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 116 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 117 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 118 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 119 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 120 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 121 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 122 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 123 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 124 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 125 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 126 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 127 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 128 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 129 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 130 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 131 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 132 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 133 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 134 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 135 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 136 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 137 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 138 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 139 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 140 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 141 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 142 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 143 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 144 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 145 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 146 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 147 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 148 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 149 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 150 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 151 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 152 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 153 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 154 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 155 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 156 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 157 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 158 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 159 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 160 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 161 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 162 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 163 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 164 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 165 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 166 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 167 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 168 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 169 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 170 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 171 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 172 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 173 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 174 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 175 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 176 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 177 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 178 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 179 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 180 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 181 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 182 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 183 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 184 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 185 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 186 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 187 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 188 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 189 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 190 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 191 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 192 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 193 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 194 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 195 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 196 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 197 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 198 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 199 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 200 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 201 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 202 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 203 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 204 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 205 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 206 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 207 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 208 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 209 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 210 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 211 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 212 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 213 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 214 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 215 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 216 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 217 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 218 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 219 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 220 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 221 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 222 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 223 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 224 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 225 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 226 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 227 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 228 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 229 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 230 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 231 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 232 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 233 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 234 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 235 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 236 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 237 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 238 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 239 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 240 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 241 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 242 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 243 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 244 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 245 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 246 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 247 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 248 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 249 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 250 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 251 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 252 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 253 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 254 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 255 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 256 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 257 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 258 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 259 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 260 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 261 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 262 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 263 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 264 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 265 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 266 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 267 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 268 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 269 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 270 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 271 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 272 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 273 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 274 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 275 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 276 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 277 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 278 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 279 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 280 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 281 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 282 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 283 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 284 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 285 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 286 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 287 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 288 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 289 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 290 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 291 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 292 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 293 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 294 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 295 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 296 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 297 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 298 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 299 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 300 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 301 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 302 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 303 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 304 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 305 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 306 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 307 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 308 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 309 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 310 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 311 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 312 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 313 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 314 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 315 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 316 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 317 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 318 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 319 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 320 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 321 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 322 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 323 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 324 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 325 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 326 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 327 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 328 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 329 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 330 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 331 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 332 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 333 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 334 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 335 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 336 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 337 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 338 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 339 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 340 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 341 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 342 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 343 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 344 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 345 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 346 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 347 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 348 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 349 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 350 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 351 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 352 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 353 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 354 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 355 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 356 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 357 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 358 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 359 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 360 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 361 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 362 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 363 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 364 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 365 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 366 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 367 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 368 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 369 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 370 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 371 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 372 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 373 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 374 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 375 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 376 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 377 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 378 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 379 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 380 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 381 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 382 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 383 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 384 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 385 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 386 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 387 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 388 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 389 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 390 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 391 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 392 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 393 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 394 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 395 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 396 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 397 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 398 | Loss: 0.06053752 | Acc: 0.95406520\n",
            "Step 399 | Loss: 0.06053752 | Acc: 0.95406520\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "\n",
        "optimizer = torch.optim.LBFGS(\n",
        "    model.parameters(),\n",
        "    lr=1.0,\n",
        "    max_iter=20,\n",
        "    history_size=100,\n",
        "    line_search_fn=\"strong_wolfe\"\n",
        ")\n",
        "\n",
        "loss_history = []\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(X_train_oh)\n",
        "    loss = loss_fn(preds, y_train)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "steps = 400  # NOT epochs\n",
        "\n",
        "for step in range(steps):\n",
        "    loss = optimizer.step(closure)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_train_oh)\n",
        "        preds_bin = (preds > 0.5).float()\n",
        "        acc = (preds_bin == y_train).float().mean().item()\n",
        "\n",
        "    loss_history.append(loss.item())\n",
        "\n",
        "    print(\n",
        "        f\"Step {step:2d} | \"\n",
        "        f\"Loss: {loss.item():.8f} | \"\n",
        "        f\"Acc: {acc:.8f}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "J4vlvcQ1QWKi",
        "outputId": "2a559a73-f8fb-4dc4-9ce7-1234fcaee1a3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_train_oh' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3408146074.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# ---- Forward ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_oh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_oh' is not defined"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "\n",
        "loss_history = []\n",
        "steps = 400  # NOT epochs\n",
        "\n",
        "for step in range(steps):\n",
        "\n",
        "    # ---- Forward ----\n",
        "    model.zero_grad()\n",
        "    preds = model(X_train_oh)\n",
        "    loss = loss_fn(preds, y_train)\n",
        "\n",
        "    # ---- Backward ----\n",
        "    loss.backward()\n",
        "\n",
        "    # ---- YOUR UPDATE RULE ----\n",
        "    with torch.no_grad():\n",
        "        grad_norm_sq = 0.0\n",
        "\n",
        "        # Compute ||grad||^2 over ALL parameters\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                grad_norm_sq += torch.sum(p.grad ** 2)\n",
        "\n",
        "        # Safety guard (very important)\n",
        "        if grad_norm_sq < 1e-12:\n",
        "            print(\"Gradient vanished â€” stopping.\")\n",
        "            break\n",
        "\n",
        "        step_scale = loss / grad_norm_sq\n",
        "\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                p -= step_scale * p.grad\n",
        "    # --------------------------\n",
        "\n",
        "    # ---- Metrics ----\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_train_oh)\n",
        "        preds_bin = (preds > 0.5).float()\n",
        "        acc = (preds_bin == y_train).float().mean().item()\n",
        "\n",
        "    loss_history.append(loss.item())\n",
        "\n",
        "    print(\n",
        "        f\"Step {step:3d} | \"\n",
        "        f\"Loss: {loss.item():.8f} | \"\n",
        "        f\"Acc: {acc:.8f}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybL5B0XNDref",
        "outputId": "5ea02751-dbc2-479f-b320-701a8398b0db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean mse: 0.06053752452135086\n",
            "median mse: 0.021217403933405876\n",
            "max mse: 0.7127650380134583\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    y_hat = model(X_train_oh)\n",
        "    mse = ((y_hat - y_train)**2)\n",
        "    print(\"mean mse:\", mse.mean().item())\n",
        "    print(\"median mse:\", mse.median().item())\n",
        "    print(\"max mse:\", mse.max().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I62HChwzkaV5",
        "outputId": "c8c82f2b-0cfc-4f23-aa43-1d892c5d20ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "325\n",
            "raw_attention.Wq.weight 6.249271392822266 0.001194161712191999\n",
            "raw_attention.Wk.weight 6.048226356506348 0.0011248550144955516\n",
            "raw_attention.Wv.weight 6.462733745574951 0.0010300666326656938\n",
            "readout.weight 2.786839723587036 0.0032262157183140516\n",
            "readout.bias 0.4663619101047516 0.0001569027081131935\n"
          ]
        }
      ],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print(num_params)\n",
        "for name, param in model.named_parameters():\n",
        "    #if param.grad is not None:\n",
        "        print(name, param.norm().item(), param.grad.norm().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxjNKRtWHHZU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0dR0gV_A_bp",
        "outputId": "e699a74b-8069-4e2a-c447-c43eaeeb88d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analyzing misclassified training examples from training data:\n",
            "Misclassified training examples 100:\n",
            "Input: [1, 7, 5, 8, 6, 9, 3, 1, 2], Predicted: 0.5912, Actual: 0\n",
            "Input: [9, 4, 7, 3, 1, 9, 6, 2, 7], Predicted: 0.6631, Actual: 0\n",
            "Input: [6, 7, 6, 7, 4, 2, 9, 1, 3], Predicted: 0.6561, Actual: 0\n",
            "Input: [5, 1, 9, 7, 6, 2, 8, 5, 4], Predicted: 0.5984, Actual: 0\n",
            "Input: [8, 1, 8, 5, 3, 7, 6, 9, 2], Predicted: 0.8380, Actual: 0\n",
            "Input: [5, 6, 8, 2, 5, 3, 1, 6, 3], Predicted: 0.6360, Actual: 0\n",
            "Input: [8, 2, 5, 3, 7, 1, 8, 7, 6], Predicted: 0.5696, Actual: 0\n",
            "Input: [2, 1, 4, 9, 7, 8, 8, 5, 3], Predicted: 0.6716, Actual: 0\n",
            "Input: [4, 8, 6, 5, 8, 7, 9, 2, 9], Predicted: 0.5618, Actual: 0\n",
            "Input: [5, 4, 2, 8, 3, 5, 7, 8, 6], Predicted: 0.5424, Actual: 0\n",
            "Input: [1, 3, 6, 9, 1, 4, 5, 8, 6], Predicted: 0.5702, Actual: 0\n",
            "Input: [9, 5, 9, 5, 6, 1, 8, 3, 2], Predicted: 0.6559, Actual: 0\n",
            "Input: [1, 5, 7, 5, 4, 3, 4, 9, 8], Predicted: 0.5160, Actual: 0\n",
            "Input: [6, 4, 4, 2, 5, 9, 1, 6, 5], Predicted: 0.5013, Actual: 0\n",
            "Input: [9, 1, 2, 2, 8, 5, 3, 7, 6], Predicted: 0.6624, Actual: 0\n",
            "Input: [6, 5, 9, 4, 1, 3, 7, 9, 5], Predicted: 0.5572, Actual: 0\n",
            "Input: [5, 2, 5, 4, 7, 2, 7, 6, 8], Predicted: 0.5502, Actual: 0\n",
            "Input: [4, 9, 1, 5, 3, 6, 7, 7, 2], Predicted: 0.6600, Actual: 0\n",
            "Input: [6, 9, 6, 1, 3, 7, 5, 1, 2], Predicted: 0.6109, Actual: 0\n",
            "Input: [1, 9, 6, 7, 2, 4, 2, 6, 8], Predicted: 0.5414, Actual: 0\n",
            "Input: [3, 2, 8, 6, 9, 5, 6, 7, 5], Predicted: 0.5452, Actual: 0\n",
            "Input: [5, 6, 7, 3, 9, 8, 6, 6, 4], Predicted: 0.5360, Actual: 0\n",
            "Input: [4, 9, 5, 1, 2, 6, 7, 3, 5], Predicted: 0.8315, Actual: 0\n",
            "Input: [6, 1, 8, 5, 9, 3, 1, 5, 7], Predicted: 0.5137, Actual: 0\n",
            "Input: [1, 5, 5, 7, 8, 2, 9, 7, 3], Predicted: 0.5067, Actual: 0\n",
            "Input: [7, 7, 6, 1, 2, 3, 4, 5, 9], Predicted: 0.7950, Actual: 0\n",
            "Input: [4, 1, 1, 6, 2, 3, 8, 5, 7], Predicted: 0.8424, Actual: 0\n",
            "Input: [3, 6, 2, 7, 9, 1, 4, 5, 3], Predicted: 0.6162, Actual: 0\n",
            "Input: [4, 6, 6, 7, 5, 2, 9, 1, 8], Predicted: 0.5737, Actual: 0\n",
            "Input: [9, 2, 6, 8, 8, 7, 5, 3, 1], Predicted: 0.5459, Actual: 0\n",
            "Input: [9, 3, 4, 2, 3, 9, 7, 5, 8], Predicted: 0.5026, Actual: 0\n",
            "Input: [9, 2, 9, 7, 2, 1, 8, 3, 5], Predicted: 0.5050, Actual: 0\n",
            "Input: [1, 3, 4, 4, 7, 1, 5, 8, 2], Predicted: 0.5292, Actual: 0\n",
            "Input: [5, 6, 9, 8, 3, 1, 3, 4, 7], Predicted: 0.7144, Actual: 0\n",
            "Input: [6, 1, 9, 3, 8, 2, 4, 6, 4], Predicted: 0.5862, Actual: 0\n",
            "Input: [7, 2, 6, 4, 2, 1, 3, 9, 7], Predicted: 0.5532, Actual: 0\n",
            "Input: [2, 8, 7, 5, 9, 7, 3, 4, 6], Predicted: 0.7386, Actual: 0\n",
            "Input: [7, 6, 4, 9, 8, 3, 2, 1, 7], Predicted: 0.6549, Actual: 0\n",
            "Input: [4, 5, 2, 9, 3, 9, 6, 8, 1], Predicted: 0.5154, Actual: 0\n",
            "Input: [7, 1, 4, 3, 3, 5, 9, 2, 6], Predicted: 0.5330, Actual: 0\n",
            "Input: [1, 3, 5, 9, 6, 2, 5, 8, 2], Predicted: 0.5531, Actual: 0\n",
            "Input: [4, 9, 3, 5, 8, 2, 1, 6, 8], Predicted: 0.6152, Actual: 0\n",
            "Input: [1, 7, 4, 4, 9, 7, 3, 2, 6], Predicted: 0.5768, Actual: 0\n",
            "Input: [3, 2, 6, 7, 5, 6, 1, 9, 4], Predicted: 0.5773, Actual: 0\n",
            "Input: [9, 2, 6, 1, 8, 4, 3, 6, 1], Predicted: 0.5699, Actual: 0\n",
            "Input: [2, 5, 6, 3, 4, 4, 9, 8, 1], Predicted: 0.5072, Actual: 0\n",
            "Input: [1, 8, 3, 2, 6, 6, 5, 4, 7], Predicted: 0.6223, Actual: 0\n",
            "Input: [9, 7, 8, 1, 8, 2, 1, 3, 5], Predicted: 0.6700, Actual: 0\n",
            "Input: [9, 4, 6, 7, 8, 5, 3, 1, 5], Predicted: 0.6048, Actual: 0\n",
            "Input: [9, 8, 5, 4, 7, 6, 4, 8, 2], Predicted: 0.7156, Actual: 0\n",
            "Input: [8, 9, 2, 4, 5, 3, 6, 7, 3], Predicted: 0.5482, Actual: 0\n",
            "Input: [8, 3, 7, 2, 5, 7, 4, 3, 6], Predicted: 0.5261, Actual: 0\n",
            "Input: [9, 6, 8, 8, 4, 3, 5, 1, 5], Predicted: 0.6420, Actual: 0\n",
            "Input: [7, 3, 1, 8, 4, 1, 6, 1, 9], Predicted: 0.6070, Actual: 0\n",
            "Input: [8, 4, 7, 6, 4, 9, 2, 2, 5], Predicted: 0.5205, Actual: 0\n",
            "Input: [1, 2, 3, 7, 7, 5, 9, 8, 2], Predicted: 0.6114, Actual: 0\n",
            "Input: [5, 8, 7, 2, 1, 5, 9, 3, 4], Predicted: 0.7152, Actual: 0\n",
            "Input: [5, 1, 9, 6, 7, 8, 2, 5, 3], Predicted: 0.6865, Actual: 0\n",
            "Input: [6, 3, 4, 2, 2, 9, 7, 5, 1], Predicted: 0.6433, Actual: 0\n",
            "Input: [1, 8, 9, 5, 3, 4, 7, 6, 1], Predicted: 0.6274, Actual: 0\n",
            "Input: [5, 2, 5, 3, 1, 7, 7, 4, 1], Predicted: 0.5460, Actual: 0\n",
            "Input: [9, 5, 3, 7, 9, 1, 2, 4, 8], Predicted: 0.7453, Actual: 0\n",
            "Input: [5, 2, 6, 7, 6, 9, 1, 8, 4], Predicted: 0.6374, Actual: 0\n",
            "Input: [9, 2, 1, 4, 6, 1, 8, 2, 3], Predicted: 0.6171, Actual: 0\n",
            "Input: [1, 4, 7, 3, 9, 1, 2, 6, 3], Predicted: 0.5561, Actual: 0\n",
            "Input: [2, 9, 3, 5, 7, 1, 2, 4, 4], Predicted: 0.5595, Actual: 0\n",
            "Input: [7, 2, 5, 4, 6, 4, 9, 8, 1], Predicted: 0.6836, Actual: 0\n",
            "Input: [5, 3, 8, 2, 4, 9, 1, 9, 7], Predicted: 0.5520, Actual: 0\n",
            "Input: [5, 9, 6, 3, 1, 5, 4, 2, 7], Predicted: 0.5769, Actual: 0\n",
            "Input: [8, 3, 8, 5, 6, 2, 4, 1, 1], Predicted: 0.5602, Actual: 0\n",
            "Input: [5, 4, 6, 6, 1, 3, 8, 5, 3], Predicted: 0.5155, Actual: 0\n",
            "Input: [8, 1, 4, 3, 8, 9, 3, 2, 5], Predicted: 0.5088, Actual: 0\n",
            "Input: [1, 3, 7, 2, 7, 2, 9, 5, 8], Predicted: 0.6688, Actual: 0\n",
            "Input: [2, 4, 9, 8, 9, 4, 1, 5, 6], Predicted: 0.5105, Actual: 0\n",
            "Input: [7, 5, 1, 3, 9, 6, 5, 2, 8], Predicted: 0.5887, Actual: 0\n",
            "Input: [4, 3, 1, 6, 5, 8, 4, 7, 7], Predicted: 0.5516, Actual: 0\n",
            "Input: [4, 1, 5, 7, 8, 2, 1, 7, 9], Predicted: 0.5005, Actual: 0\n",
            "Input: [1, 8, 6, 5, 5, 2, 9, 3, 4], Predicted: 0.7367, Actual: 0\n",
            "Input: [8, 3, 4, 2, 7, 9, 6, 9, 1], Predicted: 0.7998, Actual: 0\n",
            "Input: [3, 7, 3, 9, 6, 5, 4, 2, 9], Predicted: 0.5478, Actual: 0\n",
            "Input: [5, 3, 8, 7, 1, 5, 4, 1, 2], Predicted: 0.5207, Actual: 0\n",
            "Input: [8, 4, 8, 1, 3, 6, 5, 1, 2], Predicted: 0.5412, Actual: 0\n",
            "Input: [2, 5, 3, 4, 6, 9, 1, 1, 7], Predicted: 0.6425, Actual: 0\n",
            "Input: [8, 7, 9, 4, 1, 5, 4, 2, 3], Predicted: 0.5393, Actual: 0\n",
            "Input: [8, 6, 9, 5, 3, 6, 4, 1, 1], Predicted: 0.5356, Actual: 0\n",
            "Input: [7, 2, 7, 6, 1, 5, 9, 6, 4], Predicted: 0.5822, Actual: 0\n",
            "Input: [3, 5, 1, 9, 5, 6, 2, 9, 1], Predicted: 0.5723, Actual: 0\n",
            "Input: [6, 6, 9, 5, 3, 4, 6, 7, 1], Predicted: 0.5668, Actual: 0\n",
            "Input: [5, 4, 7, 9, 8, 8, 2, 3, 6], Predicted: 0.6407, Actual: 0\n",
            "Input: [6, 3, 8, 9, 8, 2, 5, 3, 1], Predicted: 0.5431, Actual: 0\n",
            "Input: [3, 7, 1, 7, 9, 2, 1, 4, 8], Predicted: 0.6393, Actual: 0\n",
            "Input: [9, 7, 5, 8, 3, 2, 8, 4, 7], Predicted: 0.6728, Actual: 0\n",
            "Input: [3, 8, 6, 2, 2, 9, 7, 1, 4], Predicted: 0.6861, Actual: 0\n",
            "Input: [2, 9, 2, 5, 1, 7, 3, 8, 6], Predicted: 0.5367, Actual: 0\n",
            "Input: [5, 7, 7, 8, 6, 2, 3, 4, 5], Predicted: 0.5135, Actual: 0\n",
            "Input: [9, 4, 6, 5, 8, 7, 2, 9, 7], Predicted: 0.5225, Actual: 0\n",
            "Input: [4, 3, 8, 5, 2, 7, 1, 6, 3], Predicted: 0.5085, Actual: 0\n",
            "Input: [3, 4, 9, 7, 6, 4, 7, 1, 2], Predicted: 0.5860, Actual: 0\n",
            "Input: [8, 1, 7, 3, 2, 6, 6, 7, 4], Predicted: 0.5444, Actual: 0\n",
            "Input: [3, 8, 5, 6, 1, 9, 8, 7, 2], Predicted: 0.5742, Actual: 0\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nAnalyzing misclassified training examples from training data:\")\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad(): # Disable gradient tracking\n",
        "    final_preds = model(X_train_oh)\n",
        "    final_preds_bin = (final_preds > 0.5).float()\n",
        "    incorrect_indices = (final_preds_bin != y_train).nonzero(as_tuple=True)[0]\n",
        "\n",
        "    if len(incorrect_indices) == 0:\n",
        "        print(\"All training examples were predicted correctly!\")\n",
        "    else:\n",
        "        print(f\"Misclassified training examples {len(incorrect_indices)}:\")\n",
        "        for i in incorrect_indices:\n",
        "            original_input = X_train[i].tolist() # Get original digits, not one-hot\n",
        "            predicted_value = final_preds[i].item()\n",
        "            true_label = y_train[i].item()\n",
        "            print(f\"Input: {original_input}, Predicted: {predicted_value:.4f}, Actual: {int(true_label)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frXyefbsV63J",
        "outputId": "2ad92d93-884d-4292-898e-1f53f07d3f07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learned Parameters:\n",
            "Parameter: raw_attention.Wq.weight, Value: tensor([[ 0.5477, -0.0366,  0.1062, -0.7744, -0.4338, -0.4307,  0.7363,  0.0732,\n",
            "         -0.1985],\n",
            "        [-0.1114,  0.7091, -0.3124,  0.5589, -0.4155, -0.6528,  0.4183, -0.5023,\n",
            "          0.0408],\n",
            "        [ 0.5418,  0.4839, -0.9124, -0.2684,  0.1241,  0.0243,  0.0832,  1.2510,\n",
            "         -0.4712],\n",
            "        [-0.5264,  0.5337,  0.8134, -0.3640, -0.4603,  0.1032, -0.1016,  0.0036,\n",
            "         -0.3987],\n",
            "        [-0.5089,  0.4652,  0.2729, -0.6537,  0.8158, -0.4725, -0.4494, -0.0639,\n",
            "          0.7105],\n",
            "        [ 0.1830,  0.6322, -1.0218, -0.2257,  0.4617,  0.3037,  0.4557, -0.6404,\n",
            "         -0.3768],\n",
            "        [ 0.3750,  0.0022, -0.5381,  0.0483,  0.0513, -0.6253, -0.7698,  0.4334,\n",
            "          0.4935],\n",
            "        [ 0.7165, -0.1155,  1.1301, -0.1698,  0.3438,  0.3168, -0.5389, -0.1317,\n",
            "         -0.5720],\n",
            "        [ 0.1692,  0.3521, -0.6486, -0.0646, -0.6996,  0.3671, -0.0946, -0.1256,\n",
            "          0.8814]])\n",
            "Parameter: raw_attention.Wk.weight, Value: tensor([[-0.6432,  0.1323,  0.4360,  0.2923, -0.6473,  0.2847,  0.2708,  0.3992,\n",
            "         -0.1425],\n",
            "        [-0.8367, -0.9477, -0.7159, -1.0491, -0.1569, -0.3527,  0.0172, -0.1427,\n",
            "         -0.0099],\n",
            "        [-0.2205,  0.2034,  0.8252,  0.6973,  0.4780, -0.4302, -0.3175, -0.7030,\n",
            "          1.0855],\n",
            "        [ 0.4039, -0.6082,  0.0903,  0.0897, -0.9316, -0.4290,  0.1413,  0.3974,\n",
            "          0.1462],\n",
            "        [ 0.2112, -0.6875, -0.1489,  0.3814,  0.7921,  0.2898,  0.8941,  0.5682,\n",
            "          0.2255],\n",
            "        [-0.6084,  0.3417, -0.4178,  0.2322,  0.3451, -1.0096,  0.0751, -0.1063,\n",
            "          0.7055],\n",
            "        [ 0.0263, -0.1907,  0.2312,  0.3395,  1.0612,  0.6002, -0.8330, -0.2691,\n",
            "          0.1261],\n",
            "        [ 0.3066,  0.1238,  0.6917, -0.4025,  0.0113, -0.2616, -1.0625,  1.1746,\n",
            "          0.0801],\n",
            "        [-0.2706, -0.2793, -0.4417,  0.6536,  0.4328, -0.6814, -0.9633, -0.6890,\n",
            "         -0.4994]])\n",
            "Parameter: raw_attention.Wv.weight, Value: tensor([[ 0.4648, -0.3341, -0.3951, -0.4157, -1.0035,  0.7075,  0.8091, -1.4081,\n",
            "          0.7129],\n",
            "        [ 0.3369,  0.4889, -0.4894,  0.3068,  0.1068,  0.6710, -0.4600,  0.5681,\n",
            "          0.1452],\n",
            "        [ 0.1695,  0.3411, -0.9809,  0.5114,  0.1069,  0.2618, -0.3418,  0.1729,\n",
            "          0.6344],\n",
            "        [-0.0041,  0.6683, -0.1602,  0.8695, -0.6689,  0.1616,  0.4584,  0.1926,\n",
            "          0.0326],\n",
            "        [ 0.6727,  1.0321, -0.3995,  0.8024, -0.6007, -0.6822,  0.6795, -0.5880,\n",
            "         -1.1736],\n",
            "        [ 0.6331,  0.4530, -0.4326,  0.7278,  0.5850,  0.1598,  0.7770,  0.5456,\n",
            "         -0.2710],\n",
            "        [ 0.7774,  0.3726, -0.5749, -0.0723, -0.3014,  0.0313, -0.3861, -0.2768,\n",
            "          0.3259],\n",
            "        [-0.1056,  0.2570, -0.8939,  0.0065, -0.0882,  0.0016, -0.6713,  1.0526,\n",
            "          0.1020],\n",
            "        [ 0.6682, -0.0191, -0.5733,  0.0726, -0.2033,  0.1714, -0.4469,  0.5032,\n",
            "          1.2835]])\n",
            "Parameter: readout.weight, Value: tensor([[ 1.2671e-02,  2.1618e-01, -1.1663e-01,  3.5465e-02,  1.2086e-01,\n",
            "         -5.9911e-02,  1.3807e-01,  2.0734e-01,  1.7006e-01, -1.5894e-02,\n",
            "          1.9167e-01,  1.5507e-02,  2.1925e-01, -7.2510e-02,  7.2572e-02,\n",
            "          1.5520e-01,  3.3028e-02,  1.0600e-01,  2.3878e-02,  1.8065e-01,\n",
            "          2.3518e-01,  6.4606e-02,  2.3294e-02,  6.8259e-03,  1.2601e-01,\n",
            "          9.9051e-02, -3.0521e-02, -9.5387e-02,  1.4357e-01,  1.0721e-01,\n",
            "          1.2263e-01, -7.1438e-02, -1.4521e-02,  2.7109e-01, -9.6353e-03,\n",
            "          1.1029e-01, -8.1309e-02,  1.6129e-01,  2.1592e-01,  2.2030e-01,\n",
            "          3.6914e-02, -9.5498e-02,  1.2917e-01, -5.5947e-02,  1.1393e-01,\n",
            "          5.5252e-02,  2.6217e-01, -1.2401e-01,  2.0055e-01, -6.8651e-02,\n",
            "          5.2466e-02,  1.8543e-01,  4.8538e-02,  2.2406e-01, -1.1135e-02,\n",
            "          3.0716e-01, -9.9100e-03,  1.7108e-01, -1.9832e-02,  2.6565e-02,\n",
            "          2.2471e-01,  2.4163e-02,  5.5775e-02, -5.9099e-02,  1.0356e-01,\n",
            "          8.8308e-02,  1.0357e-01,  3.9254e-02, -7.1192e-02,  1.6806e-01,\n",
            "          4.6541e-02,  2.0055e-01, -3.2618e-02,  2.9297e-01, -1.8996e-03,\n",
            "          1.4478e-01, -1.3220e-04, -1.1223e-02,  2.2077e-01, -1.7591e-02,\n",
            "          1.2256e-01]])\n",
            "Parameter: readout.bias, Value: tensor([0.0798])\n"
          ]
        }
      ],
      "source": [
        "print('Learned Parameters:')\n",
        "for name, param in model.named_parameters():\n",
        "    print(f'Parameter: {name}, Value: {param.data}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "23d6c280",
        "outputId": "e40e62ae-ff52-4dd3-f3c2-8a6b6b2074ce"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "#plt.plot(loss_history[:1500], label='Training Loss')\n",
        "#plt.plot(loss_history[200:], label='Training Loss')\n",
        "plt.plot(loss_history[10:], label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss History')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JglXlC03WBL2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMg0g95c927T",
        "outputId": "f109bbfe-683c-4cbe-f827-bdfb352f6d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss never reached threshold.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "losses = np.array(loss_history)\n",
        "THRESHOLD = 0.001\n",
        "\n",
        "# Find first epoch where loss goes below threshold\n",
        "below_idx = np.where(losses <= THRESHOLD)[0]\n",
        "\n",
        "if len(below_idx) == 0:\n",
        "    print(\"Loss never reached threshold.\")\n",
        "else:\n",
        "    start = below_idx[0]\n",
        "\n",
        "    max_after = losses[start:].max()\n",
        "    print(\"Max value after threshold: \",max_after)\n",
        "\n",
        "    increases = np.where(losses[start+1:] > losses[start:-1])[0]\n",
        "\n",
        "    if len(increases) == 0:\n",
        "        print(\"No loss increases after convergence.\")\n",
        "    else:\n",
        "        print(f\"Loss increased {len(increases)} times after reaching {THRESHOLD}.\")\n",
        "        for i in increases[:10]:  # show first few\n",
        "            e = start + i + 1\n",
        "            print(\n",
        "                f\"Epoch {e}: \"\n",
        "                f\"{losses[e-1]:.6f} â†’ {losses[e]:.6f}\"\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4tHZwM04LLK",
        "outputId": "c207c8c5-f11c-4a70-912f-eb348f61010a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: torch.Size([2177, 9, 9]) torch.Size([2177, 1])\n",
            "Val:   torch.Size([723583, 9, 9]) torch.Size([723583, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "# -----------------------------\n",
        "# Parameters\n",
        "# -----------------------------\n",
        "num_symbols = 9\n",
        "train_frac = 0.003\n",
        "\n",
        "# -----------------------------\n",
        "# Generate ALL valid permutations\n",
        "# -----------------------------\n",
        "valid_sequences = list(itertools.permutations(range(1, num_symbols + 1)))\n",
        "valid_labels = [1.0] * len(valid_sequences)\n",
        "\n",
        "# -----------------------------\n",
        "# Generate invalid sequences\n",
        "# -----------------------------\n",
        "def generate_invalid(num_samples):\n",
        "    invalid = set()\n",
        "    while len(invalid) < num_samples:\n",
        "        seq = [random.randint(1, num_symbols) for _ in range(num_symbols)]\n",
        "        if len(set(seq)) != num_symbols:  # invalid condition\n",
        "            invalid.add(tuple(seq))\n",
        "    return list(invalid)\n",
        "\n",
        "num_invalid = len(valid_sequences)\n",
        "invalid_sequences = generate_invalid(num_invalid)\n",
        "invalid_labels = [0.0] * num_invalid\n",
        "\n",
        "# -----------------------------\n",
        "# Combine & shuffle\n",
        "# -----------------------------\n",
        "all_sequences = valid_sequences + invalid_sequences\n",
        "all_labels = valid_labels + invalid_labels\n",
        "\n",
        "combined = list(zip(all_sequences, all_labels))\n",
        "random.shuffle(combined)\n",
        "\n",
        "# -----------------------------\n",
        "# Train / validation split\n",
        "# -----------------------------\n",
        "split_idx = int(len(combined) * train_frac)\n",
        "\n",
        "train_data = combined[:split_idx]\n",
        "val_data   = combined[split_idx:]\n",
        "\n",
        "# -----------------------------\n",
        "# Ensure NO overlap (sanity check)\n",
        "# -----------------------------\n",
        "train_set = set(seq for seq, _ in train_data)\n",
        "val_set   = set(seq for seq, _ in val_data)\n",
        "\n",
        "assert train_set.isdisjoint(val_set), \"Train / validation overlap detected!\"\n",
        "\n",
        "# -----------------------------\n",
        "# Convert to tensors\n",
        "# -----------------------------\n",
        "def to_tensors(data):\n",
        "    X = torch.tensor([seq for seq, _ in data], dtype=torch.long)\n",
        "    y = torch.tensor([[label] for _, label in data], dtype=torch.float)\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = to_tensors(train_data)\n",
        "X_val,   y_val   = to_tensors(val_data)\n",
        "\n",
        "# -----------------------------\n",
        "# One-hot encode\n",
        "# -----------------------------\n",
        "X_train_oh = torch.nn.functional.one_hot(X_train - 1, num_classes=num_symbols).float()\n",
        "X_val_oh   = torch.nn.functional.one_hot(X_val - 1,   num_classes=num_symbols).float()\n",
        "\n",
        "# -----------------------------\n",
        "# Final shapes\n",
        "# -----------------------------\n",
        "print(\"Train:\", X_train_oh.shape, y_train.shape)\n",
        "print(\"Val:  \", X_val_oh.shape, y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFyD3Yu8BA1e",
        "outputId": "9df8dfe2-9a1d-4940-8e74-4544bbec08b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss: 0.0966 | Val acc: 0.93\n"
          ]
        }
      ],
      "source": [
        "model.eval()              # switch to evaluation mode\n",
        "with torch.no_grad():     # disable gradient tracking\n",
        "    val_preds = model(X_val_oh)   # (val_batch, 1)\n",
        "    val_loss = loss_fn(val_preds, y_val)\n",
        "    val_preds_bin = (val_preds > 0.5).float()\n",
        "    val_acc = (val_preds_bin == y_val).float().mean()\n",
        "    print(\n",
        "            f\"Val loss: {val_loss.item():.4f} | \"\n",
        "            f\"Val acc: {val_acc.item():.2f}\"\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE_dYCxEHJP0",
        "outputId": "acf3b8dd-e5ba-4a86-9075-ac991bc8104e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch    0 | loss 103225.903334 | w 2.29398138 | b 6.40732693\n",
            "epoch   20 | loss 50257.947006 | w 27.51857569 | b 103.99519101\n",
            "epoch   40 | loss 25634.777274 | w 49.52485545 | b 169.14562702\n",
            "epoch   60 | loss 13887.447145 | w 68.72343373 | b 212.64057746\n",
            "epoch   80 | loss 8063.495225 | w 85.47253500 | b 241.67815310\n",
            "epoch  100 | loss 5020.104048 | w 100.08467915 | b 261.06387008\n",
            "epoch  120 | loss 3322.951849 | w 112.83251278 | b 274.00592928\n",
            "epoch  140 | loss 2307.213005 | w 123.95389653 | b 282.64615117\n",
            "epoch  160 | loss 1657.129866 | w 133.65634324 | b 288.41443218\n",
            "epoch  180 | loss 1217.169728 | w 142.12088994 | b 292.26538257\n",
            "epoch  200 | loss 906.747703 | w 149.50547580 | b 294.83630774\n",
            "epoch  220 | loss 681.374057 | w 155.94788912 | b 296.55267789\n",
            "epoch  240 | loss 514.694728 | w 161.56833828 | b 297.69854027\n",
            "epoch  260 | loss 389.997510 | w 166.47169470 | b 298.46352714\n",
            "epoch  280 | loss 296.053968 | w 170.74944965 | b 298.97423847\n",
            "epoch  300 | loss 224.982764 | w 174.48142135 | b 299.31519343\n",
            "epoch  320 | loss 171.081615 | w 177.73724430 | b 299.54281767\n",
            "epoch  340 | loss 130.142521 | w 180.57766861 | b 299.69478143\n",
            "epoch  360 | loss 99.021599 | w 183.05569347 | b 299.79623365\n",
            "epoch  380 | loss 75.352251 | w 185.21755613 | b 299.86396396\n",
            "epoch  400 | loss 57.344937 | w 187.10359456 | b 299.90918126\n",
            "epoch  420 | loss 43.642840 | w 188.74900019 | b 299.93936868\n",
            "epoch  440 | loss 33.215600 | w 190.18447447 | b 299.95952205\n",
            "epoch  460 | loss 25.280039 | w 191.43680180 | b 299.97297660\n",
            "epoch  480 | loss 19.240538 | w 192.52934922 | b 299.98195896\n",
            "epoch  500 | loss 14.643973 | w 193.48250247 | b 299.98795566\n",
            "epoch  520 | loss 11.145561 | w 194.31404636 | b 299.99195910\n",
            "epoch  540 | loss 8.482927 | w 195.03949658 | b 299.99463183\n",
            "epoch  560 | loss 6.456393 | w 195.67238923 | b 299.99641617\n",
            "epoch  580 | loss 4.913992 | w 196.22453340 | b 299.99760741\n",
            "epoch  600 | loss 3.740065 | w 196.70623150 | b 299.99840268\n",
            "epoch  620 | loss 2.846583 | w 197.12647148 | b 299.99893362\n",
            "epoch  640 | loss 2.166550 | w 197.49309457 | b 299.99928808\n",
            "epoch  660 | loss 1.648973 | w 197.81294155 | b 299.99952471\n",
            "epoch  680 | loss 1.255042 | w 198.09198041 | b 299.99968270\n",
            "epoch  700 | loss 0.955220 | w 198.33541771 | b 299.99978816\n",
            "epoch  720 | loss 0.727023 | w 198.54779573 | b 299.99985858\n",
            "epoch  740 | loss 0.553341 | w 198.73307721 | b 299.99990558\n",
            "epoch  760 | loss 0.421151 | w 198.89471930 | b 299.99993697\n",
            "epoch  780 | loss 0.320540 | w 199.03573806 | b 299.99995792\n",
            "epoch  800 | loss 0.243965 | w 199.15876474 | b 299.99997191\n",
            "epoch  820 | loss 0.185683 | w 199.26609490 | b 299.99998124\n",
            "epoch  840 | loss 0.141324 | w 199.35973119 | b 299.99998748\n",
            "epoch  860 | loss 0.107563 | w 199.44142077 | b 299.99999164\n",
            "epoch  880 | loss 0.081867 | w 199.51268787 | b 299.99999442\n",
            "epoch  900 | loss 0.062309 | w 199.57486226 | b 299.99999627\n",
            "epoch  920 | loss 0.047424 | w 199.62910404 | b 299.99999751\n",
            "epoch  940 | loss 0.036095 | w 199.67642531 | b 299.99999834\n",
            "epoch  960 | loss 0.027472 | w 199.71770903 | b 299.99999889\n",
            "epoch  980 | loss 0.020909 | w 199.75372551 | b 299.99999926\n",
            "epoch 1000 | loss 0.015914 | w 199.78514678 | b 299.99999951\n",
            "epoch 1020 | loss 0.012112 | w 199.81255913 | b 299.99999967\n",
            "epoch 1040 | loss 0.009219 | w 199.83647403 | b 299.99999978\n",
            "epoch 1060 | loss 0.007016 | w 199.85733771 | b 299.99999985\n",
            "epoch 1080 | loss 0.005340 | w 199.87553948 | b 299.99999990\n",
            "epoch 1100 | loss 0.004064 | w 199.89141895 | b 299.99999993\n",
            "epoch 1120 | loss 0.003093 | w 199.90527241 | b 299.99999996\n",
            "epoch 1140 | loss 0.002354 | w 199.91735836 | b 299.99999997\n",
            "epoch 1160 | loss 0.001792 | w 199.92790231 | b 299.99999998\n",
            "epoch 1180 | loss 0.001364 | w 199.93710099 | b 299.99999999\n",
            "epoch 1200 | loss 0.001038 | w 199.94512605 | b 299.99999999\n",
            "epoch 1220 | loss 0.000790 | w 199.95212722 | b 299.99999999\n",
            "epoch 1240 | loss 0.000601 | w 199.95823513 | b 300.00000000\n",
            "epoch 1260 | loss 0.000458 | w 199.96356376 | b 300.00000000\n",
            "epoch 1280 | loss 0.000348 | w 199.96821253 | b 300.00000000\n",
            "epoch 1300 | loss 0.000265 | w 199.97226818 | b 300.00000000\n",
            "epoch 1320 | loss 0.000202 | w 199.97580638 | b 300.00000000\n",
            "epoch 1340 | loss 0.000154 | w 199.97889315 | b 300.00000000\n",
            "epoch 1360 | loss 0.000117 | w 199.98158610 | b 300.00000000\n",
            "epoch 1380 | loss 0.000089 | w 199.98393546 | b 300.00000000\n",
            "epoch 1400 | loss 0.000068 | w 199.98598508 | b 300.00000000\n",
            "epoch 1420 | loss 0.000052 | w 199.98777319 | b 300.00000000\n",
            "epoch 1440 | loss 0.000039 | w 199.98933317 | b 300.00000000\n",
            "epoch 1460 | loss 0.000030 | w 199.99069411 | b 300.00000000\n",
            "epoch 1480 | loss 0.000023 | w 199.99188141 | b 300.00000000\n",
            "epoch 1500 | loss 0.000017 | w 199.99291723 | b 300.00000000\n",
            "epoch 1520 | loss 0.000013 | w 199.99382090 | b 300.00000000\n",
            "epoch 1540 | loss 0.000010 | w 199.99460927 | b 300.00000000\n",
            "epoch 1560 | loss 0.000008 | w 199.99529705 | b 300.00000000\n",
            "epoch 1580 | loss 0.000006 | w 199.99589708 | b 300.00000000\n",
            "epoch 1600 | loss 0.000004 | w 199.99642056 | b 300.00000000\n",
            "epoch 1620 | loss 0.000003 | w 199.99687725 | b 300.00000000\n",
            "epoch 1640 | loss 0.000003 | w 199.99727567 | b 300.00000000\n",
            "epoch 1660 | loss 0.000002 | w 199.99762326 | b 300.00000000\n",
            "epoch 1680 | loss 0.000001 | w 199.99792650 | b 300.00000000\n",
            "epoch 1700 | loss 0.000001 | w 199.99819105 | b 300.00000000\n",
            "epoch 1720 | loss 0.000001 | w 199.99842184 | b 300.00000000\n",
            "epoch 1740 | loss 0.000001 | w 199.99862320 | b 300.00000000\n",
            "epoch 1760 | loss 0.000000 | w 199.99879886 | b 300.00000000\n",
            "epoch 1780 | loss 0.000000 | w 199.99895211 | b 300.00000000\n",
            "epoch 1800 | loss 0.000000 | w 199.99908580 | b 300.00000000\n",
            "epoch 1820 | loss 0.000000 | w 199.99920244 | b 300.00000000\n",
            "epoch 1840 | loss 0.000000 | w 199.99930420 | b 300.00000000\n",
            "epoch 1860 | loss 0.000000 | w 199.99939297 | b 300.00000000\n",
            "epoch 1880 | loss 0.000000 | w 199.99947042 | b 300.00000000\n",
            "epoch 1900 | loss 0.000000 | w 199.99953799 | b 300.00000000\n",
            "epoch 1920 | loss 0.000000 | w 199.99959694 | b 300.00000000\n",
            "epoch 1940 | loss 0.000000 | w 199.99964836 | b 300.00000000\n",
            "epoch 1960 | loss 0.000000 | w 199.99969323 | b 300.00000000\n",
            "epoch 1980 | loss 0.000000 | w 199.99973237 | b 300.00000000\n",
            "epoch 2000 | loss 0.000000 | w 199.99976651 | b 300.00000000\n",
            "epoch 2020 | loss 0.000000 | w 199.99979630 | b 300.00000000\n",
            "epoch 2040 | loss 0.000000 | w 199.99982229 | b 300.00000000\n",
            "epoch 2060 | loss 0.000000 | w 199.99984496 | b 300.00000000\n",
            "epoch 2080 | loss 0.000000 | w 199.99986474 | b 300.00000000\n",
            "epoch 2100 | loss 0.000000 | w 199.99988200 | b 300.00000000\n",
            "epoch 2120 | loss 0.000000 | w 199.99989706 | b 300.00000000\n",
            "epoch 2140 | loss 0.000000 | w 199.99991019 | b 300.00000000\n",
            "epoch 2160 | loss 0.000000 | w 199.99992165 | b 300.00000000\n",
            "epoch 2180 | loss 0.000000 | w 199.99993165 | b 300.00000000\n",
            "epoch 2200 | loss 0.000000 | w 199.99994037 | b 300.00000000\n",
            "epoch 2220 | loss 0.000000 | w 199.99994798 | b 300.00000000\n",
            "epoch 2240 | loss 0.000000 | w 199.99995461 | b 300.00000000\n",
            "epoch 2260 | loss 0.000000 | w 199.99996040 | b 300.00000000\n",
            "epoch 2280 | loss 0.000000 | w 199.99996546 | b 300.00000000\n",
            "epoch 2300 | loss 0.000000 | w 199.99996986 | b 300.00000000\n",
            "epoch 2320 | loss 0.000000 | w 199.99997371 | b 300.00000000\n",
            "epoch 2340 | loss 0.000000 | w 199.99997706 | b 300.00000000\n",
            "epoch 2360 | loss 0.000000 | w 199.99997999 | b 300.00000000\n",
            "epoch 2380 | loss 0.000000 | w 199.99998254 | b 300.00000000\n",
            "epoch 2400 | loss 0.000000 | w 199.99998477 | b 300.00000000\n",
            "epoch 2420 | loss 0.000000 | w 199.99998671 | b 300.00000000\n",
            "epoch 2440 | loss 0.000000 | w 199.99998841 | b 300.00000000\n",
            "epoch 2460 | loss 0.000000 | w 199.99998989 | b 300.00000000\n",
            "epoch 2480 | loss 0.000000 | w 199.99999118 | b 300.00000000\n",
            "epoch 2500 | loss 0.000000 | w 199.99999230 | b 300.00000000\n",
            "epoch 2520 | loss 0.000000 | w 199.99999328 | b 300.00000000\n",
            "epoch 2540 | loss 0.000000 | w 199.99999414 | b 300.00000000\n",
            "epoch 2560 | loss 0.000000 | w 199.99999489 | b 300.00000000\n",
            "epoch 2580 | loss 0.000000 | w 199.99999554 | b 300.00000000\n",
            "epoch 2600 | loss 0.000000 | w 199.99999611 | b 300.00000000\n",
            "epoch 2620 | loss 0.000000 | w 199.99999661 | b 300.00000000\n",
            "epoch 2640 | loss 0.000000 | w 199.99999704 | b 300.00000000\n",
            "epoch 2660 | loss 0.000000 | w 199.99999742 | b 300.00000000\n",
            "epoch 2680 | loss 0.000000 | w 199.99999775 | b 300.00000000\n",
            "epoch 2700 | loss 0.000000 | w 199.99999803 | b 300.00000000\n",
            "epoch 2720 | loss 0.000000 | w 199.99999828 | b 300.00000000\n",
            "epoch 2740 | loss 0.000000 | w 199.99999850 | b 300.00000000\n",
            "epoch 2760 | loss 0.000000 | w 199.99999869 | b 300.00000000\n",
            "epoch 2780 | loss 0.000000 | w 199.99999886 | b 300.00000000\n",
            "epoch 2800 | loss 0.000000 | w 199.99999901 | b 300.00000000\n",
            "epoch 2820 | loss 0.000000 | w 199.99999913 | b 300.00000000\n",
            "epoch 2840 | loss 0.000000 | w 199.99999924 | b 300.00000000\n",
            "epoch 2860 | loss 0.000000 | w 199.99999934 | b 300.00000000\n",
            "epoch 2880 | loss 0.000000 | w 199.99999942 | b 300.00000000\n",
            "epoch 2900 | loss 0.000000 | w 199.99999950 | b 300.00000000\n",
            "epoch 2920 | loss 0.000000 | w 199.99999956 | b 300.00000000\n",
            "epoch 2940 | loss 0.000000 | w 199.99999962 | b 300.00000000\n",
            "epoch 2960 | loss 0.000000 | w 199.99999967 | b 300.00000000\n",
            "epoch 2980 | loss 0.000000 | w 199.99999971 | b 300.00000000\n",
            "epoch 3000 | loss 0.000000 | w 199.99999975 | b 300.00000000\n",
            "epoch 3020 | loss 0.000000 | w 199.99999978 | b 300.00000000\n",
            "epoch 3040 | loss 0.000000 | w 199.99999981 | b 300.00000000\n",
            "epoch 3060 | loss 0.000000 | w 199.99999983 | b 300.00000000\n",
            "epoch 3080 | loss 0.000000 | w 199.99999985 | b 300.00000000\n",
            "epoch 3100 | loss 0.000000 | w 199.99999987 | b 300.00000000\n",
            "epoch 3120 | loss 0.000000 | w 199.99999989 | b 300.00000000\n",
            "epoch 3140 | loss 0.000000 | w 199.99999990 | b 300.00000000\n",
            "epoch 3160 | loss 0.000000 | w 199.99999991 | b 300.00000000\n",
            "epoch 3180 | loss 0.000000 | w 199.99999993 | b 300.00000000\n",
            "epoch 3200 | loss 0.000000 | w 199.99999994 | b 300.00000000\n",
            "epoch 3220 | loss 0.000000 | w 199.99999994 | b 300.00000000\n",
            "epoch 3240 | loss 0.000000 | w 199.99999995 | b 300.00000000\n",
            "epoch 3260 | loss 0.000000 | w 199.99999996 | b 300.00000000\n",
            "epoch 3280 | loss 0.000000 | w 199.99999996 | b 300.00000000\n",
            "epoch 3300 | loss 0.000000 | w 199.99999997 | b 300.00000000\n",
            "epoch 3320 | loss 0.000000 | w 199.99999997 | b 300.00000000\n",
            "epoch 3340 | loss 0.000000 | w 199.99999998 | b 300.00000000\n",
            "epoch 3360 | loss 0.000000 | w 199.99999998 | b 300.00000000\n",
            "epoch 3380 | loss 0.000000 | w 199.99999998 | b 300.00000000\n",
            "epoch 3400 | loss 0.000000 | w 199.99999998 | b 300.00000000\n",
            "epoch 3420 | loss 0.000000 | w 199.99999999 | b 300.00000000\n",
            "epoch 3440 | loss 0.000000 | w 199.99999999 | b 300.00000000\n",
            "epoch 3460 | loss 0.000000 | w 199.99999999 | b 300.00000000\n",
            "epoch 3480 | loss 0.000000 | w 199.99999999 | b 300.00000000\n",
            "epoch 3500 | loss 0.000000 | w 199.99999999 | b 300.00000000\n",
            "epoch 3520 | loss 0.000000 | w 199.99999999 | b 300.00000000\n",
            "epoch 3540 | loss 0.000000 | w 199.99999999 | b 300.00000000\n",
            "epoch 3560 | loss 0.000000 | w 199.99999999 | b 300.00000000\n",
            "epoch 3580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 3980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 4980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 5980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 6980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 7980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 8980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 9980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 10980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 11980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 12980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 13980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 14980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 15980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 16980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 17980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 18980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19000 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19020 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19040 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19060 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19080 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19100 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19120 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19140 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19160 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19180 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19200 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19220 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19240 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19260 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19280 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19300 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19320 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19340 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19360 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19380 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19400 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19420 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19440 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19460 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19480 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19500 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19520 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19540 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19560 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19580 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19600 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19620 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19640 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19660 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19680 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19700 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19720 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19740 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19760 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19780 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19800 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19820 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19840 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19860 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19880 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19900 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19920 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19940 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19960 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "epoch 19980 | loss 0.000000 | w 200.00000000 | b 300.00000000\n",
            "weight 199.99999999999793 1.4052611823908686e-12\n",
            "bias 299.99999999999864 2.721662895055488e-12\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(0)\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "# Perfect data\n",
        "x = torch.linspace(-1, 1, 100).unsqueeze(1)\n",
        "y = 200 * x + 300\n",
        "\n",
        "# Linear model\n",
        "model = torch.nn.Linear(1, 1)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)  # try 1e-1, 1e-3\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(20000):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(x)\n",
        "    loss = criterion(y_pred, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        w = model.weight.item()\n",
        "        b = model.bias.item()\n",
        "        print(f\"epoch {epoch:4d} | loss {loss.item():.6f} | w {w:.8f} | b {b:.8f}\")\n",
        "\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    #if param.grad is not None:\n",
        "        print(name, param.norm().item(), param.grad.norm().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "NEvcyL9NIvQ_",
        "outputId": "0eaa55df-9576-4c29-c52d-109f77cd6e34"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "LBFGS.step() missing 1 required positional argument: 'closure'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2559719946.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m                             )\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LBFGS.step() missing 1 required positional argument: 'closure'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# -------------------------------\n",
        "# Configuration\n",
        "# -------------------------------\n",
        "torch.manual_seed(0)\n",
        "torch.set_default_dtype(torch.float)\n",
        "\n",
        "N = 400      # number of inputs / weights\n",
        "SAMPLES = 500\n",
        "LR = 1e-2\n",
        "EPOCHS = 60000\n",
        "\n",
        "# -------------------------------\n",
        "# Perfect data\n",
        "# -------------------------------\n",
        "X = torch.randn(SAMPLES, N)\n",
        "true_w = torch.tensor([200.0 + i for i in range(N)])\n",
        "y = X @ true_w\n",
        "\n",
        "# -------------------------------\n",
        "# Linear model\n",
        "# -------------------------------\n",
        "model = torch.nn.Linear(N, 1, bias=True)\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "#optimizer = torch.optim.LBFGS(model.parameters(), lr=1.0)\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Training loop\n",
        "# -------------------------------\n",
        "for epoch in range(EPOCHS):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(X).squeeze()\n",
        "    loss = criterion(y_pred, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "        max_err = (model.weight.squeeze() - true_w).abs().max().item()\n",
        "        print(f\"epoch {epoch:4d} | loss {loss.item():.8f} | max weight error {max_err:.8f}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Final result\n",
        "# -------------------------------\n",
        "print(\"\\nTrue weights:\")\n",
        "print(true_w)\n",
        "\n",
        "print(\"\\nLearned weights:\")\n",
        "print(model.weight.detach().squeeze())\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    #if param.grad is not None:\n",
        "        print(name, param.norm().item(), param.grad.norm().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnS-ayk-S3QE",
        "outputId": "09dd6013-fbc5-44f5-de15-d3ecc8a39837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step  0 | loss 6.776e+07 | max weight error 1.265e+02\n",
            "step  1 | loss 1.837e+04 | max weight error 1.980e+01\n",
            "step  2 | loss 4.116e+02 | max weight error 2.714e+00\n",
            "step  3 | loss 6.664e+00 | max weight error 1.740e-01\n",
            "step  4 | loss 4.076e-02 | max weight error 1.755e-02\n",
            "step  5 | loss 2.904e-04 | max weight error 3.113e-03\n",
            "step  6 | loss 1.044e-05 | max weight error 1.572e-03\n",
            "step  7 | loss 3.825e-06 | max weight error 1.572e-03\n",
            "step  8 | loss 3.825e-06 | max weight error 1.572e-03\n",
            "step  9 | loss 3.825e-06 | max weight error 1.572e-03\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.set_default_dtype(torch.float)\n",
        "\n",
        "N = 400\n",
        "SAMPLES = 500\n",
        "\n",
        "X = torch.randn(SAMPLES, N)\n",
        "true_w = torch.tensor([200.0 + i for i in range(N)])\n",
        "y = X @ true_w\n",
        "\n",
        "model = torch.nn.Linear(N, 1, bias=True)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.LBFGS(\n",
        "    model.parameters(),\n",
        "    lr=1.0,                 # not a \"learning rate\" in the SGD sense\n",
        "    max_iter=20,            # iterations per step()\n",
        "    history_size=100,\n",
        "    line_search_fn=\"strong_wolfe\"\n",
        ")\n",
        "\n",
        "def closure():\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(X).squeeze()\n",
        "    loss = criterion(y_pred, y)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "# Run a few outer steps\n",
        "for step in range(10):\n",
        "    loss = optimizer.step(closure)\n",
        "    max_err = (model.weight.squeeze() - true_w).abs().max().item()\n",
        "    print(f\"step {step:2d} | loss {loss.item():.3e} | max weight error {max_err:.3e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e913444b"
      },
      "source": [
        "# Task\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import itertools\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Set default dtype for consistency\n",
        "torch.set_default_dtype(torch.float)\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "# --- 1. Encapsulate Model Definition ---\n",
        "class RawAttention(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.Wq = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.Wk = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.Wv = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        Q = self.Wq(x)\n",
        "        K = self.Wk(x)\n",
        "        V = self.Wv(x)\n",
        "        scores = torch.matmul(Q, K.transpose(1, 2)) / (self.d_model ** 0.5)\n",
        "        out = torch.matmul(scores, V)\n",
        "        return out\n",
        "\n",
        "class RawAttentionWithTopNeuron(nn.Module):\n",
        "    def __init__(self, d_model, seq_len):\n",
        "        super().__init__()\n",
        "        self.raw_attention = RawAttention(d_model)\n",
        "        self.readout = nn.Linear(d_model * seq_len, 1, bias=True)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        attended = self.raw_attention(x)\n",
        "        combined = attended + x  # Residual\n",
        "        out = self.readout(combined.reshape(combined.shape[0], -1))\n",
        "        return out\n",
        "\n",
        "def initialize_model_and_loss(d_model, seq_len):\n",
        "    \"\"\"Initializes the model and loss function.\"\"\"\n",
        "    model = RawAttentionWithTopNeuron(d_model, seq_len)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    return model, loss_fn\n",
        "\n",
        "# --- 2. Consolidate Data Generation ---\n",
        "def generate_data(num_symbols=9, train_frac=0.003, seed=0):\n",
        "    \"\"\"\n",
        "    Generates training and validation data for the permutation task.\n",
        "\n",
        "    Args:\n",
        "        num_symbols (int): The number of symbols (e.g., 9 for digits 1-9).\n",
        "        train_frac (float): The fraction of data to use for training.\n",
        "        seed (int): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_train_oh, y_train, X_val_oh, y_val, X_train_original, X_val_original)\n",
        "               where _oh refers to one-hot encoded and _original refers to non-one-hot.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Generate ALL valid permutations\n",
        "    valid_sequences = list(itertools.permutations(range(1, num_symbols + 1)))\n",
        "    valid_labels = [1.0] * len(valid_sequences)\n",
        "\n",
        "    # Generate invalid sequences\n",
        "    invalid = set()\n",
        "    num_invalid = len(valid_sequences) # Keep balance of valid/invalid for now\n",
        "    while len(invalid) < num_invalid:\n",
        "        seq = [random.randint(1, num_symbols) for _ in range(num_symbols)]\n",
        "        if len(set(seq)) != num_symbols:  # invalid condition\n",
        "            invalid.add(tuple(seq))\n",
        "    invalid_sequences = list(invalid)\n",
        "    invalid_labels = [0.0] * len(invalid_sequences)\n",
        "\n",
        "    # Combine & shuffle\n",
        "    all_sequences = valid_sequences + invalid_sequences\n",
        "    all_labels = valid_labels + invalid_labels\n",
        "    combined = list(zip(all_sequences, all_labels))\n",
        "    random.shuffle(combined)\n",
        "\n",
        "    # Train / validation split\n",
        "    split_idx = int(len(combined) * train_frac)\n",
        "    train_data = combined[:split_idx]\n",
        "    val_data = combined[split_idx:]\n",
        "\n",
        "    # Convert to tensors\n",
        "    def to_tensors(data):\n",
        "        X = torch.tensor([seq for seq, _ in data], dtype=torch.long)\n",
        "        y = torch.tensor([[label] for _, label in data], dtype=torch.float)\n",
        "        return X, y\n",
        "\n",
        "    X_train_original, y_train = to_tensors(train_data)\n",
        "    X_val_original, y_val = to_tensors(val_data)\n",
        "\n",
        "    # One-hot encode\n",
        "    X_train_oh = torch.nn.functional.one_hot(X_train_original - 1, num_classes=num_symbols).float()\n",
        "    X_val_oh = torch.nn.functional.one_hot(X_val_original - 1, num_classes=num_symbols).float()\n",
        "\n",
        "    print(f\"Data generated with {num_symbols} symbols, train_frac={train_frac}:\")\n",
        "    print(\"  Train:\", X_train_oh.shape, y_train.shape)\n",
        "    print(\"  Val:  \", X_val_oh.shape, y_val.shape)\n",
        "    return X_train_oh, y_train, X_val_oh, y_val, X_train_original, X_val_original\n",
        "\n",
        "# --- 3. Create Reusable Training Function ---\n",
        "def train_model(model, optimizer, loss_fn, X_train_oh, y_train, X_val_oh=None, y_val=None,\n",
        "                epochs=100, batch_size=None, optimizer_type='adamw', custom_update_fn=None,\n",
        "                log_interval=100, log_verbose=True):\n",
        "    \"\"\"\n",
        "    Trains the model and records loss history.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer to use.\n",
        "        loss_fn (nn.Module): The loss function.\n",
        "        X_train_oh (torch.Tensor): One-hot encoded training features.\n",
        "        y_train (torch.Tensor): Training labels.\n",
        "        X_val_oh (torch.Tensor, optional): One-hot encoded validation features.\n",
        "        y_val (torch.Tensor, optional): Validation labels.\n",
        "        epochs (int): Number of training epochs/steps.\n",
        "        batch_size (int, optional): Batch size for training. If None, uses full batch.\n",
        "        optimizer_type (str): 'adamw', 'lbfgs', or 'custom'.\n",
        "        custom_update_fn (callable, optional): A function for custom parameter updates.\n",
        "                                               Expected signature: custom_update_fn(model, loss)\n",
        "        log_interval (int): How often to print training progress.\n",
        "        log_verbose (bool): Whether to print detailed logs.\n",
        "\n",
        "    Returns:\n",
        "        list: List of training loss values per epoch/step.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    loss_history = []\n",
        "    N = X_train_oh.size(0)\n",
        "    batch_size = batch_size if batch_size is not None else N\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        epoch_correct = 0.0\n",
        "        epoch_total = 0.0\n",
        "\n",
        "        if optimizer_type == 'lbfgs':\n",
        "            # LBFGS uses a closure\n",
        "            def closure():\n",
        "                optimizer.zero_grad()\n",
        "                preds = model(X_train_oh)\n",
        "                loss = loss_fn(preds, y_train)\n",
        "                loss.backward()\n",
        "                return loss\n",
        "            loss = optimizer.step(closure)\n",
        "            current_loss = loss.item()\n",
        "            # Calculate accuracy for LBFGS outside closure\n",
        "            with torch.no_grad():\n",
        "                preds = model(X_train_oh)\n",
        "                preds_bin = (preds > 0.5).float()\n",
        "                acc = (preds_bin == y_train).float().mean().item()\n",
        "            epoch_loss = current_loss\n",
        "            epoch_correct = acc * N\n",
        "            epoch_total = N\n",
        "            loss_history.append(current_loss)\n",
        "\n",
        "        elif optimizer_type == 'custom':\n",
        "            model.zero_grad()\n",
        "            preds = model(X_train_oh)\n",
        "            loss = loss_fn(preds, y_train)\n",
        "            loss.backward()\n",
        "            if custom_update_fn:\n",
        "                custom_update_fn(model, loss)\n",
        "            current_loss = loss.item()\n",
        "            # Calculate accuracy for custom update\n",
        "            with torch.no_grad():\n",
        "                preds_bin = (preds > 0.5).float()\n",
        "                acc = (preds_bin == y_train).float().mean().item()\n",
        "            epoch_loss = current_loss\n",
        "            epoch_correct = acc * N\n",
        "            epoch_total = N\n",
        "            loss_history.append(current_loss)\n",
        "\n",
        "        else: # AdamW, SGD, etc.\n",
        "            perm = torch.randperm(N)\n",
        "            for i in range(0, N, batch_size):\n",
        "                idx = perm[i:i + batch_size]\n",
        "                X_batch = X_train_oh[idx]\n",
        "                y_batch = y_train[idx]\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                preds = model(X_batch)\n",
        "                loss = loss_fn(preds, y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    preds_bin = (preds > 0.5).float()\n",
        "                    epoch_loss += loss.item() * y_batch.size(0)\n",
        "                    epoch_correct += (preds_bin == y_batch).sum().item()\n",
        "                    epoch_total += y_batch.size(0)\n",
        "            \n",
        "            current_loss = epoch_loss / epoch_total\n",
        "            loss_history.append(current_loss)\n",
        "\n",
        "\n",
        "        if log_verbose and epoch % log_interval == 0:\n",
        "            if epoch_total > 0:\n",
        "                print(\n",
        "                    f\"Epoch {epoch:4d} | \"\n",
        "                    f\"Loss: {current_loss:.8f} | \"\n",
        "                    f\"Acc: {epoch_correct / epoch_total:.8f}\"\n",
        "                )\n",
        "            else:\n",
        "                print(f\"Epoch {epoch:4d} | Loss: {current_loss:.8f}\")\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "# --- 4. Create Reusable Evaluation Function ---\n",
        "def evaluate_model(model, loss_fn, X_data_oh, y_data, X_data_original=None, data_name=\"Validation\"):\n",
        "    \"\"\"\n",
        "    Evaluates the model's performance on a given dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        loss_fn (nn.Module): The loss function.\n",
        "        X_data_oh (torch.Tensor): One-hot encoded features of the dataset.\n",
        "        y_data (torch.Tensor): Labels of the dataset.\n",
        "        X_data_original (torch.Tensor, optional): Original (non-one-hot) features for logging misclassified examples.\n",
        "        data_name (str): Name of the dataset (e.g., \"Training\", \"Validation\").\n",
        "\n",
        "    Returns:\n",
        "        tuple: (loss, accuracy)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_data_oh)\n",
        "        loss = loss_fn(preds, y_data)\n",
        "        preds_bin = (preds > 0.5).float()\n",
        "        correct = (preds_bin == y_data).sum().item()\n",
        "        total = y_data.size(0)\n",
        "        accuracy = correct / total\n",
        "\n",
        "        print(\n",
        "            f\"{data_name} results | \"\n",
        "            f\"Loss: {loss.item():.4f} | \"\n",
        "            f\"Acc: {accuracy:.4f}\"\n",
        "        )\n",
        "\n",
        "        if X_data_original is not None:\n",
        "            incorrect_indices = (preds_bin != y_data).nonzero(as_tuple=True)[0]\n",
        "            if len(incorrect_indices) > 0:\n",
        "                print(f\"\\nAnalyzing misclassified {data_name} examples ({len(incorrect_indices)} total):\")\n",
        "                for i in incorrect_indices[:5]: # Show up to 5 misclassified examples\n",
        "                    original_input = X_data_original[i].tolist()\n",
        "                    predicted_value = preds[i].item()\n",
        "                    true_label = y_data[i].item()\n",
        "                    print(f\"  Input: {original_input}, Predicted: {predicted_value:.4f}, Actual: {int(true_label)}\")\n",
        "            else:\n",
        "                print(f\"\\nAll {data_name} examples predicted correctly!\")\n",
        "    return loss.item(), accuracy\n",
        "\n",
        "# Custom update rule function\n",
        "def custom_gradient_update(model, loss):\n",
        "    \"\"\"Applies a custom gradient update rule.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        grad_norm_sq = 0.0\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                grad_norm_sq += torch.sum(p.grad ** 2)\n",
        "\n",
        "        if grad_norm_sq < 1e-12:\n",
        "            print(\"Gradient vanished â€” skipping update.\")\n",
        "            return\n",
        "\n",
        "        step_scale = loss / grad_norm_sq\n",
        "\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                p -= step_scale * p.grad\n",
        "\n",
        "# --- Demonstrate Usage with Different Optimizers ---\n",
        "print(\"--- Training with AdamW Optimizer ---\")\n",
        "d_model = 9\n",
        "seq_len = 9\n",
        "X_train_oh_adamw, y_train_adamw, X_val_oh_adamw, y_val_adamw, X_train_original_adamw, X_val_original_adamw = generate_data(num_symbols=9, train_frac=0.003, seed=42)\n",
        "model_adamw, loss_fn_adamw = initialize_model_and_loss(d_model, seq_len)\n",
        "optimizer_adamw = optim.AdamW(model_adamw.parameters(), lr=0.03)\n",
        "adamw_loss_history = train_model(model_adamw, optimizer_adamw, loss_fn_adamw, X_train_oh_adamw, y_train_adamw,\n",
        "                                 epochs=500, log_interval=100, optimizer_type='adamw')\n",
        "evaluate_model(model_adamw, loss_fn_adamw, X_val_oh_adamw, y_val_adamw, X_val_original_adamw, data_name=\"Validation (AdamW)\")\n",
        "\n",
        "print(\"\\n--- Training with LBFGS Optimizer ---\")\n",
        "X_train_oh_lbfgs, y_train_lbfgs, X_val_oh_lbfgs, y_val_lbfgs, X_train_original_lbfgs, X_val_original_lbfgs = generate_data(num_symbols=9, train_frac=0.003, seed=43)\n",
        "model_lbfgs, loss_fn_lbfgs = initialize_model_and_loss(d_model, seq_len)\n",
        "optimizer_lbfgs = torch.optim.LBFGS(model_lbfgs.parameters(), lr=1.0, max_iter=20, history_size=100, line_search_fn=\"strong_wolfe\")\n",
        "lbfgs_loss_history = train_model(model_lbfgs, optimizer_lbfgs, loss_fn_lbfgs, X_train_oh_lbfgs, y_train_lbfgs,\n",
        "                                 epochs=400, optimizer_type='lbfgs', log_interval=100) # LBFGS steps are not epochs, usually fewer steps\n",
        "evaluate_model(model_lbfgs, loss_fn_lbfgs, X_val_oh_lbfgs, y_val_lbfgs, X_val_original_lbfgs, data_name=\"Validation (LBFGS)\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Training with Custom Optimizer (Gradient Normalization) ---\")\n",
        "X_train_oh_custom, y_train_custom, X_val_oh_custom, y_val_custom, X_train_original_custom, X_val_original_custom = generate_data(num_symbols=9, train_frac=0.003, seed=44)\n",
        "model_custom, loss_fn_custom = initialize_model_and_loss(d_model, seq_len)\n",
        "custom_loss_history = train_model(model_custom, None, loss_fn_custom, X_train_oh_custom, y_train_custom,\n",
        "                                  epochs=500, optimizer_type='custom', custom_update_fn=custom_gradient_update, log_interval=100)\n",
        "evaluate_model(model_custom, loss_fn_custom, X_val_oh_custom, y_val_custom, X_val_original_custom, data_name=\"Validation (Custom)\")\n",
        "\n",
        "\n",
        "# --- Demonstrate Usage with Different Input Data Parameters ---\n",
        "print(\"\\n--- Training with Different Data Parameters (AdamW, 5 symbols) ---\")\n",
        "d_model_small = 5\n",
        "seq_len_small = 5\n",
        "X_train_oh_small, y_train_small, X_val_oh_small, y_val_small, X_train_original_small, X_val_original_small = generate_data(num_symbols=d_model_small, train_frac=0.1, seed=45)\n",
        "model_small, loss_fn_small = initialize_model_and_loss(d_model_small, seq_len_small)\n",
        "optimizer_small = optim.AdamW(model_small.parameters(), lr=0.01)\n",
        "small_data_loss_history = train_model(model_small, optimizer_small, loss_fn_small, X_train_oh_small, y_train_small,\n",
        "                                      epochs=300, log_interval=50, optimizer_type='adamw')\n",
        "evaluate_model(model_small, loss_fn_small, X_val_oh_small, y_val_small, X_val_original_small, data_name=\"Validation (Small Data)\")\n",
        "\n",
        "\n",
        "# --- Visualize Training History ---\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(adamw_loss_history, label='AdamW Loss', alpha=0.7)\n",
        "plt.plot(lbfgs_loss_history, label='LBFGS Loss', alpha=0.7)\n",
        "plt.plot(custom_loss_history, label='Custom Update Loss', alpha=0.7)\n",
        "plt.plot(small_data_loss_history, label='AdamW (5 Symbols) Loss', alpha=0.7, linestyle='--')\n",
        "plt.xlabel('Epoch/Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss History for Different Optimizers and Data Parameters')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.yscale('log') # Use log scale for better visualization of different convergence speeds\n",
        "plt.show()\n",
        "\n",
        "# --- Final Task: Summary ---\n",
        "print(\"\\n--- Summary of Organized Code Structure ---\")\n",
        "print(\"The code has been refactored into modular functions:\")\n",
        "print(\"1. `generate_data`: Centralized function to create training and validation datasets, ensuring reproducibility and easy modification of data parameters (e.g., number of symbols, train/validation split ratio).\")\n",
        "print(\"2. `initialize_model_and_loss`: A function to instantiate the `RawAttentionWithTopNeuron` model and the `MSELoss` function, making it easy to configure model size or loss types.\")\n",
        "print(\"3. `train_model`: A flexible training loop that accommodates different optimizers (AdamW, LBFGS, custom update rules) by handling their specific `step` mechanisms (e.g., LBFGS's `closure`). This allows for straightforward experimentation with various optimization algorithms.\")\n",
        "print(\"4. `evaluate_model`: A dedicated function to assess model performance on given data, calculating loss and accuracy, and providing insights into misclassified examples. This standardizes the evaluation process.\")\n",
        "\n",
        "print(\"\\n**How this structure facilitates experimentation:**\")\n",
        "print(\"- **Different Optimizers**: By passing different optimizer instances (e.g., `optim.AdamW`, `torch.optim.LBFGS`) and specifying `optimizer_type`, the same `train_model` function can be used without code duplication, as demonstrated above.\")\n",
        "print(\"- **Different Input Data Parameters**: The `generate_data` function allows easy generation of datasets with varying `num_symbols` or `train_frac`. This means one can quickly test the model's performance on different problem complexities or dataset sizes, as shown with the 5-symbol example.\")\n",
        "print(\"- **Clearer Workflow**: The modularity makes the entire machine learning pipeline (data -> model -> train -> evaluate) much clearer, easier to understand, debug, and extend.\")\n",
        "print(\"- **Reproducibility**: Explicit seeding and function encapsulation promote reproducibility of experiments.\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1ec8435"
      },
      "source": [
        "## Consolidate Data Generation\n",
        "\n",
        "### Subtask:\n",
        "Create a dedicated function to generate training and validation data (X_train, y_train, X_val, y_val, and their one-hot encoded versions) based on specified parameters (e.g., number of symbols, train_frac). This function will ensure data is generated consistently and can be easily reproduced or modified for different experiments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d77319d"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define a function `generate_data` that encapsulates all the data generation logic, including setting seeds, generating valid and invalid sequences, combining and splitting data, one-hot encoding, and converting to tensors, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee08e7e7",
        "outputId": "72356d4a-39fb-45d8-8164-fd1c542d9472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train OH: torch.Size([2177, 9, 9]) Train y: torch.Size([2177, 1])\n",
            "Val OH:   torch.Size([723583, 9, 9]) Val y: torch.Size([723583, 1])\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "def generate_data(num_symbols=9, train_frac=0.003, seed=0, dtype=torch.float):\n",
        "    # Set seeds for reproducibility\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Generate ALL valid permutations\n",
        "    # -----------------------------\n",
        "    valid_sequences = list(itertools.permutations(range(1, num_symbols + 1)))\n",
        "    valid_labels = [1.0] * len(valid_sequences)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Generate invalid sequences\n",
        "    # -----------------------------\n",
        "    def generate_invalid(num_samples):\n",
        "        invalid = set()\n",
        "        while len(invalid) < num_samples:\n",
        "            seq = [random.randint(1, num_symbols) for _ in range(num_symbols)]\n",
        "            if len(set(seq)) != num_symbols:  # invalid condition\n",
        "                invalid.add(tuple(seq))\n",
        "        return list(invalid)\n",
        "\n",
        "    num_invalid = len(valid_sequences) # Ensure equal number of valid and invalid for balance\n",
        "    invalid_sequences = generate_invalid(num_invalid)\n",
        "    invalid_labels = [0.0] * num_invalid\n",
        "\n",
        "    # -----------------------------\n",
        "    # Combine & shuffle\n",
        "    # -----------------------------\n",
        "    all_sequences = valid_sequences + invalid_sequences\n",
        "    all_labels = valid_labels + invalid_labels\n",
        "\n",
        "    combined = list(zip(all_sequences, all_labels))\n",
        "    random.shuffle(combined)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Train / validation split\n",
        "    # -----------------------------\n",
        "    split_idx = int(len(combined) * train_frac)\n",
        "\n",
        "    train_data = combined[:split_idx]\n",
        "    val_data   = combined[split_idx:]\n",
        "\n",
        "    # -----------------------------\n",
        "    # Ensure NO overlap (sanity check)\n",
        "    # -----------------------------\n",
        "    train_set = set(seq for seq, _ in train_data)\n",
        "    val_set   = set(seq for seq, _ in val_data)\n",
        "\n",
        "    assert train_set.isdisjoint(val_set), \"Train / validation overlap detected!\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # Convert to tensors\n",
        "    # -----------------------------\n",
        "    def to_tensors(data):\n",
        "        X = torch.tensor([seq for seq, _ in data], dtype=torch.long)\n",
        "        y = torch.tensor([[label] for _, label in data], dtype=dtype)\n",
        "        return X, y\n",
        "\n",
        "    X_train_original, y_train = to_tensors(train_data)\n",
        "    X_val_original,   y_val   = to_tensors(val_data)\n",
        "\n",
        "    # -----------------------------\n",
        "    # One-hot encode\n",
        "    # -----------------------------\n",
        "    X_train_oh = torch.nn.functional.one_hot(X_train_original - 1, num_classes=num_symbols).to(dtype=dtype)\n",
        "    X_val_oh   = torch.nn.functional.one_hot(X_val_original - 1,   num_classes=num_symbols).to(dtype=dtype)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Final shapes\n",
        "    # -----------------------------\n",
        "    print(\"Train OH:\", X_train_oh.shape, \"Train y:\", y_train.shape)\n",
        "    print(\"Val OH:  \", X_val_oh.shape, \"Val y:\", y_val.shape)\n",
        "\n",
        "    return X_train_oh, y_train, X_val_oh, y_val, X_train_original, X_val_original\n",
        "\n",
        "# Call the function to generate data\n",
        "X_train_oh, y_train, X_val_oh, y_val, X_train, X_val = generate_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f80c91d7"
      },
      "source": [
        "## Encapsulate Model Definition\n",
        "\n",
        "### Subtask:\n",
        "Ensure the model `RawAttentionWithTopNeuron` and its initialization are clearly defined in a separate block or function, allowing for easy re-instantiation with different `d_model` or `seq_len` parameters if needed. This step also includes setting the loss function (`nn.MSELoss`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17376670"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `RawAttention` and `RawAttentionWithTopNeuron` classes and then create the `initialize_model_and_loss` function to encapsulate the model and loss initialization as specified in the instructions. This will make the model definition reusable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c6b680e",
        "outputId": "6c9bc98e-5e14-4259-858a-32ddc0fe3a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model classes and initialization function defined.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 1. Define the RawAttention class\n",
        "class RawAttention(nn.Module):\n",
        "    def __init__(self, d_model, dtype=torch.float):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.Wq = nn.Linear(d_model, d_model, bias=False, dtype=dtype)\n",
        "        self.Wk = nn.Linear(d_model, d_model, bias=False, dtype=dtype)\n",
        "        self.Wv = nn.Linear(d_model, d_model, bias=False, dtype=dtype)\n",
        "\n",
        "    def forward(self, x):\n",
        "        Q = self.Wq(x)\n",
        "        K = self.Wk(x)\n",
        "        V = self.Wv(x)\n",
        "        scores = torch.matmul(Q, K.transpose(1, 2)) / (self.d_model ** 0.5)\n",
        "        out = torch.matmul(scores, V)\n",
        "        return out\n",
        "\n",
        "# 2. Define the RawAttentionWithTopNeuron class\n",
        "class RawAttentionWithTopNeuron(nn.Module):\n",
        "    def __init__(self, d_model, seq_len, dtype=torch.float):\n",
        "        super().__init__()\n",
        "        self.raw_attention = RawAttention(d_model, dtype=dtype)\n",
        "        self.readout = nn.Linear(d_model * seq_len, 1, bias=True, dtype=dtype)\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def forward(self, x):\n",
        "        attended = self.raw_attention(x)\n",
        "        combined = attended + x  # Residual connection\n",
        "        out = self.readout(combined.reshape(combined.shape[0], -1))\n",
        "        return out\n",
        "\n",
        "# 3. Create a function named initialize_model_and_loss\n",
        "def initialize_model_and_loss(d_model, seq_len, dtype=torch.float):\n",
        "    \"\"\"Initializes the model and loss function.\"\"\"\n",
        "    model = RawAttentionWithTopNeuron(d_model, seq_len, dtype=dtype)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    return model, loss_fn\n",
        "\n",
        "print(\"Model classes and initialization function defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9276981d"
      },
      "source": [
        "## Create Reusable Training Function\n",
        "\n",
        "### Subtask:\n",
        "Develop a function that encapsulates the training loop logic. This function should accept the model, optimizer, loss function, training data (X_train_oh, y_train), and optional validation data (X_val_oh, y_val). It will handle the forward pass, loss calculation, backward pass, optimizer step, and logging of metrics like loss and accuracy. It should also be flexible enough to accommodate different optimizers like AdamW, LBFGS, or custom update rules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcdce7c2"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `train_model` function as specified, incorporating logic for different optimizer types (AdamW/SGD, LBFGS, custom updates) and handling batching, loss calculation, and logging.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40f06d94",
        "outputId": "0703d633-1bea-48e1-c304-fa3ee1625080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reusable training function `train_model` defined and reorganized.\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def _train_adamw_or_sgd(model, optimizer, loss_fn, X_train_oh, y_train, epochs, batch_size, log_interval, log_verbose):\n",
        "    loss_history = []\n",
        "    N = X_train_oh.size(0)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        epoch_correct = 0.0\n",
        "        epoch_total = 0.0\n",
        "\n",
        "        perm = torch.randperm(N)\n",
        "        for i in range(0, N, batch_size):\n",
        "            idx = perm[i:i + batch_size]\n",
        "            X_batch = X_train_oh[idx]\n",
        "            y_batch = y_train[idx]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(X_batch)\n",
        "            loss = loss_fn(preds, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds_bin = (preds > 0.5).float()\n",
        "                epoch_loss += loss.item() * y_batch.size(0)\n",
        "                epoch_correct += (preds_bin == y_batch).sum().item()\n",
        "                epoch_total += y_batch.size(0)\n",
        "\n",
        "        current_loss = epoch_loss / epoch_total if epoch_total > 0 else 0.0\n",
        "        current_acc = epoch_correct / epoch_total if epoch_total > 0 else 0.0\n",
        "        loss_history.append(current_loss)\n",
        "\n",
        "        if log_verbose and epoch % log_interval == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch:4d} | \"\n",
        "                f\"Loss: {current_loss:.8f} | \"\n",
        "                f\"Acc: {current_acc:.8f}\"\n",
        "            )\n",
        "    return loss_history\n",
        "\n",
        "def _train_lbfgs(model, optimizer, loss_fn, X_train_oh, y_train, epochs, log_interval, log_verbose):\n",
        "    loss_history = []\n",
        "    N = X_train_oh.size(0)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(X_train_oh)\n",
        "            loss = loss_fn(preds, y_train)\n",
        "            loss.backward()\n",
        "            return loss\n",
        "\n",
        "        loss = optimizer.step(closure)\n",
        "        current_loss = loss.item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model(X_train_oh)\n",
        "            preds_bin = (preds > 0.5).float()\n",
        "            current_acc = (preds_bin == y_train).float().mean().item()\n",
        "\n",
        "        loss_history.append(current_loss)\n",
        "\n",
        "        if log_verbose and epoch % log_interval == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch:4d} | \"\n",
        "                f\"Loss: {current_loss:.8f} | \"\n",
        "                f\"Acc: {current_acc:.8f}\"\n",
        "            )\n",
        "    return loss_history\n",
        "\n",
        "def _train_custom_optimizer(model, custom_update_fn, loss_fn, X_train_oh, y_train, epochs, log_interval, log_verbose):\n",
        "    loss_history = []\n",
        "    N = X_train_oh.size(0)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.zero_grad()\n",
        "        preds = model(X_train_oh)\n",
        "        loss = loss_fn(preds, y_train)\n",
        "        loss.backward()\n",
        "        if custom_update_fn:\n",
        "            custom_update_fn(model, loss)\n",
        "        current_loss = loss.item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds_bin = (preds > 0.5).float()\n",
        "            current_acc = (preds_bin == y_train).float().mean().item()\n",
        "\n",
        "        loss_history.append(current_loss)\n",
        "\n",
        "        if log_verbose and epoch % log_interval == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch:4d} | \"\n",
        "                f\"Loss: {current_loss:.8f} | \"\n",
        "                f\"Acc: {current_acc:.8f}\"\n",
        "            )\n",
        "    return loss_history\n",
        "\n",
        "def train_model(model, optimizer, loss_fn, X_train_oh, y_train, X_val_oh=None, y_val=None,\n",
        "                epochs=100, batch_size=None, optimizer_type='adamw', custom_update_fn=None,\n",
        "                log_interval=100, log_verbose=True):\n",
        "    \"\"\"\n",
        "    Trains the model and records loss history.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The model to train.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer to use.\n",
        "        loss_fn (nn.Module): The loss function.\n",
        "        X_train_oh (torch.Tensor): One-hot encoded training features.\n",
        "        y_train (torch.Tensor): Training labels.\n",
        "        X_val_oh (torch.Tensor, optional): One-hot encoded validation features.\n",
        "        y_val (torch.Tensor, optional): Validation labels.\n",
        "        epochs (int): Number of training epochs/steps.\n",
        "        batch_size (int, optional): Batch size for training. If None, uses full batch.\n",
        "        optimizer_type (str): 'adamw', 'lbfgs', or 'custom'.\n",
        "        custom_update_fn (callable, optional): A function for custom parameter updates.\n",
        "                                               Expected signature: custom_update_fn(model, loss)\n",
        "        log_interval (int): How often to print training progress.\n",
        "        log_verbose (bool): Whether to print detailed logs.\n",
        "\n",
        "    Returns:\n",
        "        list: List of training loss values per epoch/step.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    N = X_train_oh.size(0)\n",
        "    batch_size = batch_size if batch_size is not None else N\n",
        "\n",
        "    if optimizer_type == 'lbfgs':\n",
        "        return _train_lbfgs(model, optimizer, loss_fn, X_train_oh, y_train, epochs, log_interval, log_verbose)\n",
        "    elif optimizer_type == 'custom':\n",
        "        return _train_custom_optimizer(model, custom_update_fn, loss_fn, X_train_oh, y_train, epochs, log_interval, log_verbose)\n",
        "    else:  # 'adamw', 'sgd', or any other batch-based optimizer\n",
        "        return _train_adamw_or_sgd(model, optimizer, loss_fn, X_train_oh, y_train, epochs, batch_size, log_interval, log_verbose)\n",
        "\n",
        "print(\"Reusable training function `train_model` defined and reorganized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53a145e6"
      },
      "source": [
        "## Create Reusable Evaluation Function\n",
        "\n",
        "### Subtask:\n",
        "Implement a function to evaluate the model's performance on a given dataset (e.g., validation set). This function will take the trained model, evaluation data, and loss function, and return metrics like loss and accuracy. It should also include logic for analyzing misclassified examples, similar to your existing `k0dR0gV_A_bp` cell.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0408589"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `evaluate_model` function as specified in the instructions. This function will handle model evaluation, calculate loss and accuracy, and optionally identify and print misclassified examples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a9e36ef",
        "outputId": "537217a9-7ad5-4582-ea30-e2680afbeda4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reusable evaluation function `evaluate_model` defined.\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, loss_fn, X_data_oh, y_data, X_data_original=None, data_name=\"Validation\"):\n",
        "    \"\"\"\n",
        "    Evaluates the model's performance on a given dataset.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The trained model.\n",
        "        loss_fn (nn.Module): The loss function.\n",
        "        X_data_oh (torch.Tensor): One-hot encoded features of the dataset.\n",
        "        y_data (torch.Tensor): Labels of the dataset.\n",
        "        X_data_original (torch.Tensor, optional): Original (non-one-hot) features for logging misclassified examples.\n",
        "        data_name (str): Name of the dataset (e.g., \"Training\", \"Validation\").\n",
        "\n",
        "    Returns:\n",
        "        tuple: (loss, accuracy)\n",
        "    \"\"\"\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    with torch.no_grad(): # Disable gradient tracking\n",
        "        preds = model(X_data_oh) # Make predictions\n",
        "        loss = loss_fn(preds, y_data)\n",
        "        preds_bin = (preds > 0.5).float() # Binarize predictions\n",
        "\n",
        "        correct = (preds_bin == y_data).sum().item()\n",
        "        total = y_data.size(0)\n",
        "        accuracy = correct / total\n",
        "\n",
        "        print(\n",
        "            f\"{data_name} results | \"\n",
        "            f\"Loss: {loss.item():.4f} | \"\n",
        "            f\"Acc: {accuracy:.4f}\"\n",
        "        )\n",
        "\n",
        "        if X_data_original is not None:\n",
        "            incorrect_indices = (preds_bin != y_data).nonzero(as_tuple=True)[0]\n",
        "            if len(incorrect_indices) > 0:\n",
        "                print(f\"\\nAnalyzing misclassified {data_name} examples ({len(incorrect_indices)} total):\")\n",
        "                for i in incorrect_indices[:5]: # Show up to 5 misclassified examples\n",
        "                    original_input = X_data_original[i].tolist()\n",
        "                    predicted_value = preds[i].item()\n",
        "                    true_label = y_data[i].item()\n",
        "                    print(f\"  Input: {original_input}, Predicted: {predicted_value:.4f}, Actual: {int(true_label)}\")\n",
        "            else:\n",
        "                print(f\"\\nAll {data_name} examples predicted correctly!\")\n",
        "\n",
        "    return loss.item(), accuracy\n",
        "\n",
        "print(\"Reusable evaluation function `evaluate_model` defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75008e1e"
      },
      "source": [
        "## Demonstrate Usage with Different Optimizers\n",
        "\n",
        "### Subtask:\n",
        "Show how to use the refactored functions to train the model with different optimizers (e.g., AdamW, LBFGS, or your custom update rule) by passing them to the generic training function. This will illustrate the reusability of the new structure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2cf0aac"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the `custom_gradient_update` function and then demonstrate the usage of the `generate_data`, `initialize_model_and_loss`, `train_model`, and `evaluate_model` functions with AdamW, LBFGS, and a custom gradient update rule, as specified in the instructions. This will show the reusability and flexibility of the refactored code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "afa0d23f",
        "outputId": "9467f05c-64e2-4c7e-e54b-f0364fafa976"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Custom update rule function (from previous implementation 'J4vlvcQ1QWKi')\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcustom_gradient_update\u001b[39m(model, loss):\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Custom update rule function (from previous implementation 'J4vlvcQ1QWKi')\n",
        "def custom_gradient_update(model, loss):\n",
        "    \"\"\"Applies a custom gradient update rule.\"\"\"\n",
        "    with torch.no_grad():\n",
        "        grad_norm_sq = 0.0\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                grad_norm_sq += torch.sum(p.grad ** 2)\n",
        "\n",
        "        if grad_norm_sq < 1e-12:\n",
        "            # print(\"Gradient vanished â€” skipping update.\") # Commented out to avoid excessive output\n",
        "            return\n",
        "\n",
        "        step_scale = loss / grad_norm_sq\n",
        "\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                p -= step_scale * p.grad\n",
        "\n",
        "# 2. Initialize d_model and seq_len\n",
        "d_model = 9\n",
        "seq_len = 9\n",
        "\n",
        "# Define the dtypes to experiment with\n",
        "dtype_float32 = torch.float\n",
        "dtype_float64 = torch.float64\n",
        "\n",
        "\n",
        "print(\"--- Training with AdamW Optimizer (float32) ---\")\n",
        "torch.set_default_dtype(dtype_float32) # Set default dtype for this block\n",
        "# 3. Generate training and validation data for AdamW\n",
        "X_train_oh_adamw, y_train_adamw, X_val_oh_adamw, y_val_adamw, X_train_original_adamw, X_val_original_adamw = generate_data(num_symbols=9, train_frac=0.003, seed=42, dtype=dtype_float32)\n",
        "\n",
        "# 4. Initialize a new model and loss function\n",
        "model_adamw, loss_fn_adamw = initialize_model_and_loss(d_model, seq_len, dtype=dtype_float32)\n",
        "\n",
        "# 5. Initialize an AdamW optimizer\n",
        "optimizer_adamw = optim.AdamW(model_adamw.parameters(), lr=0.03)\n",
        "\n",
        "# 6. Train the model using train_model with AdamW optimizer\n",
        "adamw_loss_history = train_model(model_adamw, optimizer_adamw, loss_fn_adamw, X_train_oh_adamw, y_train_adamw,\n",
        "                                 epochs=500, log_interval=100, optimizer_type='adamw')\n",
        "\n",
        "# 7. Evaluate the AdamW-trained model on the validation set\n",
        "print(\"\\n--- Evaluation for AdamW Model (float32) ---\")\n",
        "evaluate_model(model_adamw, loss_fn_adamw, X_val_oh_adamw, y_val_adamw, X_val_original_adamw, data_name=\"Validation (AdamW, float32)\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Training with LBFGS Optimizer (float64) ---\")\n",
        "torch.set_default_dtype(dtype_float64) # Set default dtype for this block\n",
        "# 8. Generate new training and validation data for LBFGS\n",
        "X_train_oh_lbfgs, y_train_lbfgs, X_val_oh_lbfgs, y_val_lbfgs, X_train_original_lbfgs, X_val_original_lbfgs = generate_data(num_symbols=9, train_frac=0.003, seed=43, dtype=dtype_float64)\n",
        "\n",
        "# 9. Initialize another new model and loss function\n",
        "model_lbfgs, loss_fn_lbfgs = initialize_model_and_loss(d_model, seq_len, dtype=dtype_float64)\n",
        "\n",
        "# 10. Initialize an LBFGS optimizer\n",
        "optimizer_lbfgs = torch.optim.LBFGS(model_lbfgs.parameters(), lr=1.0, max_iter=20, history_size=100, line_search_fn=\"strong_wolfe\")\n",
        "\n",
        "# 11. Train the model using train_model with LBFGS optimizer\n",
        "lbfgs_loss_history = train_model(model_lbfgs, optimizer_lbfgs, loss_fn_lbfgs, X_train_oh_lbfgs, y_train_lbfgs,\n",
        "                                 epochs=400, optimizer_type='lbfgs', log_interval=100) # LBFGS steps are not epochs, usually fewer steps\n",
        "\n",
        "# 12. Evaluate the LBFGS-trained model on the validation set\n",
        "print(\"\\n--- Evaluation for LBFGS Model (float64) ---\")\n",
        "evaluate_model(model_lbfgs, loss_fn_lbfgs, X_val_oh_lbfgs, y_val_lbfgs, X_val_original_lbfgs, data_name=\"Validation (LBFGS, float64)\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Training with Custom Optimizer (Gradient Normalization, float32) ---\")\n",
        "torch.set_default_dtype(dtype_float32) # Set default dtype for this block\n",
        "# 13. Generate new training and validation data for Custom Optimizer\n",
        "X_train_oh_custom, y_train_custom, X_val_oh_custom, y_val_custom, X_train_original_custom, X_val_original_custom = generate_data(num_symbols=9, train_frac=0.003, seed=44, dtype=dtype_float32)\n",
        "\n",
        "# 14. Initialize yet another new model and loss function\n",
        "model_custom, loss_fn_custom = initialize_model_and_loss(d_model, seq_len, dtype=dtype_float32)\n",
        "\n",
        "# 15. Train the model using train_model with custom update rule\n",
        "custom_loss_history = train_model(model_custom, None, loss_fn_custom, X_train_oh_custom, y_train_custom,\n",
        "                                  epochs=500, optimizer_type='custom', custom_update_fn=custom_gradient_update, log_interval=100)\n",
        "\n",
        "# 16. Evaluate the custom-optimizer-trained model on the validation set\n",
        "print(\"\\n--- Evaluation for Custom Optimizer Model (float32) ---\")\n",
        "evaluate_model(model_custom, loss_fn_custom, X_val_oh_custom, y_val_custom, X_val_original_custom, data_name=\"Validation (Custom, float32)\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n--- Training with Different Data Parameters (AdamW, 5 symbols, float32) ---\")\n",
        "torch.set_default_dtype(dtype_float32) # Set default dtype for this block\n",
        "d_model_small = 5\n",
        "seq_len_small = 5\n",
        "X_train_oh_small, y_train_small, X_val_oh_small, y_val_small, X_train_original_small, X_val_original_small = generate_data(num_symbols=d_model_small, train_frac=0.1, seed=45, dtype=dtype_float32)\n",
        "model_small, loss_fn_small = initialize_model_and_loss(d_model_small, seq_len_small, dtype=dtype_float32)\n",
        "optimizer_small = optim.AdamW(model_small.parameters(), lr=0.01)\n",
        "small_data_loss_history = train_model(model_small, optimizer_small, loss_fn_small, X_train_oh_small, y_train_small,\n",
        "                                      epochs=300, log_interval=50, optimizer_type='adamw')\n",
        "evaluate_model(model_small, loss_fn_small, X_val_oh_small, y_val_small, X_val_original_small, data_name=\"Validation (Small Data, float32)\")\n",
        "\n",
        "\n",
        "# --- Visualize Training History ---\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(adamw_loss_history, label='AdamW Loss (float32)', alpha=0.7)\n",
        "plt.plot(lbfgs_loss_history, label='LBFGS Loss (float64)', alpha=0.7)\n",
        "plt.plot(custom_loss_history, label='Custom Update Loss (float32)', alpha=0.7)\n",
        "plt.plot(small_data_loss_history, label='AdamW (5 Symbols, float32) Loss', alpha=0.7, linestyle='--')\n",
        "plt.xlabel('Epoch/Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss History for Different Optimizers and Data Parameters')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.yscale('log') # Use log scale for better visualization of different convergence speeds\n",
        "plt.show()\n",
        "\n",
        "# --- Final Task: Summary ---\n",
        "print(\"\\n--- Summary of Organized Code Structure ---\")\n",
        "print(\"The code has been refactored into modular functions:\")\n",
        "print(\"1. `generate_data`: Centralized function to create training and validation datasets, ensuring reproducibility and easy modification of data parameters (e.g., number of symbols, train/validation split ratio).\")\n",
        "print(\"2. `initialize_model_and_loss`: A function to instantiate the `RawAttentionWithTopNeuron` model and the `MSELoss` function, making it easy to configure model size or loss types.\")\n",
        "print(\"3. `train_model`: A flexible training loop that accommodates different optimizers (AdamW, LBFGS, custom update rules) by handling their specific `step` mechanisms (e.g., LBFGS's `closure`). This allows for straightforward experimentation with various optimization algorithms.\")\n",
        "print(\"4. `evaluate_model`: A dedicated function to assess model performance on given data, calculating loss and accuracy, and providing insights into misclassified examples. This standardizes the evaluation process.\")\n",
        "\n",
        "print(\"\\n**How this structure facilitates experimentation:**\")\n",
        "print(\"- **Different Optimizers**: By passing different optimizer instances (e.g., `optim.AdamW`, `torch.optim.LBFGS`) and specifying `optimizer_type`, the same `train_model` function can be used without code duplication, as demonstrated above.\")\n",
        "print(\"- **Different Input Data Parameters**: The `generate_data` function allows easy generation of datasets with varying `num_symbols` or `train_frac`. This means one can quickly test the model's performance on different problem complexities or dataset sizes, as shown with the 5-symbol example.\")\n",
        "print(\"- **Configurable Data Types**: The added `dtype` parameter to `generate_data` and `initialize_model_and_loss` functions allows for easy experimentation with different floating-point precision (e.g., `torch.float32` vs `torch.float64`) for both data and model parameters, enabling analysis of its impact on training stability and performance.\")\n",
        "print(\"- **Clearer Workflow**: The modularity makes the entire machine learning pipeline (data -> model -> train -> evaluate) much clearer, easier to understand, debug, and extend.\")\n",
        "print(\"- **Reproducibility**: Explicit seeding and function encapsulation promote reproducibility of experiments.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40edc215"
      },
      "source": [
        "**Reasoning**:\n",
        "I will now proceed with demonstrating the usage of the refactored functions with different input data parameters as per the instructions. This includes generating data with 5 symbols, training a new model with AdamW, and then evaluating it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4ba55cae",
        "outputId": "22b9e64b-96a8-41ec-af74-70d09747567a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Training with Different Data Parameters (AdamW, 5 symbols) ---\n",
            "Train OH: torch.Size([24, 5, 5]) Train y: torch.Size([24, 1])\n",
            "Val OH:   torch.Size([216, 5, 5]) Val y: torch.Size([216, 1])\n",
            "Epoch    0 | Loss: 0.74764085 | Acc: 0.58333333\n",
            "Epoch   50 | Loss: 0.08695977 | Acc: 0.95833333\n",
            "Epoch  100 | Loss: 0.01005732 | Acc: 1.00000000\n",
            "Epoch  150 | Loss: 0.00018962 | Acc: 1.00000000\n",
            "Epoch  200 | Loss: 0.00000167 | Acc: 1.00000000\n",
            "Epoch  250 | Loss: 0.00000030 | Acc: 1.00000000\n",
            "Validation (Small Data) results | Loss: 1.1743 | Acc: 0.5185\n",
            "\n",
            "Analyzing misclassified Validation (Small Data) examples (104 total):\n",
            "  Input: [4, 5, 3, 2, 1], Predicted: 0.2963, Actual: 1\n",
            "  Input: [3, 4, 2, 1, 2], Predicted: 0.8219, Actual: 0\n",
            "  Input: [5, 1, 2, 4, 3], Predicted: -0.6113, Actual: 1\n",
            "  Input: [4, 1, 5, 2, 3], Predicted: -0.5139, Actual: 1\n",
            "  Input: [4, 2, 4, 2, 3], Predicted: 0.8502, Actual: 0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Summary of Organized Code Structure ---\n",
            "The code has been refactored into modular functions:\n",
            "1. `generate_data`: Centralized function to create training and validation datasets, ensuring reproducibility and easy modification of data parameters (e.g., number of symbols, train/validation split ratio).\n",
            "2. `initialize_model_and_loss`: A function to instantiate the `RawAttentionWithTopNeuron` model and the `MSELoss` function, making it easy to configure model size or loss types.\n",
            "3. `train_model`: A flexible training loop that accommodates different optimizers (AdamW, LBFGS, custom update rules) by handling their specific `step` mechanisms (e.g., LBFGS's `closure`). This allows for straightforward experimentation with various optimization algorithms.\n",
            "4. `evaluate_model`: A dedicated function to assess model performance on given data, calculating loss and accuracy, and providing insights into misclassified examples. This standardizes the evaluation process.\n",
            "\n",
            "**How this structure facilitates experimentation:**\n",
            "- **Different Optimizers**: By passing different optimizer instances (e.g., `optim.AdamW`, `torch.optim.LBFGS`) and specifying `optimizer_type`, the same `train_model` function can be used without code duplication, as demonstrated above.\n",
            "- **Different Input Data Parameters**: The `generate_data` function allows easy generation of datasets with varying `num_symbols` or `train_frac`. This means one can quickly test the model's performance on different problem complexities or dataset sizes, as shown with the 5-symbol example.\n",
            "- **Clearer Workflow**: The modularity makes the entire machine learning pipeline (data -> model -> train -> evaluate) much clearer, easier to understand, debug, and extend.\n",
            "- **Reproducibility**: Explicit seeding and function encapsulation promote reproducibility of experiments.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Training with Different Data Parameters (AdamW, 5 symbols) ---\")\n",
        "d_model_small = 5\n",
        "seq_len_small = 5\n",
        "X_train_oh_small, y_train_small, X_val_oh_small, y_val_small, X_train_original_small, X_val_original_small = generate_data(num_symbols=d_model_small, train_frac=0.1, seed=45)\n",
        "model_small, loss_fn_small = initialize_model_and_loss(d_model_small, seq_len_small)\n",
        "optimizer_small = optim.AdamW(model_small.parameters(), lr=0.01)\n",
        "small_data_loss_history = train_model(model_small, optimizer_small, loss_fn_small, X_train_oh_small, y_train_small,\n",
        "                                      epochs=300, log_interval=50, optimizer_type='adamw')\n",
        "evaluate_model(model_small, loss_fn_small, X_val_oh_small, y_val_small, X_val_original_small, data_name=\"Validation (Small Data)\")\n",
        "\n",
        "\n",
        "# --- Visualize Training History ---\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(adamw_loss_history, label='AdamW Loss', alpha=0.7)\n",
        "plt.plot(lbfgs_loss_history, label='LBFGS Loss', alpha=0.7)\n",
        "plt.plot(custom_loss_history, label='Custom Update Loss', alpha=0.7)\n",
        "plt.plot(small_data_loss_history, label='AdamW (5 Symbols) Loss', alpha=0.7, linestyle='--')\n",
        "plt.xlabel('Epoch/Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss History for Different Optimizers and Data Parameters')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.yscale('log') # Use log scale for better visualization of different convergence speeds\n",
        "plt.show()\n",
        "\n",
        "# --- Final Task: Summary ---\n",
        "print(\"\\n--- Summary of Organized Code Structure ---\")\n",
        "print(\"The code has been refactored into modular functions:\")\n",
        "print(\"1. `generate_data`: Centralized function to create training and validation datasets, ensuring reproducibility and easy modification of data parameters (e.g., number of symbols, train/validation split ratio).\")\n",
        "print(\"2. `initialize_model_and_loss`: A function to instantiate the `RawAttentionWithTopNeuron` model and the `MSELoss` function, making it easy to configure model size or loss types.\")\n",
        "print(\"3. `train_model`: A flexible training loop that accommodates different optimizers (AdamW, LBFGS, custom update rules) by handling their specific `step` mechanisms (e.g., LBFGS's `closure`). This allows for straightforward experimentation with various optimization algorithms.\")\n",
        "print(\"4. `evaluate_model`: A dedicated function to assess model performance on given data, calculating loss and accuracy, and providing insights into misclassified examples. This standardizes the evaluation process.\")\n",
        "\n",
        "print(\"\\n**How this structure facilitates experimentation:**\")\n",
        "print(\"- **Different Optimizers**: By passing different optimizer instances (e.g., `optim.AdamW`, `torch.optim.LBFGS`) and specifying `optimizer_type`, the same `train_model` function can be used without code duplication, as demonstrated above.\")\n",
        "print(\"- **Different Input Data Parameters**: The `generate_data` function allows easy generation of datasets with varying `num_symbols` or `train_frac`. This means one can quickly test the model's performance on different problem complexities or dataset sizes, as shown with the 5-symbol example.\")\n",
        "print(\"- **Clearer Workflow**: The modularity makes the entire machine learning pipeline (data -> model -> train -> evaluate) much clearer, easier to understand, debug, and extend.\")\n",
        "print(\"- **Reproducibility**: Explicit seeding and function encapsulation promote reproducibility of experiments.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9332607b"
      },
      "source": [
        "## Visualize Training History\n",
        "\n",
        "### Subtask:\n",
        "Generate a plot of the training loss history for different training runs to compare optimizer performance or impact of different input data. Ensure the plot has appropriate labels and a legend.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a16c36a"
      },
      "source": [
        "**Reasoning**:\n",
        "I will generate a plot of the training loss histories for the different optimizers and data configurations as instructed, using `matplotlib.pyplot` to visualize and compare their performance with appropriate labels and a logarithmic y-axis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "5ba79836",
        "outputId": "cb6e8f70-ac4a-48c7-a7bd-2d3e6374021a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Visualize Training History ---\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(adamw_loss_history, label='AdamW Loss', alpha=0.7)\n",
        "plt.plot(lbfgs_loss_history, label='LBFGS Loss', alpha=0.7)\n",
        "plt.plot(custom_loss_history, label='Custom Update Loss', alpha=0.7)\n",
        "plt.plot(small_data_loss_history, label='AdamW (5 Symbols) Loss', alpha=0.7, linestyle='--')\n",
        "plt.xlabel('Epoch/Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss History for Different Optimizers and Data Parameters')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.yscale('log') # Use log scale for better visualization of different convergence speeds\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b77a9ba"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a summary of the organized code structure and how it facilitates experimentation with different optimizers and input data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78041349"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The organized code structure facilitates experimentation with different optimizers and input data in several key ways:\n",
        "\n",
        "*   **Different Optimizers**: The `train_model` function is designed to accept any `torch.optim.Optimizer` instance and handles specific optimizer behaviors (like LBFGS's `closure` or custom update rules) via an `optimizer_type` parameter. This allows users to simply instantiate a different optimizer (e.g., `optim.AdamW`, `torch.optim.LBFGS`) and pass it to the same training function, eliminating code duplication and making comparative studies straightforward.\n",
        "*   **Different Input Data Parameters**: The `generate_data` function centralizes data creation, allowing easy modification of parameters like `num_symbols` (problem complexity) and `train_frac` (dataset size/split). This enables rapid testing of a model's performance under various data conditions without altering the training or evaluation logic.\n",
        "*   **Modular and Clear Workflow**: By encapsulating model definition (`initialize_model_and_loss`), data generation (`generate_data`), training (`train_model`), and evaluation (`evaluate_model`) into distinct functions, the entire machine learning pipeline becomes modular. This modularity enhances readability, simplifies debugging, and makes it easier to extend or modify specific components of the experiment.\n",
        "*   **Reproducibility**: The explicit use of random seeds in data generation and the clear separation of concerns in the code structure promote reproducibility, ensuring that experiments can be reliably replicated.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The code was successfully refactored into modular functions: `generate_data` for creating datasets, `initialize_model_and_loss` for model and loss setup, `train_model` for the training loop (supporting AdamW, LBFGS, and custom optimizers), and `evaluate_model` for performance assessment.\n",
        "*   **AdamW Optimizer (9 symbols):** Achieved a validation accuracy of 93.62% and a loss of 0.0957 over 500 epochs, demonstrating stable and effective learning.\n",
        "*   **LBFGS Optimizer (9 symbols):** Achieved a validation accuracy of 91.71% and a loss of 0.0965 over 400 steps, showing rapid initial convergence.\n",
        "*   **Custom Optimizer (9 symbols):** Achieved a validation accuracy of 87.91% and a loss of 0.1507 over 500 epochs. Its loss history exhibited more fluctuations and less optimal performance compared to AdamW and LBFGS for this task.\n",
        "*   **AdamW with Different Data Parameters (5 symbols):** Training on a smaller problem with 5 symbols and a train fraction of 0.1 resulted in high training accuracy but a validation accuracy of only 51.85% and a loss of 1.1743, indicating significant overfitting due to the limited training data (24 samples).\n",
        "*   The visualization of loss histories clearly illustrated the distinct convergence patterns and speeds of the different optimizers and data configurations.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The modular code structure significantly reduces overhead for running comparative experiments, enabling efficient exploration of different optimization strategies and data configurations.\n",
        "*   Further hyperparameter tuning, especially for the custom optimizer and the smaller dataset scenario, could improve model performance and generalization. For the 5-symbol case, increasing the training data size or implementing regularization techniques would be crucial to combat overfitting.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
