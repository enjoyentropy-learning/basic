{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e9533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#import debugsudoku\n",
    "#importlib.reload(debugsudoku)\n",
    "#print(debugsudoku.d_model)\n",
    "%run debugsudoku.py\n",
    "print(d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee30641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Training with AdamW Optimizer (float32) ---\")\n",
    "torch.set_default_dtype(dtype_float32) # Set default dtype for this block\n",
    "# 3. Generate training and validation data for AdamW\n",
    "X_train_oh_adamw, y_train_adamw, X_val_oh_adamw, y_val_adamw, X_train_original_adamw, X_val_original_adamw = generate_data(num_symbols=9, train_frac=0.003, seed=42, dtype=dtype_float32)\n",
    "\n",
    "# 4. Initialize a new model and loss function\n",
    "model_adamw, loss_fn_adamw = initialize_model_and_loss(d_model, seq_len, dtype=dtype_float32)\n",
    "\n",
    "# 5. Initialize an AdamW optimizer\n",
    "optimizer_adamw = optim.AdamW(model_adamw.parameters(), lr=0.03)\n",
    "\n",
    "# 6. Train the model using train_model with AdamW optimizer\n",
    "adamw_loss_history = train_model(model_adamw, optimizer_adamw, loss_fn_adamw, X_train_oh_adamw, y_train_adamw,\n",
    "                                 epochs=500, log_interval=100, optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize Training History ---\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(adamw_loss_history, label='AdamW Loss (float32)', alpha=0.7)\n",
    "# plt.plot(lbfgs_loss_history, label='LBFGS Loss (float64)', alpha=0.7)\n",
    "# plt.plot(custom_loss_history, label='Custom Update Loss (float32)', alpha=0.7)\n",
    "# plt.plot(small_data_loss_history, label='AdamW (5 Symbols, float32) Loss', alpha=0.7, linestyle='--')\n",
    "plt.xlabel('Epoch/Step')\n",
    "plt.ylabel('Loss')\n",
    "#plt.title('Training Loss History for Different Optimizers and Data Parameters')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.yscale('log') # Use log scale for better visualization of different convergence speeds\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
